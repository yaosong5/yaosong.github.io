<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="纵浪大化中，不喜亦不悲"><title>钢铁锅 | 应尽便须尽，无复独多虑</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">钢铁锅</h1><a id="logo" href="/.">钢铁锅</a><p class="description">应尽便须尽，无复独多虑</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title"><a href="/2018/08/15/HDFS元数据备份流程/">HDFS元数据备份流程</a></h1><div class="post-meta">2018-08-15</div><div class="post-content"><p>[TOC]</p></div><p class="readmore"><a href="/2018/08/15/HDFS元数据备份流程/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/08/15/Hdfs结构性能分析及读写流程/">Hdfs结构性能分析及读写流程</a></h1><div class="post-meta">2018-08-15</div><div class="post-content"><p>[TOC]</p>
<h1 id="hdfs的设计思想"><a href="#hdfs的设计思想" class="headerlink" title="hdfs的设计思想"></a>hdfs的设计思想</h1><p>分而治之：将大文件、大批量文件，分布式存放在大量服务器上，以便于采取分而治之的方式对海量数据进行运算分析<br>首先，它是一个文件系统，用于存储文件，通过统一的命名空间——目录树来定位文件</p>
<h1 id="hdfs功能和特点"><a href="#hdfs功能和特点" class="headerlink" title="hdfs功能和特点"></a>hdfs功能和特点</h1><p>其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色；</p>
<p>hdfs的重要特性如下：</p>
<ul>
<li><p>HDFS中的文件在物理上是分块存储（block），块的大小可以通过配置参数( dfs.blocksize)来规定，默认大小在hadoop2.x版本中是128M，老版本中是64M</p>
</li>
<li><p>HDFS文件系统会给客户端提供一个统一的抽象目录树，客户端通过路径来访问文件，形如：hdfs://namenode:port/dir-a/dir-b/dir-c/file.data</p>
</li>
<li><p>目录结构及文件分块信息(元数据)的管理由namenode节点承担<br>——namenode是HDFS集群主节点，负责维护整个hdfs文件系统的目录树，以及每一个路径（文件）所对应的block块信息（block的id，及所在的datanode服务器）</p>
</li>
</ul>
<ul>
<li>文件的各个block的存储管理由datanode节点承担—- datanode是HDFS集群从节点，每一个block都可以在多个datanode上存储多个副本（副本数量也可以通过参数设置dfs.replication）</li>
</ul>
<p>HDFS是设计成适应一次写入，多次读出的场景，且不支持文件的修改</p>
<h1 id="Hdfs的结构"><a href="#Hdfs的结构" class="headerlink" title="Hdfs的结构"></a>Hdfs的结构</h1><p>1.HDFS集群分为两大角色：NameNode、DataNode （secondary NameNode）<br>2.NameNode负责管理整个文件系统的元数据<br>记录文件在哪里<br>3.DataNode 负责管理用户的文件数据块<br>不负责切块，负责保管<br>4.文件会按照固定的大小（blocksize）切成若干块后分布式存储在若干台datanode上<br>5.每一个文件块可以有多个副本，并存放在不同的datanode上<br>副本不会放在同一个机器上，因为副本就是防止宕机，<br>6.Datanode会定期向Namenode汇报自身所保存的文件block信息，而namenode则会负责保持文件的副本数量<br>因为datanode如果宕机的话，name该机器上的对应的副本数据将会消失，这样需要将其在其他机器上进行恢复，恢复的话，就需要上面就需要数据和未宕机时的数据尽量保持一致，所以需要依赖于datanode定期汇报，不然差距的数据会很大<br>7.HDFS的内部工作机制对客户端保持透明，客户端请求访问HDFS都是通过向namenode申请来进行</p>
<h1 id="Hdfs写操作"><a href="#Hdfs写操作" class="headerlink" title="Hdfs写操作"></a>Hdfs写操作</h1><p><img src="http://pebgsxjpj.bkt.clouddn.com/15361391927714.jpg" alt=""></p>
<p> 详细步骤解析</p>
<p>1、根namenode通信请求上传文件，namenode检查目标文件是否已存在，父目录是否存在</p>
<p>不存在则会返回path not exist异常</p>
<p>2、namenode返回是否可以上传</p>
<p>3、client请求第一个 block（0-128m）该传输到哪些datanode服务器上</p>
<p>返回该block存放的位置，及其副本的信息存放的位置</p>
<p>4、namenode返回3个datanode服务器ABC</p>
<p>副本选择策略（如果设置为被分数为2的话）</p>
<p>考虑空间和距离的因素，网络跳转的跳数，比如说机架的位置，</p>
<p>第一台是看谁比较近（机架），因为传输比较快，副本则是是看谁比较远，防止机架出问题（如断电），干扰性更小</p>
<p>而集群全线崩塌</p>
<p>5、client请求3台dn中的一台A上传数据（本质上是一个RPC调用，建立pipeline），A收到请求会继续调用B，然后B调用C，将真个pipeline建立完成，逐级返回客户端</p>
<p>这样是防止整个流程变慢，同时创建通道，先建立通道pipeline,通道</p>
<p>6、client开始往A上传第一个block（先从磁盘读取数据放到一个本地内存缓存bytebuf），以packet为单位，A收到一个packet就会传给B，B传给C；A每传一个packet会放入一个应答队列等待应答</p>
<p>因为等一个block写满之后再传送，速度会很慢，所以是接收一个packet就会写入到管道流pipeline中。</p>
<p>只要上传一个成功，则客户端视为上传成功，因为如果没上传成功，namenode会进行异步的复制副本的信息</p>
<p>7、当一个block传输完成之后，client再次请求<strong>namenode</strong>上传第二个block的服务器。</p>
<p>注：写的过程中，namenode记录下来了文件路径，文件有几个block也记录下来了，每个block分配到哪些机器上也记录下到了，及其每个block的副本信息，副本在那几个机器上。</p>
<p>校验的时候不是一个packet（一批chunk，共64k）校验，而是以一个chunk来校验，一个chunk是512byte（字节）</p>
<h1 id="Hdfs读操作"><a href="#Hdfs读操作" class="headerlink" title="Hdfs读操作"></a>Hdfs读操作</h1><p><img src="http://pebgsxjpj.bkt.clouddn.com/15361460237204.jpg" alt=""></p>
<p>客户端将要读取的文件路径发送给namenode，namenode获取文件的元信息（主要是block的存放位置信息）返回给客户端，客户端根据返回的信息找到相应datanode逐个获取文件的block并在客户端本地进行数据追加合并从而获得整个文件</p>
<p>1、跟namenode通信查询元数据，找到文件块所在的datanode服务器</p>
<p>2、挑选一台datanode（就近原则，然后随机）服务器，请求建立socket流</p>
<p>3、datanode开始发送数据（从磁盘里面读取数据放入流，以packet为单位来做校验）</p>
<p>4、客户端以packet为单位接收，现在本地缓存，然后写入目标文件</p>
<p>对此，我们了解了hdfs的读写流程，那么我们再来看看hdfs元数据的管理</p>
<h1 id="hdfs元数据管理"><a href="#hdfs元数据管理" class="headerlink" title="hdfs元数据管理"></a>hdfs元数据管理</h1><p>namenode对数据的管理采用了三种存储形式：</p>
<ul>
<li>内存元数据(NameSystem)</li>
<li>磁盘元数据镜像文件fsimage</li>
<li>数据操作日志文件edits（可通过日志运算出元数据）</li>
</ul>
<h1 id="namenode和secondaryNameNode最好不要放在一台机器上"><a href="#namenode和secondaryNameNode最好不要放在一台机器上" class="headerlink" title="namenode和secondaryNameNode最好不要放在一台机器上"></a>namenode和secondaryNameNode最好不要放在一台机器上</h1><p>宕机可能导致数据不能恢复<br>测试环境或者学习环境可以弄在一台机器上</p></div><p class="readmore"><a href="/2018/08/15/Hdfs结构性能分析及读写流程/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/08/15/Spark启动流程及一些小总结/">Spark启动流程及一些小总结</a></h1><div class="post-meta">2018-08-15</div><div class="post-content"><p>[TOC]</p>
<h1 id="spark的架构模型"><a href="#spark的架构模型" class="headerlink" title="spark的架构模型"></a>spark的架构模型</h1><p><img src="https://ws3.sinaimg.cn/large/006tNbRwly1fuhrnmk1skj310i0ssgma.jpg" alt=""></p>
<h1 id="角色功能"><a href="#角色功能" class="headerlink" title="角色功能"></a>角色功能</h1><p>Driver：以spark-submit提交程序为例，执行该命令的主机为driver（在任意一台安装了spark（spark submit）的机器上启动一个任务的客户端也就是Driver 。客户端与集群需要建立链接，建立的这个链接对象叫做sparkContext，只有这个对象创建成功才标志这这个客户端与spark集群链接成功。SparkContext是driver进程中的一个对象，提交任务的时候，指定了每台机器需要多少个核cores，需要的内存 ）</p>
<p>Master: 给任务提供资源，分配资源，master跟worker通信，报活和更新资源 </p>
<p>Worker:  以子进程的方式启动executor</p>
<p>Executor：Driver提交程序到executor(CoarseGrainedExecutorBankend)，执行任务的进程，exector是task运行的容器</p></div><p class="readmore"><a href="/2018/08/15/Spark启动流程及一些小总结/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/08/15/SparkStreaming消费Kafka数据/">SparkStreaming消费Kafka数据</a></h1><div class="post-meta">2018-08-15</div><div class="post-content"><p>[TOC]</p>
<p>Streaming消费Kafka有两种方式</p>
<h4 id="1、reciver方式"><a href="#1、reciver方式" class="headerlink" title="1、reciver方式"></a>1、reciver方式</h4><p>根据时间来划分批次，缺点：有可能一个时间段会出现数据爆炸，有保存log到hdfs机制，但消耗大（zk来管理偏移量）</p>
<h4 id="2、direct方式-1-3-6后推出"><a href="#2、direct方式-1-3-6后推出" class="headerlink" title="2、direct方式 1.3.6后推出"></a>2、direct方式 1.3.6后推出</h4><p>executor和kafka的partition是一一对应的（是rdd的分区和kafka对应，如果一个executor的rdd有多个分区，那么一个executor可以对应多个partition）必须自己来管理偏移量，最好把偏移量写在zk或者其他第三方介质里面</p></div><p class="readmore"><a href="/2018/08/15/SparkStreaming消费Kafka数据/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/08/15/Spark算子/">Spark算子案例</a></h1><div class="post-meta">2018-08-15</div><div class="post-content"><p>[TOC]</p>
<h1 id="HelloWord？WorldCount"><a href="#HelloWord？WorldCount" class="headerlink" title="HelloWord？WorldCount"></a>HelloWord？WorldCount</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc.textfile(<span class="string">"hdfs://master:9000/wc"</span>).flatMap(_.split(<span class="string">"分隔符"</span>)).map((_,<span class="number">1</span>)).reduceByKey(_+_).saveAsTextFile(<span class="string">"hdfs://master:9000/wcResult"</span>)</span><br></pre></td></tr></table></figure>
<p>数据最开始在Driver，计算的时候数据会流入worker<br>当rdd形成过程中，worker的分区中只是预留了存放数据的位置，只有当action触发的时候，worker的分区中才会存在数据</p>
<p>Spark的运算都是通过算子进行RDD的转换及运算，那我们对算子进行简单熟悉<a href="http://homepage.cs.latrobe.edu.au/zhe/ZhenHeSparkRDDAPIExamples.html" target="_blank" rel="noopener">参考RDD算子实例</a></p></div><p class="readmore"><a href="/2018/08/15/Spark算子/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/08/15/Scala基本使用/">Scala基本使用-杂记</a></h1><div class="post-meta">2018-08-15</div><div class="post-content"><p>[TOC]</p>
<p><img src="https://ws4.sinaimg.cn/large/006tNbRwgy1fukx028pz0j313t0op400.jpg" alt=""></p>
<p>Var和val</p>
<p>var 修饰的变量可改变，val 修饰的变量不可改变；但真的如此吗？事实上，var 修饰的对象引用可以改变，val 修饰的则不可改变，但对象的状态却是可以改变的。</p>
<h2 id="定义方法"><a href="#定义方法" class="headerlink" title="定义方法"></a>定义方法</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span><span class="title"> m1</span></span>(x:<span class="type">Int</span>,y:<span class="type">Int</span>):<span class="type">Int</span>=x*y</span><br></pre></td></tr></table></figure></div><p class="readmore"><a href="/2018/08/15/Scala基本使用/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/08/15/Hadoop-构成及HA-/">Hadoop-HA-Federation机制</a></h1><div class="post-meta">2018-08-15</div><div class="post-content"><p>[TOC]</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNbRwly1fubqgn0culj31eo0nm401.jpg" alt=""></p>
<p>（1）hadoop-HA集群运作机制介绍</p>
<p>所谓HA，即高可用（7*24小时不中断服务）</p>
<p>实现高可用最关键的是消除单点故障</p>
<p>hadoop-ha严格来说应该分成各个组件的HA机制——HDFS的HA、YARN的HA</p>
<p>（2）HDFS的HA机制详解</p>
<p>通过双namenode消除单点故障</p>
<p>双namenode协调工作的要点：</p>
<p>​    A、元数据管理方式需要改变：</p>
<p>​    内存中各自保存一份元数据</p>
<p>​    Edits日志只能有一份，只有Active状态的namenode节点可以做写操作</p>
<p>​    两个namenode都可以读取edits</p>
<p>​    共享的edits放在一个共享存储中管理（qjournal和NFS两个主流实现）</p>
<p>​    B、需要一个状态管理功能模块</p>
<p>​    实现了一个zkfailover，常驻在每一个namenode所在的节点</p>
<p>​    每一个zkfailover负责监控自己所在namenode节点，利用zk进行状态标识</p>
<p>​    当需要进行状态切换时，由zkfailover来负责切换</p>
<p>​    切换时需要防止brain split现象的发生</p>
<p>Hadoop-HA的主要思想是有两个NameNode，一个作为主NameNode，一个作为standby，两个NameNode使用同一个命名空间。通过zookeepr（JournalNode）来进行协调，实现NameNode的主备切换。</p></div><p class="readmore"><a href="/2018/08/15/Hadoop-构成及HA-/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/08/15/HBase性能分析/">no-title</a></h1><div class="post-meta">2018-08-15</div><div class="post-content"><p>[TOC]</p>
<p><img src="https://ws3.sinaimg.cn/large/0069RVTdgy1fuap8gxtquj31ca0ncdij.jpg" alt=""></p>
<h1 id="HBase介绍"><a href="#HBase介绍" class="headerlink" title="HBase介绍"></a>HBase介绍</h1><p>HBase表很大：一个表可以有数十亿行，上百万列；</p>
<p>HBase的表将会分成很多个分区，每个分区部分会存在不同的机器上<br>分区是为了便于查询，放在不同机器上，io也增大，假如一个机器的io的是100m，两个就为200m，读取速度就变快了==&gt;<strong>多台机器的io能得到充分利用</strong></p></div><p class="readmore"><a href="/2018/08/15/HBase性能分析/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/08/14/Kafka读取数据性能/">Kafka读写数据</a></h1><div class="post-meta">2018-08-14</div><div class="post-content"><p>[TOC]</p>
<p>首先kafka依赖于操作系统的pageCache机制，尽可能的把空闲的内存作为一个磁盘，只有发生缺页的才会放在磁盘中</p></div><p class="readmore"><a href="/2018/08/14/Kafka读取数据性能/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/08/14/Kafka深入解析/">Kafka深入解析</a></h1><div class="post-meta">2018-08-14</div><div class="post-content"><p>[TOC]</p>
<h1 id="Kafka结构"><a href="#Kafka结构" class="headerlink" title="Kafka结构"></a>Kafka结构</h1><ul>
<li><strong>Producer</strong> ：消息生产者，就是向kafka broker发消息的客户端。</li>
</ul>
<ul>
<li><p><strong>Consumer</strong> ：消息消费者，向kafka broker取消息的客户端</p>
</li>
<li><p><strong>Topic</strong> ：可以理解为一个队列</p></div><p class="readmore"><a href="/2018/08/14/Kafka深入解析/">阅读全文</a></p></div><nav class="page-navigator"><a class="extend prev" rel="prev" href="/">上一页</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/3/">下一页</a></nav></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://gangtieguo.cn"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spark-On-Yarn/">Spark-On-Yarn</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spring/">Spring</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客/">博客</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/安装部署/">安装部署</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/工程框架/">工程框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/快捷键/">快捷键</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/总结/">总结</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/框架/">框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/环境配置/">环境配置</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/碎片知识/">碎片知识</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/组件/">组件</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/语言/">语言</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/大数据/" style="font-size: 15px;">大数据</a> <a href="/tags/Docker/" style="font-size: 15px;">Docker</a> <a href="/tags/Jenkins/" style="font-size: 15px;">Jenkins</a> <a href="/tags/Docker-machine/" style="font-size: 15px;">Docker-machine</a> <a href="/tags/安装部署/" style="font-size: 15px;">安装部署</a> <a href="/tags/CDH/" style="font-size: 15px;">CDH</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/HBase/" style="font-size: 15px;">HBase</a> <a href="/tags/操作/" style="font-size: 15px;">操作</a> <a href="/tags/原理/" style="font-size: 15px;">原理</a> <a href="/tags/HDFS/" style="font-size: 15px;">HDFS</a> <a href="/tags/Hive/" style="font-size: 15px;">Hive</a> <a href="/tags/使用/" style="font-size: 15px;">使用</a> <a href="/tags/Shell/" style="font-size: 15px;">Shell</a> <a href="/tags/报表/" style="font-size: 15px;">报表</a> <a href="/tags/Json/" style="font-size: 15px;">Json</a> <a href="/tags/Scala/" style="font-size: 15px;">Scala</a> <a href="/tags/Kafka/" style="font-size: 15px;">Kafka</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Mysql/" style="font-size: 15px;">Mysql</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/开发/" style="font-size: 15px;">开发</a> <a href="/tags/Ambari/" style="font-size: 15px;">Ambari</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/SSH/" style="font-size: 15px;">SSH</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/Yarn/" style="font-size: 15px;">Yarn</a> <a href="/tags/SparkStreaming/" style="font-size: 15px;">SparkStreaming</a> <a href="/tags/SparkSQL/" style="font-size: 15px;">SparkSQL</a> <a href="/tags/RDD/" style="font-size: 15px;">RDD</a> <a href="/tags/ELK/" style="font-size: 15px;">ELK</a> <a href="/tags/es/" style="font-size: 15px;">es</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/FLINK/" style="font-size: 15px;">FLINK</a> <a href="/tags/命令/" style="font-size: 15px;">命令</a> <a href="/tags/Hue/" style="font-size: 15px;">Hue</a> <a href="/tags/技术/" style="font-size: 15px;">技术</a> <a href="/tags/zk/" style="font-size: 15px;">zk</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/Other/" style="font-size: 15px;">Other</a> <a href="/tags/快捷键/" style="font-size: 15px;">快捷键</a> <a href="/tags/Mac/" style="font-size: 15px;">Mac</a> <a href="/tags/Idea/" style="font-size: 15px;">Idea</a> <a href="/tags/Finder/" style="font-size: 15px;">Finder</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(四)Spark业务代码的执行及其任务分配调度stage划分/">Spark-on-Yarn源码解析(四)Spark业务代码的执行及其任务分配调度stage划分</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(三)client做的事情/">Spark-on-Yarn源码解析(三)client做的事情</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(二)Spark-Submit解析/">Spark-on-Yarn源码解析(二)Spark-Submit解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(一)Yarn任务解析/">Spark-on-Yarn源码解析(一)Yarn任务解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/20/MapReduce中Shuffle中的机制/">MapReduce中Shuffle中的机制</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/SparkSQL介绍/">SparkSQL介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/Spark-On-yarn/">Spark-On-Yarn模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/SparkStreaming介绍/">SparkStreaming介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/SparkRDD介绍/">SparkRDD介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/Hadoop零碎知识点/">Hadoop零碎知识点</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">钢铁锅.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>