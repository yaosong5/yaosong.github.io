<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="纵浪大化中，不喜亦不悲"><title>Spark-on-Yarn源码解析(三)client做的事情 | 钢铁锅</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Spark-on-Yarn源码解析(三)client做的事情</h1><a id="logo" href="/.">钢铁锅</a><p class="description">应尽便须尽，无复独多虑</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Spark-on-Yarn源码解析(三)client做的事情</h1><div class="post-meta">Sep 4, 2018<span> | </span><span class="category"><a href="/categories/Spark-On-Yarn/">Spark-On-Yarn</a></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div></div></div><div class="post-content"><p>[TOC]</p>
<p>spark-on-yarn系列</p>
<p><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B8%80" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (一)Yarn 任务解析</a>Yarn%E4%BB%BB%E5%8A%A1%E8%A7%A3%E6%9E%90/)<br><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%BA%8C" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (二)Spark-Submit 解析</a>Spark-Submit%E8%A7%A3%E6%9E%90/)<br><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B8%89" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (三)client 做的事情</a>client%E5%81%9A%E7%9A%84%E4%BA%8B%E6%83%85/)<br><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E5%9B%9B" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (四)Spark 业务代码的执行及其任务分配调度 stage 划分</a>Spark%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E7%9A%84%E6%89%A7%E8%A1%8C%E5%8F%8A%E5%85%B6%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D%E8%B0%83%E5%BA%A6stage%E5%88%92%E5%88%86/)</p>
<p>org.apache.spark.deploy.yarn.Client</p>
<p>话不多说，先上源码，当然还是简洁版本的</p>
<p>这儿我先上一下最简洁的调用链。</p>
<pre><code>Client.main()
    -&gt;new Client().run()
         -&gt;monitorApplication(submitApplication())
            -&gt;submitApplication()
                -&gt;createContainerLaunchContext()会封装一些启动信息如我们启动的类 --class
                    -&gt;userClass
                    -&gt;amArgs
                    -&gt;commands
                    -&gt;printableCommands
                    -&gt;amClass applicationMaster启动的真实类

                -&gt;createApplicationSubmissionContext()
                    -&gt;Records.newRecord(classOf[Resource])启动
                -&gt;yarnClientImpl.submitApplication(appContext)                
</code></pre><a id="more"></a>
<p>最终是调用的client里面main方法-&gt;run-&gt;</p>
<p>monitorApplication(submitApplication())</p>
<pre><code>object Client extends Logging {
  def main(argStrings: Array[String]) {
    ... ...
    val sparkConf = new SparkConf
    val args = new ClientArguments(argStrings, sparkConf)
    new Client(args, sparkConf).run()
    ... ...
  }
}

... ...
def run(): Unit = {
    val (yarnApplicationState, finalApplicationStatus) = monitorApplication(submitApplication())
    }
... ...
def submitApplication(): ApplicationId = {
    // TODO: 初始化并且启动client
    yarnClient.init(yarnConf)
    yarnClient.start()
    // TODO: 准备提交请求到resouceManager
    val newApp = yarnClient.createApplication()
    val newAppResponse = newApp.getNewApplicationResponse()
    val appId = newAppResponse.getApplicationId()
    // TODO: 检查集群的内存是否满足当前的任务要求
    verifyClusterResources(newAppResponse)
    // TODO:  设置适当上下文环境来启动applicationMaster
    val containerContext = createContainerLaunchContext(newAppResponse)
    val appContext = createApplicationSubmissionContext(newApp, containerContext)
    // TODO: 提交application
    yarnClient.submitApplication(appContext)
    appId
  }
   private def createContainerLaunchContext(newAppResponse: GetNewApplicationResponse)
    : ContainerLaunchContext = {
    ... ...
          val userClass =
      if (isClusterMode) {
        Seq(&quot;--class&quot;, YarnSparkHadoopUtil.escapeForShell(args.userClass))
      } else {
        Nil
      }
      ...
       val amClass =
      if (isClusterMode) {
Class.forName(&quot;org.apache.spark.deploy.yarn.ApplicationMaster&quot;).getName
      } else {
Class.forName(&quot;org.apache.spark.deploy.yarn.ExecutorLauncher&quot;).getName
      }
          val amArgs =
      Seq(amClass) ++ userClass ++ userJar ++ primaryPyFile ++ pyFiles ++ userArgs ++
        Seq(
          &quot;--executor-memory&quot;, args.executorMemory.toString + &quot;m&quot;,
          &quot;--executor-cores&quot;, args.executorCores.toString,
          &quot;--num-executors &quot;, args.numExecutors.toString)

    val commands = prefixEnv ++ Seq(YarnSparkHadoopUtil.expandEnvironment(Environment.JAVA_HOME) + &quot;/bin/java&quot;, &quot;-server&quot;
      ) ++
      javaOpts ++ amArgs ++
    ... ...
     val printableCommands = commands.map(s =&gt; if (s == null) &quot;null&quot; else s).toList
    amContainer.setCommands(printableCommands)
    }
    ... ...
def createApplicationSubmissionContext(
      newApp: YarnClientApplication,
      containerContext: ContainerLaunchContext): ApplicationSubmissionContext = {
    val appContext = newApp.getApplicationSubmissionContext
    appContext.setApplicationName(args.appName)
    appContext.setQueue(args.amQueue)
    appContext.setAMContainerSpec(containerContext)
    appContext.setApplicationType(&quot;SPARK&quot;)
    sparkConf.getOption(&quot;spark.yarn.maxAppAttempts&quot;).map(_.toInt) match {
      case Some(v) =&gt; appContext.setMaxAppAttempts(v)
      case None =&gt; logDebug(&quot;spark.yarn.maxAppAttempts is not set. &quot; +
          &quot;Cluster&apos;s default value will be used.&quot;)
    }

    val capability = Records.newRecord(classOf[Resource])
    capability.setMemory(args.amMemory + amMemoryOverhead)
    capability.setVirtualCores(args.amCores)
    appContext.setResource(capability)
    appContext
  }

//yarnClient.submitApplication(appContext)提交的真实处  
@Override
  public ApplicationId
      submitApplication(ApplicationSubmissionContext appContext)
          throws YarnException, IOException {
...
//此处通过yarn的协议对applicationMaster进行提交和启动 （此处为个人理解有疑惑，如有错误，还望留言分享，会立即作出更正）
    SubmitApplicationRequest request =
        Records.newRecord(SubmitApplicationRequest.class);
    request.setApplicationSubmissionContext(appContext);
...
</code></pre><p>此处client的事情都已经做完了，请摄影师将镜头切换到applicationMaster</p>
<p>小细节用户业务代码信息的封装及流转</p>
<p>我们提交的class的封装流程</p>
<pre><code>-&gt;sublimit的prepareSubmitEnvironment中封装到childArgs中--class
-&gt;传入到client的构造函数里面作为clientArgs，将其封装到userClass属性里面

在submitApplication中createContainerLaunchContext会将其通过重新封到userClass
    userClass-&gt;amArgs-&gt;commands-&gt;printableCommands
    -&gt;amContainer.setCommands(printableCommands)
    在此，createContainerLaunchContext方法接收到amContainer赋名为containerContext传递给createApplicationSubmissionContext(..,containerContext)

那么在createApplicationSubmissionContext中又有哪些惊天变化（其实并没有）

appContext.setAMContainerSpec(containerContext)
那么appContext作为createApplicationSubmissionContext方法返回值，由appContext接收，看码

appContext = createApplicationSubmissionContext(newApp, containerContext)
最后，由yarnClientImpl提交
yarnClient.submitApplication(appContext)
码又来了，最终执行的是
SubmitApplicationRequest request =Records.newRecord(SubmitApplicationRequest.class);
</code></pre><p>启动applicationMaster</p>
<p>对于client的封装，对于applicationMaster需要启动的信息(如资源信息)及用户提交的业务代码（wordcount的类信息）信息都已经封装到appContext，并且传递到applicationmaster，那么来看看applicationMaster的执行流程。</p>
<p>程序调用结构</p>
<pre><code>ApplicationMaster.main()
    -&gt;run()
        -&gt;runDriver()
            -&gt;run()
                -&gt;startUserApplication()
                    //启动userClass
                    -&gt;userClassLoader.loadClass(args.userClass)
      .getMethod(&quot;main&quot;, classOf[Array[String]])
                     -&gt;mainMethod.invoke(null, mainArgs)
                runAMActor()
                registerAM()
                    -&gt;yarnRmClient.register()-&gt;return new YarnAllocater(......)
                    -&gt;yarnAllocator.allocateResources()
                        -&gt;yarnAllocator.handleAllocatedContainers()
                        //启动executor
                        -&gt;yarnAllocator.runAllocatedContainers(containersToUse)
</code></pre><p>runAllocatedContainers(containersToUse)是去启动 executor，最终真正执行启动Container的是在 ExecutorRunnable.run()中。</p>
<p>创建了 NMClient 客户端调用提供的 API 最终实现在 NM 上启动 Container，具体如何启动 Container 将在后文中进行介绍。</p>
<p>launcherPool线程池会将container，driver等相关信息封装成ExecutorRunnable对象，通过ExecutorRunnable启动新的container以运行executor。在此过程中，指定启动executor的类是</p>
<p>org.apache.spark.executor.CoarseGrainedExecutorBackend。spark yarn cluster 模式下任务提交和计算流程分析</p>
<p>程序的细节</p>
<pre><code>def main(args: Array[String]) = {
    SignalLogger.register(log)
    val amArgs = new ApplicationMasterArguments(args)
    SparkHadoopUtil.get.runAsSparkUser { () =&gt;
      master = new ApplicationMaster(amArgs, new YarnRMClient(amArgs))
      System.exit(master.run())
    }
  }


  ......
  final def run(): Int = {
  ....
    if (isClusterMode) {
        runDriver(securityMgr)
      } else {
        runExecutorLauncher(securityMgr)
      }
...
}

  private def runDriver(securityMgr: SecurityManager): Unit = {
    addAmIpFilter()
    // TODO:  启动我们自定的类，也就是启动submit里面的--class的东西
    userClassThread = startUserApplication()
    val sc = waitForSparkContextInitialized()
...
  actorSystem = sc.env.actorSystem
  runAMActor(
    sc.getConf.get(&quot;spark.driver.host&quot;),
    sc.getConf.get(&quot;spark.driver.port&quot;),
    isClusterMode = true)
  registerAM(sc.ui.map(_.appUIAddress).getOrElse(&quot;&quot;), securityMgr)
  userClassThread.join()
    ...
  }
</code></pre><p>在ApplicationMasterArguments设置了要启动的信息</p>
<pre><code>class ApplicationMasterArguments(val args: Array[String]) {
  var userJar: String = null
  var userClass: String = null
  var primaryPyFile: String = null
  var pyFiles: String = null
  var userArgs: Seq[String] = Seq[String]()
  var executorMemory = 1024
  var executorCores = 1
  var numExecutors = DEFAULT_NUMBER_EXECUTORS
  ......
  }
</code></pre><p>startUserApplication 主要执行了调用用户的代码，以及创建了一个 spark driver 的进程。 </p>
<p>Start the user class, which contains the spark driver, in a separate Thread.</p>
<pre><code>private def startUserApplication(): Thread = {
  val classpath = Client.getUserClasspath(sparkConf)
val urls = classpath.map { entry =&gt;
  new URL(&quot;file:&quot; + new File(entry.getPath()).getAbsolutePath())
}
val userClassLoader =
...
// TODO:  userClass就是submit里面的--class 提交的类
val mainMethod = userClassLoader.loadClass(args.userClass)
  .getMethod(&quot;main&quot;, classOf[Array[String]])
userThread.setContextClassLoader(userClassLoader)
userThread.setName(&quot;Driver&quot;)
userThread.start()
userThread
}
</code></pre><p>从userThread.setName(“Driver”)也可以看出创建的是名为driver的进程</p>
<p>registerAM 向 resourceManager 中正式注册 applicationMaster。注册applicationMaster 以后，并且分配资源，这样，用户代码就可以执行了，任务切分、调度、执行。</p>
<p>然后，用户代码中的 action 会调用 SparkContext 的 runJob，SparkContext 中有很多个 runJob，但最后都是调用 DAGScheduler 的 runJob</p>
<pre><code>  // registerAM
   private def registerAM(uiAddress: String, securityMgr: SecurityManager) = {
   .....
  allocator = client.register(yarnConf,
    if (sc != null) sc.getConf else sparkConf,
    if (sc != null) sc.preferredNodeLocationData else Map(),
    uiAddress,
    historyAddress,
    securityMgr)
    //为exector分配资源
  allocator.allocateResources()
  reporterThread = launchReporterThread()
  ......
}
</code></pre></div><div class="tags"><a href="/tags/原理/">原理</a><a href="/tags/Spark/">Spark</a></div><div class="post-nav"><a class="pre" href="/2018/09/04/Spark-on-Yarn源码解析(四)Spark业务代码的执行及其任务分配调度stage划分/">Spark-on-Yarn源码解析(四)Spark业务代码的执行及其任务分配调度stage划分</a><a class="next" href="/2018/09/04/Spark-on-Yarn源码解析(二)Spark-Submit解析/">Spark-on-Yarn源码解析(二)Spark-Submit解析</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://gangtieguo.cn"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spark-On-Yarn/">Spark-On-Yarn</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spring/">Spring</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客/">博客</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/安装部署/">安装部署</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/工程框架/">工程框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/快捷键/">快捷键</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/总结/">总结</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/框架/">框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/环境配置/">环境配置</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/碎片知识/">碎片知识</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/组件/">组件</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/语言/">语言</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/Docker/" style="font-size: 15px;">Docker</a> <a href="/tags/Jenkins/" style="font-size: 15px;">Jenkins</a> <a href="/tags/Docker-machine/" style="font-size: 15px;">Docker-machine</a> <a href="/tags/安装部署/" style="font-size: 15px;">安装部署</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/CDH/" style="font-size: 15px;">CDH</a> <a href="/tags/HBase/" style="font-size: 15px;">HBase</a> <a href="/tags/操作/" style="font-size: 15px;">操作</a> <a href="/tags/HDFS/" style="font-size: 15px;">HDFS</a> <a href="/tags/原理/" style="font-size: 15px;">原理</a> <a href="/tags/Shell/" style="font-size: 15px;">Shell</a> <a href="/tags/Hive/" style="font-size: 15px;">Hive</a> <a href="/tags/报表/" style="font-size: 15px;">报表</a> <a href="/tags/Json/" style="font-size: 15px;">Json</a> <a href="/tags/Scala/" style="font-size: 15px;">Scala</a> <a href="/tags/使用/" style="font-size: 15px;">使用</a> <a href="/tags/Kafka/" style="font-size: 15px;">Kafka</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/开发/" style="font-size: 15px;">开发</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Mysql/" style="font-size: 15px;">Mysql</a> <a href="/tags/Ambari/" style="font-size: 15px;">Ambari</a> <a href="/tags/SSH/" style="font-size: 15px;">SSH</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/大数据/" style="font-size: 15px;">大数据</a> <a href="/tags/SparkSQL/" style="font-size: 15px;">SparkSQL</a> <a href="/tags/Yarn/" style="font-size: 15px;">Yarn</a> <a href="/tags/RDD/" style="font-size: 15px;">RDD</a> <a href="/tags/SparkStreaming/" style="font-size: 15px;">SparkStreaming</a> <a href="/tags/ELK/" style="font-size: 15px;">ELK</a> <a href="/tags/es/" style="font-size: 15px;">es</a> <a href="/tags/FLINK/" style="font-size: 15px;">FLINK</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/命令/" style="font-size: 15px;">命令</a> <a href="/tags/Hue/" style="font-size: 15px;">Hue</a> <a href="/tags/zk/" style="font-size: 15px;">zk</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/Other/" style="font-size: 15px;">Other</a> <a href="/tags/技术/" style="font-size: 15px;">技术</a> <a href="/tags/快捷键/" style="font-size: 15px;">快捷键</a> <a href="/tags/Mac/" style="font-size: 15px;">Mac</a> <a href="/tags/Idea/" style="font-size: 15px;">Idea</a> <a href="/tags/Finder/" style="font-size: 15px;">Finder</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(四)Spark业务代码的执行及其任务分配调度stage划分/">Spark-on-Yarn源码解析(四)Spark业务代码的执行及其任务分配调度stage划分</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(三)client做的事情/">Spark-on-Yarn源码解析(三)client做的事情</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(二)Spark-Submit解析/">Spark-on-Yarn源码解析(二)Spark-Submit解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(一)Yarn任务解析/">Spark-on-Yarn源码解析(一)Yarn任务解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/20/MapReduce中Shuffle中的机制/">MapReduce中Shuffle中的机制</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/SparkSQL介绍/">SparkSQL介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/Spark-On-yarn/">Spark-On-Yarn模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/SparkStreaming介绍/">SparkStreaming介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/SparkRDD介绍/">SparkRDD介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/Hadoop零碎知识点/">Hadoop零碎知识点</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">钢铁锅.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>