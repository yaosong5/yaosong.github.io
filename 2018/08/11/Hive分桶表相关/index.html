<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="纵浪大化中，不喜亦不悲"><title>Hive分桶表,分区表简单分析 | 钢铁锅</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Hive分桶表,分区表简单分析</h1><a id="logo" href="/.">钢铁锅</a><p class="description">应尽便须尽，无复独多虑</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Hive分桶表,分区表简单分析</h1><div class="post-meta">Aug 11, 2018<span> | </span><span class="category"><a href="/categories/大数据/">大数据</a></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#分桶表创建"><span class="toc-number">1.</span> <span class="toc-text">分桶表创建</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#分桶模式的参数"><span class="toc-number">1.1.</span> <span class="toc-text">分桶模式的参数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Update与分桶表关系"><span class="toc-number">1.2.</span> <span class="toc-text">Update与分桶表关系</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#更新语句"><span class="toc-number">1.3.</span> <span class="toc-text">更新语句:</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#分桶表测试"><span class="toc-number">2.</span> <span class="toc-text">分桶表测试</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#创建表"><span class="toc-number">2.1.</span> <span class="toc-text">创建表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#创建数据"><span class="toc-number">2.2.</span> <span class="toc-text">创建数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#读取本地文件"><span class="toc-number">2.3.</span> <span class="toc-text">读取本地文件</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#注意"><span class="toc-number">3.</span> <span class="toc-text">注意</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#hive分桶表的使用场景"><span class="toc-number">4.</span> <span class="toc-text">hive分桶表的使用场景</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#结果如下"><span class="toc-number">4.1.</span> <span class="toc-text">结果如下</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#设置分桶参数"><span class="toc-number">5.</span> <span class="toc-text">设置分桶参数</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#重新创建表"><span class="toc-number">5.1.</span> <span class="toc-text">重新创建表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#再分别查看这几个文件"><span class="toc-number">5.2.</span> <span class="toc-text">再分别查看这几个文件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#得到结果"><span class="toc-number">5.3.</span> <span class="toc-text">得到结果</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#分桶表疑问"><span class="toc-number">6.</span> <span class="toc-text">分桶表疑问</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#为什么每个桶里面的数据条数不一样"><span class="toc-number">6.1.</span> <span class="toc-text">为什么每个桶里面的数据条数不一样</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#分桶表的意义："><span class="toc-number">7.</span> <span class="toc-text">分桶表的意义：</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#注意-1"><span class="toc-number">8.</span> <span class="toc-text">注意</span></a></li></ol></div></div><div class="post-content"><p>[TOC]</p>
<p><img src="https://ws2.sinaimg.cn/large/0069RVTdgy1fu81tzpekzj305z06j3yc.jpg" alt=""></p>
<p>对于每一个表或者是分区，Hive 可以进一步组织成桶，也就是说桶是更为细粒度的数据范围划分。Hive 是针对某一列进行分桶。Hive 采用对列值哈希，然后除以桶的个数求余的方式决定该条记录存放在哪个桶中。分桶的好处是可以获得更高的查询处理效率。使取样更高效。</p>
<p>分桶依赖于yarn的所以分桶的时候需要启动yarn</p>
<a id="more"></a>
<h1 id="分桶表创建"><a href="#分桶表创建" class="headerlink" title="分桶表创建"></a>分桶表创建</h1><p>#设置变量,设置分桶为true, 设置reduce数量是分桶的数量个数</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.enforce.bucketing = <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> mapreduce.job.reduces=<span class="number">4</span>;</span><br></pre></td></tr></table></figure>
<p>创建表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> person_buck(<span class="keyword">id</span> <span class="built_in">int</span>,<span class="keyword">name</span> <span class="keyword">string</span>,sex <span class="keyword">string</span>,age <span class="built_in">int</span>)</span><br><span class="line">clustered <span class="keyword">by</span>(<span class="keyword">id</span>) </span><br><span class="line">sorted <span class="keyword">by</span>(<span class="keyword">id</span> <span class="keyword">DESC</span>)</span><br><span class="line"><span class="keyword">into</span> <span class="number">4</span> buckets</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span></span><br><span class="line"><span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span>;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">开会往创建的分桶表插入数据(插入数据需要是已分桶, 且排序的)</span><br><span class="line">可以使用distribute by(id) sort by(id asc)  或是排序和分桶的字段相同的时候使用Cluster by(字段)</span><br><span class="line">注意使用cluster by  就等同于分桶+排序(sort)</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> person_buck <span class="keyword">select</span> <span class="keyword">id</span>,<span class="keyword">name</span>,sex,age <span class="keyword">from</span> student <span class="keyword">distribute</span> <span class="keyword">by</span>(<span class="keyword">id</span>) <span class="keyword">sort</span> <span class="keyword">by</span>(<span class="keyword">id</span> <span class="keyword">asc</span>);</span><br></pre></td></tr></table></figure>
<h2 id="分桶模式的参数"><a href="#分桶模式的参数" class="headerlink" title="分桶模式的参数"></a>分桶模式的参数</h2><p>设置变量,设置分桶为true, 设置reduce数量是分桶的数量个数</p>
<p>set hive.enforce.bucketing = true;</p>
<p>不设置reduce的数量会使用默认的数量，默认的数量会和分桶的数量不一致，则不能分出正确分桶</p>
<p>set mapreduce.job.reduces=4;</p>
<p>本地模式</p>
<p>set hive.exec.mode.local.auto=true</p>
<p>动态分区</p>
<p>–设置为true表示开启动态分区功能（默认为false）</p>
<p>set hive.exec.dynamic.partition=true;</p>
<p>–设置为nonstrict,表示允许所有分区都是动态的（默认为strict）</p>
<p>set hive.exec.dynamic.partition.mode=nonstrict;</p>
<h2 id="Update与分桶表关系"><a href="#Update与分桶表关系" class="headerlink" title="Update与分桶表关系"></a>Update与分桶表关系</h2><p>Hive对使用Update功能的表有特定的语法要求, 语法要求如下:<br>(1)要执行Update的表中, 建表时必须带有buckets(分桶)属性<br>(2)要执行Update的表中, 需要指定格式,其余格式目前赞不支持, 如:parquet格式, 目前只支持ORCFileformat和AcidOutputFormat<br>(3)要执行Update的表中, 建表时必须指定参数(‘transactional’ = true);<br>举例:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create table student (id bigint,name string) clustered by (name) into 2 buckets stored as orc TBLPROPERTIES(&apos;transactional&apos;=&apos;true&apos;);</span><br></pre></td></tr></table></figure>
<h2 id="更新语句"><a href="#更新语句" class="headerlink" title="更新语句:"></a>更新语句:</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update student set id=&apos;444&apos; where name=&apos;tom&apos;;</span><br></pre></td></tr></table></figure>
<h1 id="分桶表测试"><a href="#分桶表测试" class="headerlink" title="分桶表测试"></a>分桶表测试</h1><p>这个例子就是将分区的字段进行hash散列将数据分桶到分桶数个文件中去</p>
<p>导入一个文件到分桶表里面</p>
<h2 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_buk(<span class="keyword">id</span> <span class="built_in">int</span>,<span class="keyword">name</span> <span class="keyword">string</span>) clustered <span class="keyword">by</span>(<span class="keyword">id</span>)  sorted <span class="keyword">by</span>(<span class="keyword">id</span> <span class="keyword">DESC</span>) <span class="keyword">into</span> <span class="number">4</span> buckets <span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span><span class="string">``</span><span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span>;</span><br></pre></td></tr></table></figure>
<h2 id="创建数据"><a href="#创建数据" class="headerlink" title="创建数据"></a>创建数据</h2><p><strong>cd /usr/hive/hivedata/</strong></p>
<p><strong>vim buk.txt</strong> </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">1,数据库</span><br><span class="line">2,数学</span><br><span class="line">3,信息系统</span><br><span class="line">4,操作系统</span><br><span class="line">5,数据结构</span><br><span class="line">6,数据no</span><br><span class="line">7,数据other</span><br><span class="line">8,数据time</span><br><span class="line">9,数据操作</span><br><span class="line">10,数据挖掘</span><br><span class="line">11,数据挖机</span><br><span class="line">12,数据信号</span><br></pre></td></tr></table></figure>
<h2 id="读取本地文件"><a href="#读取本地文件" class="headerlink" title="读取本地文件"></a>读取本地文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &apos;/usr/hive/hivedata/buk.txt&apos; into table t_buk;</span><br></pre></td></tr></table></figure>
<p>load方式这样导入数据到一个分桶表里面，是不会作出分桶的操作的，不会分成桶数个文件，还是一个文件在hdfs系统中</p>
<h1 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h1><ol>
<li>要想导入到数据到分桶表里面，必须是一个是已经是分桶的数据，比如已经形成了分桶数据个文件，才可以导入到分桶表里面，导数据的时候是不会将原来的数据形式变成分桶的数据形式</li>
</ol>
<h1 id="hive分桶表的使用场景"><a href="#hive分桶表的使用场景" class="headerlink" title="hive分桶表的使用场景"></a>hive分桶表的使用场景</h1><p>所以一般是在一个表中查询了数据然后在塞入到一个分区表里面，查询是走mapReduce程序，然后将数据按分桶表照分桶的策略写入到分桶表中</p>
<p>形如</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_buk <span class="keyword">select</span> * <span class="keyword">from</span> other … …;</span><br></pre></td></tr></table></figure>
<p>后面的</p>
<p>清除数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">truncate</span> <span class="keyword">table</span> t_buk;</span><br></pre></td></tr></table></figure>
<p>创建一个表来读取数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_p(<span class="keyword">id</span> <span class="built_in">int</span>,<span class="keyword">name</span> <span class="keyword">string</span>)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span></span><br><span class="line"><span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/usr/hive/hivedata/buk.txt'</span> <span class="keyword">into</span> <span class="keyword">table</span> t_p;</span><br></pre></td></tr></table></figure>
<p> insert into table t_buk select id,name from t_p; </p>
<p> insert overwirte 也可以</p>
<h2 id="结果如下"><a href="#结果如下" class="headerlink" title="结果如下"></a>结果如下</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Number of reduce tasks is set to 0 since there&apos;s no reduce operator</span><br><span class="line">INFO  : number of splits:1</span><br><span class="line">INFO  : Submitting tokens for job: job_1502537431423_0011</span><br><span class="line">INFO  : The url to track the job: http://bigdata1:8088/proxy/application_1502537431423_0011/</span><br><span class="line">INFO  : Starting Job = job_1502537431423_0011, Tracking URL = http://bigdata1:8088/proxy/application_1502537431423_0011/</span><br><span class="line">INFO  : Kill Command = /home/bigdata/apps/hadoop/bin/hadoop job  -kill job_1502537431423_0011</span><br><span class="line">INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0</span><br><span class="line">INFO  : 2017-08-15 21:12:15,669 Stage-1 map = 0%,  reduce = 0%</span><br><span class="line">INFO  : 2017-08-15 21:12:32,386 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.27 sec</span><br><span class="line">INFO  : MapReduce Total cumulative CPU time: 1 seconds 270 msec</span><br><span class="line">INFO  : Ended Job = job_1502537431423_0011</span><br><span class="line">INFO  : Stage-4 is selected by condition resolver.</span><br><span class="line">INFO  : Stage-3 is filtered out by condition resolver.</span><br><span class="line">INFO  : Stage-5 is filtered out by condition resolver.</span><br><span class="line">INFO  : Moving data to: hdfs://bigdata1:9000/user/hive/warehouse/t_buk/.hive-staging_hive_2017-08-15_21-12-02_490_4088487413275551800-3/-ext-10000 from hdfs://bigdata1:9000/user/hive/warehouse/t_buk/.hive-staging_hive_2017-08-15_21-12-02_490_4088487413275551800-3/-ext-10002</span><br><span class="line">INFO  : Loading data to table default.t_buk from hdfs://bigdata1:9000/user/hive/warehouse/t_buk/.hive-staging_hive_2017-08-15_21-12-02_490_4088487413275551800-3/-ext-10000</span><br><span class="line">INFO  : Table default.t_buk stats: [numFiles=1, numRows=12, totalSize=167, rawDataSize=155]</span><br></pre></td></tr></table></figure>
<p>查看hdfs管理页面 50070</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNbRwgy1fu7ufetxnpj30yw06fmx9.jpg" alt=""></p>
<p> 还是只有一文件，表示分桶不成功，没设reduce数量，使用默认的数量1，和我们期望分桶数量不一致</p>
<h1 id="设置分桶参数"><a href="#设置分桶参数" class="headerlink" title="设置分桶参数"></a>设置分桶参数</h1><p>因为没有启动模式的开关，如下</p>
<p>设置变量,设置分桶为true, 设置reduce数量是分桶的数量个数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">set hive.enforce.bucketing = true;</span><br><span class="line">set mapreduce.job.reduces=4;</span><br><span class="line">set hive.exec.mode.local.auto=true;</span><br><span class="line">set hive.exec.dynamic.partition=true;</span><br><span class="line">set hive.exec.dynamic.partition.mode=nonstrict;</span><br></pre></td></tr></table></figure>
<h2 id="重新创建表"><a href="#重新创建表" class="headerlink" title="重新创建表"></a>重新创建表</h2><p>可以通过set hive.enforce.bucketing查看是否设置成功</p>
<p>先查看sort by (id)；</p>
<p>根据4个reduce来局部有序，每个reduce有序，但是从哪儿截断每个reduce并不确定</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">select id,name from t_p sort by (id);</span><br><span class="line">INFO  : Number of reduce tasks not specified. Defaulting to jobconf value of: 4</span><br><span class="line">INFO  : In order to change the average load for a reducer (in bytes):</span><br><span class="line">INFO  :   set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span><br><span class="line">INFO  : In order to limit the maximum number of reducers:</span><br><span class="line">INFO  :   set hive.exec.reducers.max=&lt;number&gt;</span><br><span class="line">INFO  : In order to set a constant number of reducers:</span><br><span class="line">INFO  :   set mapreduce.job.reduces=&lt;number&gt;</span><br><span class="line">INFO  : number of splits:1</span><br><span class="line">INFO  : Submitting tokens for job: job_1502537431423_0012</span><br><span class="line">INFO  : The url to track the job: http://bigdata1:8088/proxy/application_1502537431423_0012/</span><br><span class="line">INFO  : Starting Job = job_1502537431423_0012, Tracking URL = http://bigdata1:8088/proxy/application_1502537431423_0012/</span><br><span class="line">INFO  : Kill Command = /home/bigdata/apps/hadoop/bin/hadoop job  -kill job_1502537431423_0012</span><br><span class="line">INFO  : Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 4</span><br><span class="line">INFO  : 2017-08-15 21:26:14,284 Stage-1 map = 0%,  reduce = 0%</span><br><span class="line">INFO  : 2017-08-15 21:26:24,633 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.29 sec</span><br><span class="line">INFO  : 2017-08-15 21:26:38,745 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 6.99 sec</span><br><span class="line">INFO  : 2017-08-15 21:26:43,887 Stage-1 map = 100%,  reduce = 67%, Cumulative CPU 6.99 sec</span><br><span class="line">INFO  : 2017-08-15 21:26:46,970 Stage-1 map = 100%,  reduce = 75%, Cumulative CPU 9.06 sec</span><br><span class="line">INFO  : 2017-08-15 21:26:50,081 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 10.8 sec</span><br><span class="line">INFO  : MapReduce Total cumulative CPU time: 10 seconds 800 msec</span><br><span class="line">INFO  : Ended Job = job_1502537431423_0012</span><br><span class="line">+-----+----------+--+</span><br><span class="line">| id  |   name   |</span><br><span class="line">+-----+----------+--+</span><br><span class="line">| 4   | 操作系统     |</span><br><span class="line">| 8   | 数据time   |</span><br><span class="line">| 12  | 数据信号     |</span><br><span class="line">| 2   | 数学       |</span><br><span class="line">| 6   | 数据no     |</span><br><span class="line">| 1   | 数据库      |</span><br><span class="line">| 3   | 信息系统     |</span><br><span class="line">| 5   | 数据结构     |</span><br><span class="line">| 10  | 数据挖掘     |</span><br><span class="line">| 11  | 数据挖机     |</span><br><span class="line">| 7   | 数据other  |</span><br><span class="line">| 9   | 数据操作     |</span><br><span class="line">+-----+----------+--+</span><br></pre></td></tr></table></figure>
<p>再试一次select 插入（将t_buk truncate也可，也可使用overwrite关键字）</p>
<p> <code>insert overwrite table t_buk select id,name from t_p cluster by (id);</code></p>
<p>再查看hdfs ui页面50070</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNbRwgy1fu7uk05fz5j30x70a8mxm.jpg" alt=""></p>
<h2 id="再分别查看这几个文件"><a href="#再分别查看这几个文件" class="headerlink" title="再分别查看这几个文件"></a>再分别查看这几个文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME/bin/hadoop fs -cat /user/hive/warehouse/t_buk/000000_0</span><br><span class="line">$HADOOP_HOME/bin/hadoop fs -cat /user/hive/warehouse/t_buk/000001_0  </span><br><span class="line">$HADOOP_HOME/bin/hadoop fs -cat /user/hive/warehouse/t_buk/000002_0  </span><br><span class="line">$HADOOP_HOME/bin/hadoop fs -cat /user/hive/warehouse/t_buk/000003_0</span><br></pre></td></tr></table></figure>
<h2 id="得到结果"><a href="#得到结果" class="headerlink" title="得到结果"></a>得到结果</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[bigdata@master hivedata]$  hadoop fs -cat /user/hive/warehouse/t_buk/000000_0  </span><br><span class="line">4,操作系统</span><br><span class="line">8,数据time</span><br><span class="line">12,数据信号</span><br><span class="line">[bigdata@master hivedata]$  hadoop fs -cat /user/hive/warehouse/t_buk/000001_0  </span><br><span class="line">1,数据库</span><br><span class="line">5,数据结构</span><br><span class="line">9,数据操作</span><br><span class="line">[bigdata@master hivedata]$  hadoop fs -cat /user/hive/warehouse/t_buk/000002_0  </span><br><span class="line">2,数学</span><br><span class="line">6,数据no</span><br><span class="line">10,数据挖掘</span><br><span class="line">[bigdata@master hivedata]$  hadoop fs -cat /user/hive/warehouse/t_buk/000003_0</span><br><span class="line">3,信息系统</span><br><span class="line">7,数据other</span><br><span class="line">11,数据挖机</span><br></pre></td></tr></table></figure>
<h1 id="分桶表疑问"><a href="#分桶表疑问" class="headerlink" title="分桶表疑问"></a>分桶表疑问</h1><h2 id="为什么每个桶里面的数据条数不一样"><a href="#为什么每个桶里面的数据条数不一样" class="headerlink" title="为什么每个桶里面的数据条数不一样"></a>为什么每个桶里面的数据条数不一样</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hash散列的时候数据可能将数据有的分的多，有的分的少</span><br></pre></td></tr></table></figure>
<p>cluster by （id） 根据id分桶，桶内根据id排序，相当于 distribute by 和 sort by的集合，只是指定的字段都是同一个<br>用两个组合更加强大，分桶字段排序字段可以设置为不同</p>
<h1 id="分桶表的意义："><a href="#分桶表的意义：" class="headerlink" title="分桶表的意义："></a>分桶表的意义：</h1><p>提高join操作的效率案例</p>
<blockquote>
<p>如果a表和b表已经是分桶表，而且分桶的字段都是是id字段<br>做这个join操作是，还需要做笛卡尔积吗？ 这样不需要，因为同一id哈希后的数据是一致的，这就是分桶表存在的意义</p>
</blockquote>
<h1 id="注意-1"><a href="#注意-1" class="headerlink" title="注意"></a>注意</h1><ol>
<li>在分桶表中使用order by 是非常不建议的，这样会设置成一个reduce，强行将数据写入，一个reduce的内存会爆炸</li>
<li><p>使用cluster by  就等同于分桶+排序(sort) </p>
<p>insert overwrite table student_buck  select * from student cluster by(Sno) sort by(Sage);  报错,cluster 和 sort 不能共存</p>
</li>
</ol>
</div><div class="tags"><a href="/tags/Hive/">Hive</a></div><div class="post-nav"><a class="pre" href="/2018/08/13/Hive累计报表/">Hive累计报表</a><a class="next" href="/2018/08/11/Hive自定义函数流程/">Hive自定义函数UDF相关</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://gangtieguo.cn"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spark-On-Yarn/">Spark-On-Yarn</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spring/">Spring</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客/">博客</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/安装部署/">安装部署</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/工程框架/">工程框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/快捷键/">快捷键</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/总结/">总结</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/框架/">框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/环境配置/">环境配置</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/碎片知识/">碎片知识</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/组件/">组件</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/语言/">语言</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Mysql/" style="font-size: 15px;">Mysql</a> <a href="/tags/Jenkins/" style="font-size: 15px;">Jenkins</a> <a href="/tags/Ambari/" style="font-size: 15px;">Ambari</a> <a href="/tags/CDH/" style="font-size: 15px;">CDH</a> <a href="/tags/Docker-machine/" style="font-size: 15px;">Docker-machine</a> <a href="/tags/安装部署/" style="font-size: 15px;">安装部署</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/HBase/" style="font-size: 15px;">HBase</a> <a href="/tags/原理/" style="font-size: 15px;">原理</a> <a href="/tags/操作/" style="font-size: 15px;">操作</a> <a href="/tags/HDFS/" style="font-size: 15px;">HDFS</a> <a href="/tags/Shell/" style="font-size: 15px;">Shell</a> <a href="/tags/Hive/" style="font-size: 15px;">Hive</a> <a href="/tags/使用/" style="font-size: 15px;">使用</a> <a href="/tags/报表/" style="font-size: 15px;">报表</a> <a href="/tags/Json/" style="font-size: 15px;">Json</a> <a href="/tags/Scala/" style="font-size: 15px;">Scala</a> <a href="/tags/Kafka/" style="font-size: 15px;">Kafka</a> <a href="/tags/大数据/" style="font-size: 15px;">大数据</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/开发/" style="font-size: 15px;">开发</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Docker/" style="font-size: 15px;">Docker</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/Yarn/" style="font-size: 15px;">Yarn</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/SSH/" style="font-size: 15px;">SSH</a> <a href="/tags/RDD/" style="font-size: 15px;">RDD</a> <a href="/tags/SparkStreaming/" style="font-size: 15px;">SparkStreaming</a> <a href="/tags/SparkSQL/" style="font-size: 15px;">SparkSQL</a> <a href="/tags/ELK/" style="font-size: 15px;">ELK</a> <a href="/tags/es/" style="font-size: 15px;">es</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/命令/" style="font-size: 15px;">命令</a> <a href="/tags/FLINK/" style="font-size: 15px;">FLINK</a> <a href="/tags/Hue/" style="font-size: 15px;">Hue</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/技术/" style="font-size: 15px;">技术</a> <a href="/tags/zk/" style="font-size: 15px;">zk</a> <a href="/tags/快捷键/" style="font-size: 15px;">快捷键</a> <a href="/tags/Mac/" style="font-size: 15px;">Mac</a> <a href="/tags/Idea/" style="font-size: 15px;">Idea</a> <a href="/tags/Finder/" style="font-size: 15px;">Finder</a> <a href="/tags/Other/" style="font-size: 15px;">Other</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(四)Spark业务代码的执行及其任务分配调度stage划分/">Spark-on-Yarn源码解析(四)Spark业务代码的执行及其任务分配调度stage划分</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(三)client做的事情/">Spark-on-Yarn源码解析(三)client做的事情</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(二)Spark-Submit解析/">Spark-on-Yarn源码解析(二)Spark-Submit解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(一)Yarn任务解析/">Spark-on-Yarn源码解析(一)Yarn任务解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/20/MapReduce中Shuffle中的机制/">MapReduce中Shuffle中的机制</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/SparkSQL介绍/">SparkSQL介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/Spark-On-yarn/">Spark-On-Yarn模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/SparkStreaming介绍/">SparkStreaming介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/SparkRDD介绍/">SparkRDD介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/Hadoop零碎知识点/">Hadoop零碎知识点</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">钢铁锅.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>