<!DOCTYPE html>
<html lang=zh>
<head>
    <meta name="baidu-site-verification"content="WHXmBFaAkY"/>
    <meta name="google-site-verification" content="vDyi3jVPymP4jOpfzY4F1zG4-FXD1T-A5unnDJuNxhs" />
    <meta charset="utf-8">
    

    <title>Spark-on-Yarn任务执行流程详解 | 钢铁锅</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="[TOC] 了解spark-on-yarn,首先我们了解一下yarn提交的流程，俗话说，欲练此功，错了，我们还是先看吧 yarn任务的提交YARN 的基本架构和工作流程  YARN 的基本架构如上图所示，由三大功能模块组成，分别是 1) RM (ResourceManager) 2) NM (Node Manager) 3) AM(Application Master)">
<meta name="keywords" content="原理,Spark">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark-on-Yarn任务执行流程详解">
<meta property="og:url" content="http://gangtieguo.cn/2018/08/24/Spark任务执行流程详解/index.html">
<meta property="og:site_name" content="钢铁锅">
<meta property="og:description" content="[TOC] 了解spark-on-yarn,首先我们了解一下yarn提交的流程，俗话说，欲练此功，错了，我们还是先看吧 yarn任务的提交YARN 的基本架构和工作流程  YARN 的基本架构如上图所示，由三大功能模块组成，分别是 1) RM (ResourceManager) 2) NM (Node Manager) 3) AM(Application Master)">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://pebgsxjpj.bkt.clouddn.com/15358192541466.jpg">
<meta property="og:image" content="http://pebgsxjpj.bkt.clouddn.com/15359432887877.jpg">
<meta property="og:updated_time" content="2018-09-04T07:19:29.767Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark-on-Yarn任务执行流程详解">
<meta name="twitter:description" content="[TOC] 了解spark-on-yarn,首先我们了解一下yarn提交的流程，俗话说，欲练此功，错了，我们还是先看吧 yarn任务的提交YARN 的基本架构和工作流程  YARN 的基本架构如上图所示，由三大功能模块组成，分别是 1) RM (ResourceManager) 2) NM (Node Manager) 3) AM(Application Master)">
<meta name="twitter:image" content="http://pebgsxjpj.bkt.clouddn.com/15358192541466.jpg">
    

    

    
        <link rel="icon" href="/css/images/Basketball-icon.png" />
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    
        <script>
var _hmt = _hmt || [];
(function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?e304a23572827f3ea779e13779ddb9b6";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
})();
</script>

    


     <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?e304a23572827f3ea779e13779ddb9b6";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>


</head>

<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">钢铁锅</span>
            </a>
            <nav id="main-nav">
            <a class="main-nav-link" href="/."><i class="fa fa-home"></i>主页</a>
            <a class="main-nav-link" href="/archives"><i class="fa fa-archive"></i>归档</a>
            <a class="main-nav-link" href="/categories"><i class="fa fa-folder"></i>分类</a>
            <a class="main-nav-link" href="/tags"><i class="fa fa-tags"></i>标签</a>
            <a class="main-nav-link" href="/about"><i class="fa fa-user"></i>关于</a>

               <!--   -->
               <!--     <a class="main-nav-link" href="/.">  -->
               <!--     <i class="fa fa-home"></i>  -->
               <!--     主页  -->
               <!--     </a>  -->
               <!--   -->
               <!--     <a class="main-nav-link" href="/archives">  -->
               <!--     <i class="fa fa-home"></i>  -->
               <!--     归档  -->
               <!--     </a>  -->
               <!--   -->
               <!--     <a class="main-nav-link" href="/categories">  -->
               <!--     <i class="fa fa-home"></i>  -->
               <!--     分类  -->
               <!--     </a>  -->
               <!--   -->
               <!--     <a class="main-nav-link" href="/tags">  -->
               <!--     <i class="fa fa-home"></i>  -->
               <!--     标签  -->
               <!--     </a>  -->
               <!--   -->
               <!--     <a class="main-nav-link" href="/about">  -->
               <!--     <i class="fa fa-home"></i>  -->
               <!--     关于  -->
               <!--     </a>  -->
               <!--   -->

            </nav>
            
                
                <nav id="sub-nav">
                    <div class="profile" id="profile-nav">
                        <a id="profile-anchor" href="javascript:;">
                            <img class="avatar" src="/css/images/venum.gif" />
                            <i class="fa fa-caret-down"></i>
                        </a>
                    </div>
                </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
         <!-- <button type="submit" class="search-form-submit"></button> -->
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/.">主页</a></td>
                
                    <td><a class="main-nav-link" href="/archives">归档</a></td>
                
                    <td><a class="main-nav-link" href="/categories">分类</a></td>
                
                    <td><a class="main-nav-link" href="/tags">标签</a></td>
                
                    <td><a class="main-nav-link" href="/about">关于</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
             

                

<aside id="profile" class="profile-fixed">
    <div class="inner profile-inner">
        <div class="base-info profile-block">
            <img id="avatar" src="/css/images/venum.gif" />
            <h2 id="name">GTG</h2>
            <h3 id="title">Nothing</h3>
            <span id="location"><i class="fa fa-map-marker"></i>四海为家</span>
           
        </div>
      <div class="article-info profile-block">
            <div class="article-info-block">
                114
                <span>文章</span>
            </div>
            <div class="article-info-block">
                43
                <span>标签</span>
            </div>
        </div>
        
        <div class="profile-block social-links">
            <table>
                <tr>
                    
                    
                    <td>
                        <a href="https://github.com/yaosong5" target="_blank" title="github" class=tooltip>
                            <i class="fa fa-github"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="https://weibo.com/gangtieguo/" target="_blank" title="weibo" class=tooltip>
                            <i class="fa fa-weibo"></i>
                        </a>
                    </td>
                    
                </tr>
            </table>
        </div>

        
        
    </div>


</aside>


            

            <section id="main"><article id="post-Spark任务执行流程详解" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
            Spark-on-Yarn任务执行流程详解
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2018/08/24/Spark任务执行流程详解/">
            <time datetime="2018-08-23T16:22:57.903Z" itemprop="datePublished">2018-08-24</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/大数据/">大数据</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/Spark/">Spark</a>, <a class="tag-link" href="/tags/原理/">原理</a>
    </div>

                    </div>
                
            </header>
        
       
        
        <div class="article-entry" itemprop="articleBody">
        
            




            <p class="show-toc-btn hidden" id="show-toc-btn" onclick="showToc();">
                    <i class="fa fa-align-justify" aria-hidden="true"></i>
                    <span class="btn-text"> 文章目录</span>
            </p>


            <div id="toc toc-article "  class="toc-article">
                <span id="toc-close" class="toc-close" title="隐藏目录" onclick="showBtn();"><i class="fa fa-times" aria-hidden="true"></i></span>
                <strong class="toc-title">目录</strong>
                <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#yarn任务的提交"><span class="toc-number">1.</span> <span class="toc-text">yarn任务的提交</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ApplicationMaster和Driver的区别"><span class="toc-number">2.</span> <span class="toc-text">ApplicationMaster和Driver的区别</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#spark-submit命令"><span class="toc-number">3.</span> <span class="toc-text">spark-submit命令</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#查看spark-submit脚本"><span class="toc-number">3.1.</span> <span class="toc-text">查看spark-submit脚本</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#org-apache-spark-deploy-yarn-Client"><span class="toc-number">4.</span> <span class="toc-text">org.apache.spark.deploy.yarn.Client</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#小细节用户业务代码信息的封装及流转"><span class="toc-number">4.0.1.</span> <span class="toc-text">小细节用户业务代码信息的封装及流转</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#启动applicationMaster"><span class="toc-number">5.</span> <span class="toc-text">启动applicationMaster</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#程序的细节"><span class="toc-number">5.1.</span> <span class="toc-text">程序的细节</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#分配资源部分"><span class="toc-number">5.2.</span> <span class="toc-text">分配资源部分</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#spark业务代码的执行"><span class="toc-number">6.</span> <span class="toc-text">spark业务代码的执行</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#看看自定义的类"><span class="toc-number">6.1.</span> <span class="toc-text">看看自定义的类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sparkContext的初始化"><span class="toc-number">6.2.</span> <span class="toc-text">sparkContext的初始化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SparkEnv"><span class="toc-number">6.2.1.</span> <span class="toc-text">SparkEnv</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TaskScheduler"><span class="toc-number">6.2.2.</span> <span class="toc-text">TaskScheduler</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#启动TaskScheduler"><span class="toc-number">6.2.2.1.</span> <span class="toc-text">启动TaskScheduler</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DAGScheduler"><span class="toc-number">6.2.3.</span> <span class="toc-text">DAGScheduler</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RDD的构建过程"><span class="toc-number">6.3.</span> <span class="toc-text">RDD的构建过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#作业提交"><span class="toc-number">6.4.</span> <span class="toc-text">作业提交</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#任务流转"><span class="toc-number">6.4.1.</span> <span class="toc-text">任务流转</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#stage-的划分"><span class="toc-number">6.4.2.</span> <span class="toc-text">stage 的划分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TaskScheduler-amp-amp-TaskSchedulerBackend"><span class="toc-number">6.4.3.</span> <span class="toc-text">TaskScheduler &amp;&amp; TaskSchedulerBackend</span></a></li></ol></li></ol></li></ol>
            </div>


            
            <script type="text/javascript">
                            function showBtn(){
                             if($('.toc-article').hasClass('hidden')){
                                    $('.toc-article').removeClass('hidden');
                                }else{
                                    $('.toc-article').addClass('hidden');
                                }
                                 $('.show-toc-btn').removeClass('hidden');  
                            };
                            function showToc(){
                              if($('.show-toc-btn').hasClass('hidden')){
                                      $('.show-toc-btn').removeClass('hidden');


                                  }else{
                                      $('.show-toc-btn').addClass('hidden');

                                  }
                                   $('.toc-article').removeClass('hidden');
                            };
             </script>

                <p>[TOC]</p>
<p>了解spark-on-yarn,首先我们了解一下yarn提交的流程，俗话说，欲练此功，错了，我们还是先看吧</p>
<h1 id="yarn任务的提交"><a href="#yarn任务的提交" class="headerlink" title="yarn任务的提交"></a>yarn任务的提交</h1><p>YARN 的基本架构和工作流程</p>
<p><img src="http://pebgsxjpj.bkt.clouddn.com/15358192541466.jpg" alt=""></p>
<p>YARN 的基本架构如上图所示，由三大功能模块组成，分别是 1) RM (ResourceManager) 2) NM (Node Manager) 3) AM(Application Master)<br><a id="more"></a><br>作业提交</p>
<ol>
<li>用户通过 Client 向 ResourceManager 提交 Application， ResourceManager 根据用户请求分配合适的 Container, 然后在指定的 NodeManager 上运行 Container 以启动 ApplicationMaster</li>
<li>ApplicationMaster 启动完成后，向 ResourceManager 注册自己</li>
<li>对于用户的 Task，ApplicationMaster 需要首先跟 ResourceManager 进行协商以获取运行用户 Task 所需要的 Container，在获取成功后，ApplicationMaster 将任务发送给指定的 NodeManager</li>
<li>NodeManager 启动相应的 Container，并运行用户 Task</li>
</ol>
<blockquote>
<p><a href="https://www.cnblogs.com/hseagle/p/3728713.html" target="_blank" rel="noopener">Spark on Yarn</a></p>
</blockquote>
<p>在 yarn-cluster 模式下，Spark driver 运行在 application master 进程中，这个进程被集群中的 YARN 所管理，客户端会在初始化应用程序 之后关闭。在 yarn-client 模式下，driver 运行在客户端进程中，application master 仅仅用来向 YARN 请求资源</p>
<h1 id="ApplicationMaster和Driver的区别"><a href="#ApplicationMaster和Driver的区别" class="headerlink" title="ApplicationMaster和Driver的区别"></a>ApplicationMaster和Driver的区别</h1><p>首先区分下 AppMaster 和 Driver，任何一个 yarn 上运行的任务都必须有一个 AppMaster，而任何一个 Spark 任务都会有一个 Driver，Driver 就是运行 SparkContext(它会构建 TaskScheduler 和 DAGScheduler) 的进程，当然在 Driver 上你也可以做很多非 Spark 的事情，这些事情只会在 Driver 上面执行，而由 SparkContext 上牵引出来的代码则会由 DAGScheduler 分析，并形成 Job 和 Stage 交由 TaskScheduler，再由 TaskScheduler 交由各 Executor 分布式执行。</p>
<p>所以 Driver 和 AppMaster 是两个完全不同的东西，Driver 是控制 Spark 计算和任务资源的，而 AppMaster 是控制 yarn app 运行和任务资源的，只不过在 Spark on Yarn 上，这两者就出现了交叉，而在 standalone 模式下，资源则由 Driver 管理。在 Spark on Yarn 上，Driver 会和 AppMaster 通信，资源的申请由 AppMaster 来完成，而任务的调度和执行则由 Driver 完成，Driver 会通过与 AppMaster 通信来让 Executor 的执行具体的任务。</p>
<h1 id="spark-submit命令"><a href="#spark-submit命令" class="headerlink" title="spark-submit命令"></a>spark-submit命令</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$SPARK_HOME</span>/bin/spark-submit \</span><br><span class="line">--master yarn \ //提交模式 yarn</span><br><span class="line">--deploy-mode cluster \ //运行的模式，还有一种client模式，但大多用于调试，此处使用cluster模式</span><br><span class="line">--class me.yao.spark.me.yao.spark.WordCount \ //提交的任务</span><br><span class="line">--name <span class="string">"wc"</span> \ //任务名字</span><br><span class="line">--queue root.default \ //提交的队列</span><br><span class="line">--driver-memory 3g \ //为driver申请的内存</span><br><span class="line">--num-executors 1 \ //executors的数量，可以理解为线程数，对应yarn中的Container个数</span><br><span class="line">--executor-memory 6g \ //为每一个executor申请的内存</span><br><span class="line">--executor-cores 4 \ //为每一个executor申请的core</span><br><span class="line">--conf spark.yarn.driver.memoryOverhead=1g \ //driver可使用的非堆内存，这些内存用于如VM，字符 串常量池以及其他额外本地开销等</span><br><span class="line">--conf spark.yarn.executor.memoryOverhead=2g \ //每个executor可使用的非堆内存，这些内存用于如 VM，字符串常量池以及其他额外本地开销等</span><br></pre></td></tr></table></figure>
<p>这是通常我们提交spark程序的submit命令，以此为切入点，对spark程序的运行流程做一个跟踪和分析。</p>
<h2 id="查看spark-submit脚本"><a href="#查看spark-submit脚本" class="headerlink" title="查看spark-submit脚本"></a>查看spark-submit脚本</h2><p>查看spark-submit脚本的信息，初步可以看到submit启动的类为<strong>org.apache.spark.deploy.SparkSubmit</strong>，更多细节其实不重要（开个开玩，极客可以求甚解）如果觉得要深究一下为什么是submit的main方法的可以参考一下<a href="http://flume.cn/2017/02/28/spark-on-yarn-%E4%BD%9C%E4%B8%9A%E6%8F%90%E4%BA%A4%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" target="_blank" rel="noopener">spark on yarn 作业提交源码分析</a><br><img src="http://pebgsxjpj.bkt.clouddn.com/15359432887877.jpg" alt=""><br>接下来查看该类内部的处理逻辑<br>SparkSumbmit的类（为了简洁和文章篇幅，只保留了关键流程的信息）</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> appArgs = <span class="keyword">new</span> <span class="type">SparkSubmitArguments</span>(args)</span><br><span class="line">    <span class="keyword">if</span> (appArgs.verbose) &#123;</span><br><span class="line">      printStream.println(appArgs)</span><br><span class="line">    &#125;</span><br><span class="line">    appArgs.action <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">SUBMIT</span> =&gt; submit(appArgs)</span><br><span class="line">      <span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">KILL</span> =&gt; kill(appArgs)</span><br><span class="line">      <span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">REQUEST_STATUS</span> =&gt; requestStatus(appArgs)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span>[spark] <span class="function"><span class="keyword">def</span> <span class="title">submit</span></span>(args: <span class="type">SparkSubmitArguments</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> (childArgs, childClasspath, sysProps, childMainClass) = </span><br><span class="line">prepareSubmitEnvironment(args)</span><br><span class="line">.....</span><br><span class="line">.....</span><br><span class="line"> runMain(childArgs, childClasspath, sysProps, childMainClass, args.verbose)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>[spark] <span class="function"><span class="keyword">def</span> <span class="title">prepareSubmitEnvironment</span></span>(args: <span class="type">SparkSubmitArguments</span>)</span><br><span class="line">      : (<span class="type">Seq</span>[<span class="type">String</span>], <span class="type">Seq</span>[<span class="type">String</span>], <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>], <span class="type">String</span>) = &#123;</span><br><span class="line">      ......</span><br><span class="line">      <span class="comment">// In yarn-cluster mode, use yarn.Client as a wrapper around the user class</span></span><br><span class="line">    <span class="keyword">if</span> (isYarnCluster) &#123;</span><br><span class="line">      childMainClass = <span class="string">"org.apache.spark.deploy.yarn.Client"</span></span><br><span class="line">      .......</span><br><span class="line">      &#125;</span><br><span class="line"><span class="comment">//在submit方法中最终调用的是</span></span><br><span class="line">runMain(childArgs, childClasspath, sysProps, childMainClass, args.verbose)</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">      mainClass = <span class="type">Class</span>.forName(childMainClass, <span class="literal">true</span>, loader)</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    ......</span><br><span class="line">    <span class="type">System</span>.exit(<span class="type">CLASS_NOT_FOUND_EXIT_STATUS</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// SPARK-4170</span></span><br><span class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">runMain</span></span>(</span><br><span class="line">      childArgs: <span class="type">Seq</span>[<span class="type">String</span>],</span><br><span class="line">      childClasspath: <span class="type">Seq</span>[<span class="type">String</span>],</span><br><span class="line">      sysProps: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>],</span><br><span class="line">      childMainClass: <span class="type">String</span>,</span><br><span class="line">      verbose: <span class="type">Boolean</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    ... ...</span><br><span class="line">    </span><br><span class="line">    mainClass = <span class="type">Class</span>.forName(childMainClass, <span class="literal">true</span>, loader)</span><br><span class="line">    ... ...</span><br><span class="line">    <span class="keyword">val</span> mainMethod = mainClass.getMethod(<span class="string">"main"</span>, <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">String</span>](<span class="number">0</span>).getClass)</span><br><span class="line">    ... ...</span><br><span class="line">    mainMethod.invoke(<span class="literal">null</span>, childArgs.toArray)</span><br><span class="line">    ... ...</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>通过上面的流程可以看到，这样一个调用链(未特殊表明类名，表明为该步上一步的同一类)，我们代码简化一下，看得舒心明了，再配上解说</p>
<pre><code>submit.main()
    -&gt;submit()模式匹配到该方法，因为我们就是submit提交任务
        -&gt;prepareSubmitEnvironment()该方法中指明了要启动的类，就是大明湖畔的Client
        -&gt;runMain()通过上步指定的类，然后通过反射调用main方法
</code></pre><p>既然我们的线路走到<code>org.apache.spark.deploy.yarn.Client</code>        ，那我们再去这个类一看究竟</p>
<h1 id="org-apache-spark-deploy-yarn-Client"><a href="#org-apache-spark-deploy-yarn-Client" class="headerlink" title="org.apache.spark.deploy.yarn.Client"></a>org.apache.spark.deploy.yarn.Client</h1><p>话不多说，先上源码，当然还是简洁版本的<br>这儿我先上一下最简洁的调用链。</p>
<pre><code>Client.main()
    -&gt;new Client().run()
         -&gt;monitorApplication(submitApplication())
            -&gt;submitApplication()
                -&gt;createContainerLaunchContext()会封装一些启动信息如我们启动的类 --class
                    -&gt;userClass
                    -&gt;amArgs
                    -&gt;commands
                    -&gt;printableCommands
                    -&gt;amClass applicationMaster启动的真实类

                -&gt;createApplicationSubmissionContext()
                    -&gt;Records.newRecord(classOf[Resource])启动
                -&gt;yarnClientImpl.submitApplication(appContext)
</code></pre><p>最终是调用的client里面main方法-&gt;run-&gt;<br>monitorApplication(submitApplication())</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Client</span> <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(argStrings: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    ... ...</span><br><span class="line">    <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span></span><br><span class="line">    <span class="keyword">val</span> args = <span class="keyword">new</span> <span class="type">ClientArguments</span>(argStrings, sparkConf)</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Client</span>(args, sparkConf).run()</span><br><span class="line">    ... ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">... ...</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> (yarnApplicationState, finalApplicationStatus) = monitorApplication(submitApplication())</span><br><span class="line">    &#125;</span><br><span class="line">... ...</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">submitApplication</span></span>(): <span class="type">ApplicationId</span> = &#123;</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> 初始化并且启动client</span></span><br><span class="line">    yarnClient.init(yarnConf)</span><br><span class="line">    yarnClient.start()</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> 准备提交请求到resouceManager</span></span><br><span class="line">    <span class="keyword">val</span> newApp = yarnClient.createApplication()</span><br><span class="line">    <span class="keyword">val</span> newAppResponse = newApp.getNewApplicationResponse()</span><br><span class="line">    <span class="keyword">val</span> appId = newAppResponse.getApplicationId()</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> 检查集群的内存是否满足当前的任务要求</span></span><br><span class="line">    verifyClusterResources(newAppResponse)</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span>  设置适当上下文环境来启动applicationMaster</span></span><br><span class="line">    <span class="keyword">val</span> containerContext = createContainerLaunchContext(newAppResponse)</span><br><span class="line">    <span class="keyword">val</span> appContext = createApplicationSubmissionContext(newApp, containerContext)</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> 提交application</span></span><br><span class="line">    yarnClient.submitApplication(appContext)</span><br><span class="line">    appId</span><br><span class="line">  &#125;</span><br><span class="line">   <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">createContainerLaunchContext</span></span>(newAppResponse: <span class="type">GetNewApplicationResponse</span>)</span><br><span class="line">    : <span class="type">ContainerLaunchContext</span> = &#123;</span><br><span class="line">    ... ...</span><br><span class="line">          <span class="keyword">val</span> userClass =</span><br><span class="line">      <span class="keyword">if</span> (isClusterMode) &#123;</span><br><span class="line">        <span class="type">Seq</span>(<span class="string">"--class"</span>, <span class="type">YarnSparkHadoopUtil</span>.escapeForShell(args.userClass))</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="type">Nil</span></span><br><span class="line">      &#125;</span><br><span class="line">      ...</span><br><span class="line">       <span class="keyword">val</span> amClass =</span><br><span class="line">      <span class="keyword">if</span> (isClusterMode) &#123;</span><br><span class="line"><span class="type">Class</span>.forName(<span class="string">"org.apache.spark.deploy.yarn.ApplicationMaster"</span>).getName</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="type">Class</span>.forName(<span class="string">"org.apache.spark.deploy.yarn.ExecutorLauncher"</span>).getName</span><br><span class="line">      &#125;</span><br><span class="line">          <span class="keyword">val</span> amArgs =</span><br><span class="line">      <span class="type">Seq</span>(amClass) ++ userClass ++ userJar ++ primaryPyFile ++ pyFiles ++ userArgs ++</span><br><span class="line">        <span class="type">Seq</span>(</span><br><span class="line">          <span class="string">"--executor-memory"</span>, args.executorMemory.toString + <span class="string">"m"</span>,</span><br><span class="line">          <span class="string">"--executor-cores"</span>, args.executorCores.toString,</span><br><span class="line">          <span class="string">"--num-executors "</span>, args.numExecutors.toString)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> commands = prefixEnv ++ <span class="type">Seq</span>(<span class="type">YarnSparkHadoopUtil</span>.expandEnvironment(<span class="type">Environment</span>.<span class="type">JAVA_HOME</span>) + <span class="string">"/bin/java"</span>, <span class="string">"-server"</span></span><br><span class="line">      ) ++</span><br><span class="line">      javaOpts ++ amArgs ++</span><br><span class="line">    ... ...</span><br><span class="line">     <span class="keyword">val</span> printableCommands = commands.map(s =&gt; <span class="keyword">if</span> (s == <span class="literal">null</span>) <span class="string">"null"</span> <span class="keyword">else</span> s).toList</span><br><span class="line">    amContainer.setCommands(printableCommands)</span><br><span class="line">    &#125;</span><br><span class="line">    ... ...</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createApplicationSubmissionContext</span></span>(</span><br><span class="line">      newApp: <span class="type">YarnClientApplication</span>,</span><br><span class="line">      containerContext: <span class="type">ContainerLaunchContext</span>): <span class="type">ApplicationSubmissionContext</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> appContext = newApp.getApplicationSubmissionContext</span><br><span class="line">    appContext.setApplicationName(args.appName)</span><br><span class="line">    appContext.setQueue(args.amQueue)</span><br><span class="line">    appContext.setAMContainerSpec(containerContext)</span><br><span class="line">    appContext.setApplicationType(<span class="string">"SPARK"</span>)</span><br><span class="line">    sparkConf.getOption(<span class="string">"spark.yarn.maxAppAttempts"</span>).map(_.toInt) <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Some</span>(v) =&gt; appContext.setMaxAppAttempts(v)</span><br><span class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; logDebug(<span class="string">"spark.yarn.maxAppAttempts is not set. "</span> +</span><br><span class="line">          <span class="string">"Cluster's default value will be used."</span>)</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line">    <span class="keyword">val</span> capability = <span class="type">Records</span>.newRecord(classOf[<span class="type">Resource</span>])</span><br><span class="line">    capability.setMemory(args.amMemory + amMemoryOverhead)</span><br><span class="line">    capability.setVirtualCores(args.amCores)</span><br><span class="line">    appContext.setResource(capability)</span><br><span class="line">    appContext</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//yarnClient.submitApplication(appContext)提交的真实处  </span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line">  public <span class="type">ApplicationId</span></span><br><span class="line">      submitApplication(<span class="type">ApplicationSubmissionContext</span> appContext)</span><br><span class="line">          <span class="keyword">throws</span> <span class="type">YarnException</span>, <span class="type">IOException</span> &#123;</span><br><span class="line">...</span><br><span class="line"><span class="comment">//此处通过yarn的协议对applicationMaster进行提交和启动 （此处为个人理解有疑惑，如有错误，还望留言分享，会立即作出更正）</span></span><br><span class="line">    <span class="type">SubmitApplicationRequest</span> request =</span><br><span class="line">        <span class="type">Records</span>.newRecord(<span class="type">SubmitApplicationRequest</span>.<span class="keyword">class</span>);</span><br><span class="line">    request.setApplicationSubmissionContext(appContext);</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>此处client的事情都已经做完了，请摄影师将镜头切换到applicationMaster</p>
<h3 id="小细节用户业务代码信息的封装及流转"><a href="#小细节用户业务代码信息的封装及流转" class="headerlink" title="小细节用户业务代码信息的封装及流转"></a>小细节用户业务代码信息的封装及流转</h3><p>我们提交的class的封装流程</p>
<pre><code>-&gt;sublimit的prepareSubmitEnvironment中封装到childArgs中--class
-&gt;传入到client的构造函数里面作为clientArgs，将其封装到userClass属性里面

在submitApplication中createContainerLaunchContext会将其通过重新封到userClass
    userClass-&gt;amArgs-&gt;commands-&gt;printableCommands
    -&gt;amContainer.setCommands(printableCommands)
    在此，createContainerLaunchContext方法接收到amContainer赋名为containerContext传递给createApplicationSubmissionContext(..,containerContext)

那么在createApplicationSubmissionContext中又有哪些惊天变化（其实并没有）

appContext.setAMContainerSpec(containerContext)
那么appContext作为createApplicationSubmissionContext方法返回值，由appContext接收，看码

appContext = createApplicationSubmissionContext(newApp, containerContext)
最后，由yarnClientImpl提交
yarnClient.submitApplication(appContext)
码又来了，最终执行的是
SubmitApplicationRequest request =Records.newRecord(SubmitApplicationRequest.class);
</code></pre><h1 id="启动applicationMaster"><a href="#启动applicationMaster" class="headerlink" title="启动applicationMaster"></a>启动applicationMaster</h1><p>对于client的封装，对于applicationMaster需要启动的信息(如资源信息)及用户提交的业务代码（wordcount的类信息）信息都已经封装到appContext，并且传递到applicationmaster，那么来看看applicationMaster的执行流程。<br>程序调用结构</p>
<pre><code>ApplicationMaster.main()
    -&gt;run()
        -&gt;runDriver()
            -&gt;run()
                -&gt;startUserApplication()
                    //启动userClass
                    -&gt;userClassLoader.loadClass(args.userClass)
      .getMethod(&quot;main&quot;, classOf[Array[String]])
                     -&gt;mainMethod.invoke(null, mainArgs)
                runAMActor()
                registerAM()
                    -&gt;yarnRmClient.register()-&gt;return new YarnAllocater(......)
                    -&gt;yarnAllocator.allocateResources()
                        -&gt;yarnAllocator.handleAllocatedContainers()
                        //启动executor
                        -&gt;yarnAllocator.runAllocatedContainers(containersToUse)
</code></pre><p>runAllocatedContainers(containersToUse)是去启动 executor，最终真正执行启动Container的是在 ExecutorRunnable.run()中。<br>创建了 NMClient 客户端调用提供的 API 最终实现在 NM 上启动 Container，<strong>具体如何启动 Container 将在后文中进行介绍。</strong></p>
<p>launcherPool线程池会将container，driver等相关信息封装成ExecutorRunnable对象，通过ExecutorRunnable启动新的container以运行executor。在此过程中，指定启动executor的类是<br>org.apache.spark.executor.CoarseGrainedExecutorBackend。<a href="https://www.cnblogs.com/superhedantou/p/7688367.html" target="_blank" rel="noopener">spark yarn cluster 模式下任务提交和计算流程分析</a></p>
<h2 id="程序的细节"><a href="#程序的细节" class="headerlink" title="程序的细节"></a>程序的细节</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) = &#123;</span><br><span class="line">    <span class="type">SignalLogger</span>.register(log)</span><br><span class="line">    <span class="keyword">val</span> amArgs = <span class="keyword">new</span> <span class="type">ApplicationMasterArguments</span>(args)</span><br><span class="line">    <span class="type">SparkHadoopUtil</span>.get.runAsSparkUser &#123; () =&gt;</span><br><span class="line">      master = <span class="keyword">new</span> <span class="type">ApplicationMaster</span>(amArgs, <span class="keyword">new</span> <span class="type">YarnRMClient</span>(amArgs))</span><br><span class="line">      <span class="type">System</span>.exit(master.run())</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">  ......</span><br><span class="line">  <span class="keyword">final</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Int</span> = &#123;</span><br><span class="line">  ....</span><br><span class="line">    <span class="keyword">if</span> (isClusterMode) &#123;</span><br><span class="line">        runDriver(securityMgr)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        runExecutorLauncher(securityMgr)</span><br><span class="line">      &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">runDriver</span></span>(securityMgr: <span class="type">SecurityManager</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    addAmIpFilter()</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span>  启动我们自定的类，也就是启动submit里面的--class的东西</span></span><br><span class="line">    userClassThread = startUserApplication()</span><br><span class="line">    <span class="keyword">val</span> sc = waitForSparkContextInitialized()</span><br><span class="line">...</span><br><span class="line">  actorSystem = sc.env.actorSystem</span><br><span class="line">  runAMActor(</span><br><span class="line">    sc.getConf.get(<span class="string">"spark.driver.host"</span>),</span><br><span class="line">    sc.getConf.get(<span class="string">"spark.driver.port"</span>),</span><br><span class="line">    isClusterMode = <span class="literal">true</span>)</span><br><span class="line">  registerAM(sc.ui.map(_.appUIAddress).getOrElse(<span class="string">""</span>), securityMgr)</span><br><span class="line">  userClassThread.join()</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>在ApplicationMasterArguments设置了要启动的信息</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ApplicationMasterArguments</span>(<span class="params">val args: <span class="type">Array</span>[<span class="type">String</span>]</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> userJar: <span class="type">String</span> = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">var</span> userClass: <span class="type">String</span> = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">var</span> primaryPyFile: <span class="type">String</span> = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">var</span> pyFiles: <span class="type">String</span> = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">var</span> userArgs: <span class="type">Seq</span>[<span class="type">String</span>] = <span class="type">Seq</span>[<span class="type">String</span>]()</span><br><span class="line">  <span class="keyword">var</span> executorMemory = <span class="number">1024</span></span><br><span class="line">  <span class="keyword">var</span> executorCores = <span class="number">1</span></span><br><span class="line">  <span class="keyword">var</span> numExecutors = <span class="type">DEFAULT_NUMBER_EXECUTORS</span></span><br><span class="line">  ......</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>startUserApplication 主要执行了调用用户的代码，以及创建了一个 spark driver 的进程。<br>Start the user class, which contains the spark driver, in a separate Thread.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">startUserApplication</span></span>(): <span class="type">Thread</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> classpath = <span class="type">Client</span>.getUserClasspath(sparkConf)</span><br><span class="line"><span class="keyword">val</span> urls = classpath.map &#123; entry =&gt;</span><br><span class="line">  <span class="keyword">new</span> <span class="type">URL</span>(<span class="string">"file:"</span> + <span class="keyword">new</span> <span class="type">File</span>(entry.getPath()).getAbsolutePath())</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">val</span> userClassLoader =</span><br><span class="line">...</span><br><span class="line"><span class="comment">// <span class="doctag">TODO:</span>  userClass就是submit里面的--class 提交的类</span></span><br><span class="line"><span class="keyword">val</span> mainMethod = userClassLoader.loadClass(args.userClass)</span><br><span class="line">  .getMethod(<span class="string">"main"</span>, classOf[<span class="type">Array</span>[<span class="type">String</span>]])</span><br><span class="line">userThread.setContextClassLoader(userClassLoader)</span><br><span class="line">userThread.setName(<span class="string">"Driver"</span>)</span><br><span class="line">userThread.start()</span><br><span class="line">userThread</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从<code>userThread.setName(&quot;Driver&quot;)</code>也可以看出创建的是名为driver的进程</p>
<p>registerAM 向 resourceManager 中正式注册 applicationMaster。注册applicationMaster 以后，并且分配资源，这样，用户代码就可以执行了，任务切分、调度、执行。</p>
<p>然后，用户代码中的 action 会调用 SparkContext 的 runJob，SparkContext 中有很多个 runJob，但最后都是调用 DAGScheduler 的 runJob</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">  <span class="comment">// registerAM</span></span><br><span class="line">   <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">registerAM</span></span>(uiAddress: <span class="type">String</span>, securityMgr: <span class="type">SecurityManager</span>) = &#123;</span><br><span class="line">   .....</span><br><span class="line">  allocator = client.register(yarnConf,</span><br><span class="line">    <span class="keyword">if</span> (sc != <span class="literal">null</span>) sc.getConf <span class="keyword">else</span> sparkConf,</span><br><span class="line">    <span class="keyword">if</span> (sc != <span class="literal">null</span>) sc.preferredNodeLocationData <span class="keyword">else</span> <span class="type">Map</span>(),</span><br><span class="line">    uiAddress,</span><br><span class="line">    historyAddress,</span><br><span class="line">    securityMgr)</span><br><span class="line">    <span class="comment">//为exector分配资源</span></span><br><span class="line">  allocator.allocateResources()</span><br><span class="line">  reporterThread = launchReporterThread()</span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="分配资源部分"><a href="#分配资源部分" class="headerlink" title="分配资源部分"></a>分配资源部分</h2><h1 id="spark业务代码的执行"><a href="#spark业务代码的执行" class="headerlink" title="spark业务代码的执行"></a>spark业务代码的执行</h1><h2 id="看看自定义的类"><a href="#看看自定义的类" class="headerlink" title="看看自定义的类"></a>看看自定义的类</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"yaoWordCount"</span>).setMaster(<span class="string">"local[2]"</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="keyword">var</span> hadoopRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(args(<span class="number">0</span>))</span><br><span class="line">    <span class="keyword">var</span> hdfsRDD: <span class="type">RDD</span>[<span class="type">String</span>] = hadoopRDD.flatMap(_.split(<span class="string">""</span>))</span><br><span class="line">    <span class="comment">//单词和出现的次数，构建RDD并且调用了他的Transformation</span></span><br><span class="line">    <span class="comment">//返回的是一个hadoopRDD</span></span><br><span class="line">    <span class="comment">//transFormation都是返回的RDD</span></span><br><span class="line">    <span class="keyword">var</span> wordAndCount: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = hdfsRDD.map((_, <span class="number">1</span>))</span><br><span class="line">    <span class="comment">//创建RDD 这里面有两个RDD,一个是hadoopRDD，然后会生成一个paritionRDD</span></span><br><span class="line">    <span class="comment">//savaasTextfile还会产生一个RDD,因为会调用mapPartitons</span></span><br><span class="line">    <span class="comment">//调用RDD的action 开始真正提交任务</span></span><br><span class="line">    <span class="keyword">var</span> reducedRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordAndCount.reduceByKey(_ + _)</span><br><span class="line">    reducedRDD.saveAsTextFile(args(<span class="number">1</span>))</span><br><span class="line">    <span class="comment">//关闭saprkContext资源</span></span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="sparkContext的初始化"><a href="#sparkContext的初始化" class="headerlink" title="sparkContext的初始化"></a>sparkContext的初始化</h2><p>对于Spark程序入口为SparkContext,当我们使用spark-submit/spark-shell等命令来启动一个客户端,客户端与集群需要建立链接，建立的这个链接对象就叫做sparkContext，只有这个对象创建成功才标志这这个客户端与spark集群链接成功。现就将从SparkContext展开来描述一下Spark的任务启动和执行流程。<br>SparkContext 完成了以下几个主要的功能：<br>（1）创建 RDD，通过类似 textFile 等的方法。<br>（2）与资源管理器交互，通过 runJob 等方法启动应用。<br>（3）创建 DAGScheduler、TaskScheduler 等。 </p>
<p>在SparkContext类中，SparkContext主构造器主要做</p>
<p>我们看一下SparkContext的主构造器</p>
<ul>
<li>调用CreateSparkEnv方法创建SparkEnv(将driver的信息，url，ip等都封装)，SparkEnv中有一个对象ActorSystem</li>
<li>创建TaskScheduler ，根据提交任务的URL（如：spark://(.*)”，local[1]等，去创建TaskSchedulerImpl ，然后再创建SparkDeploySchedulerBackend(先后创建driverActor和clientActor)</li>
<li>创建DAGScheduler</li>
<li>TaskScheduler启动，TaskScheduler.start()</li>
</ul>
<h3 id="SparkEnv"><a href="#SparkEnv" class="headerlink" title="SparkEnv"></a>SparkEnv</h3><p>最终将driver的host,port端口等各种信息都封装到里面</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> <span class="type">SparkEnv</span>(</span><br><span class="line">  executorId,</span><br><span class="line">  actorSystem,</span><br><span class="line">  serializer,</span><br><span class="line">  closureSerializer,</span><br><span class="line">  cacheManager,</span><br><span class="line">  mapOutputTracker,</span><br><span class="line">  shuffleManager,</span><br><span class="line">  broadcastManager,</span><br><span class="line">  blockTransferService,</span><br><span class="line">  blockManager,</span><br><span class="line">  securityManager,</span><br><span class="line">  httpFileServer,</span><br><span class="line">  sparkFilesDir,</span><br><span class="line">  metricsSystem,</span><br><span class="line">  shuffleMemoryManager,</span><br><span class="line">  outputCommitCoordinator,</span><br><span class="line">  conf)</span><br></pre></td></tr></table></figure>
<h3 id="TaskScheduler"><a href="#TaskScheduler" class="headerlink" title="TaskScheduler"></a>TaskScheduler</h3><p>在SparkContext类中可以看到，TaskScheduler根据url类型匹配创建TaskSchedulerImpl</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">//TODO 根据提交任务时指定的URL创建相应的TaskScheduler</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">createTaskScheduler</span></span>(</span><br><span class="line">      sc: <span class="type">SparkContext</span>,</span><br><span class="line">      master: <span class="type">String</span>): (<span class="type">SchedulerBackend</span>, <span class="type">TaskScheduler</span>) = &#123;</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">case</span> <span class="string">"yarn-standalone"</span> | <span class="string">"yarn-cluster"</span> =&gt;</span><br><span class="line">...</span><br><span class="line">        <span class="keyword">val</span> scheduler = <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="keyword">val</span> clazz = <span class="type">Class</span>.forName(<span class="string">"org.apache.spark.scheduler.cluster.YarnClusterScheduler"</span>)</span><br><span class="line">          <span class="keyword">val</span> cons = clazz.getConstructor(classOf[<span class="type">SparkContext</span>])</span><br><span class="line">          cons.newInstance(sc).asInstanceOf[<span class="type">TaskSchedulerImpl</span>]</span><br><span class="line">          &#125;</span><br><span class="line">      ...</span><br><span class="line">        <span class="keyword">val</span> backend = <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="keyword">val</span> clazz =</span><br><span class="line">            <span class="type">Class</span>.forName(<span class="string">"org.apache.spark.scheduler.cluster.YarnClusterSchedulerBackend"</span>)</span><br><span class="line">          <span class="keyword">val</span> cons = clazz.getConstructor(classOf[<span class="type">TaskSchedulerImpl</span>], classOf[<span class="type">SparkContext</span>])</span><br><span class="line">          cons.newInstance(scheduler, sc).asInstanceOf[<span class="type">CoarseGrainedSchedulerBackend</span>]</span><br><span class="line">        &#125; </span><br><span class="line">        scheduler.initialize(backend)</span><br><span class="line">        (backend, scheduler)</span><br><span class="line">        ....</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<p>可知<br>TaskScheduler 的实现类<code>org.apache.spark.scheduler.cluster.YarnScheduler</code><br>TaskSchedulerBacked 的实现类为<code>org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend</code><br>且TaskScheduler对TaskSchedulerBacked保持了引用<br>scheduler.initialize(backend)</p>
<h4 id="启动TaskScheduler"><a href="#启动TaskScheduler" class="headerlink" title="启动TaskScheduler"></a>启动TaskScheduler</h4><p>在Spark的构造函数中,会启动TaskScheduler</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">taskScheduler.start()</span><br></pre></td></tr></table></figure>
<p>可以看到继承关系</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">YarnClusterScheduler</span>(<span class="params">sc: <span class="type">SparkContext</span></span>) <span class="keyword">extends</span> <span class="title">YarnScheduler</span>(<span class="params">sc</span>) </span></span><br><span class="line"><span class="class"><span class="title">private</span>[spark] <span class="title">class</span> <span class="title">YarnScheduler</span>(<span class="params">sc: <span class="type">SparkContext</span></span>) <span class="keyword">extends</span> <span class="title">TaskSchedulerImpl</span>(<span class="params">sc</span>)</span></span><br></pre></td></tr></table></figure>
<p>可以跟踪到，start方法最终调用的是TaskSchedulerImpl里面start方法，在start方法里面</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">start</span></span>() &#123;</span><br><span class="line">    <span class="comment">//TODO 首先调用SparkDeploySchedulerBackend的start方法</span></span><br><span class="line">    backend.start()</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>,这里的backend就是YarnClusterSchedulerBackend，而这个最终继承的是CoarseGrainedSchedulerBackend中start方法</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">start</span></span>() &#123;</span><br><span class="line">...</span><br><span class="line">  driverActor = actorSystem.actorOf(</span><br><span class="line">    <span class="type">Props</span>(<span class="keyword">new</span> <span class="type">DriverActor</span>(properties)), name = <span class="type">CoarseGrainedSchedulerBackend</span>.<span class="type">ACTOR_NAME</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>获取到spark的配置信息后，会创建driverActor</p>
<h3 id="DAGScheduler"><a href="#DAGScheduler" class="headerlink" title="DAGScheduler"></a>DAGScheduler</h3><p>在SparkContext的构造函数中，会创建DAGScheduler</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dagScheduler= <span class="keyword">new</span> <span class="type">DAGScheduler</span>(<span class="keyword">this</span>)</span><br></pre></td></tr></table></figure>
<p>在DAGScheduler构造函数中</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(sc: <span class="type">SparkContext</span>) = <span class="keyword">this</span>(sc, sc.taskScheduler)</span><br></pre></td></tr></table></figure>
<p>可以看到DAGScheduler对TaskScheduler保持了引用</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DAGScheduler</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    private[scheduler] val sc: <span class="type">SparkContext</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    private[scheduler] val taskScheduler: <span class="type">TaskScheduler</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    listenerBus: <span class="type">LiveListenerBus</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    mapOutputTracker: <span class="type">MapOutputTrackerMaster</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    blockManagerMaster: <span class="type">BlockManagerMaster</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    env: <span class="type">SparkEnv</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    clock: <span class="type">Clock</span> = new <span class="type">SystemClock</span>(</span>))</span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  ......</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>mapOutputTracker：是运行在 Driver 端管理 shuffle 的中间输出位置信息的。 </li>
<li>blockManagerMaster：也是运行在 Driver 端的，它是管理整个 Job 的 Bolck 信息。</li>
</ul>
<h2 id="RDD的构建过程"><a href="#RDD的构建过程" class="headerlink" title="RDD的构建过程"></a>RDD的构建过程</h2><p>其中hadoopRDD，hdfsRDD，wordRDD，reduceRDD是经过一系列transformation装换rdd，只有等到action时，才会触发数据的流转</p>
<p>该例的action为saveAsTextFile调用链为</p>
<pre><code>saveAsTextFile()
    saveAsHadoopFile()
         saveAsHadoopFile（重载函数）
                 saveAsHadoopDataset()
                     runJob()之间会调用几个重载函数
                     dagScheduler.runJob()最终调用
</code></pre><h2 id="作业提交"><a href="#作业提交" class="headerlink" title="作业提交"></a>作业提交</h2><h3 id="任务流转"><a href="#任务流转" class="headerlink" title="任务流转"></a>任务流转</h3><p>首先注意区分 2 个概述：<br>job: 每个 action 都是执行 runJob 方法，可以将之视为一个 job。<br>stage：在这个 job 内部，会根据宽依赖，划分成多个 stage。</p>
<p>在action触发后，最最终调用的是DAGScheduler.runJob()</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dagScheduler.runJob(rdd, cleanedFunc, partitions, callSite, resultHandler, localProperties.get)</span><br></pre></td></tr></table></figure>
<p>而runJob() 的核心代码为：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> waiter = submitJob(rdd, func, partitions, callSite, resultHandler, properties)</span><br></pre></td></tr></table></figure>
<p>即调用 submitJob 方法，我们进一步看看 submitJob()</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">submitJob</span></span>[<span class="type">T</span>, <span class="type">U</span>](</span><br><span class="line">      rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">      func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</span><br><span class="line">      partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</span><br><span class="line">      callSite: <span class="type">CallSite</span>,</span><br><span class="line">      resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>,</span><br><span class="line">      properties: <span class="type">Properties</span>): <span class="type">JobWaiter</span>[<span class="type">U</span>] = &#123;</span><br><span class="line">....    </span><br><span class="line">    <span class="keyword">val</span> jobId = nextJobId.getAndIncrement()</span><br><span class="line">.....</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> waiter = <span class="keyword">new</span> <span class="type">JobWaiter</span>(<span class="keyword">this</span>, jobId, partitions.size, resultHandler)</span><br><span class="line">    eventProcessLoop.post(<span class="type">JobSubmitted</span>(</span><br><span class="line">      jobId, rdd, func2, partitions.toArray, callSite, waiter,</span><br><span class="line">      <span class="type">SerializationUtils</span>.clone(properties)))</span><br><span class="line">    waiter</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>submitJob() 方法主要完成了以下 3 个工作： </p>
<ul>
<li>获取一个新的 jobId </li>
<li>生成一个 JobWaiter，它会监听 Job 的执行状态，而 Job 是由多个 Task 组成的，因此只有当 Job 的所有 Task 均已完成，Job 才会标记成功 </li>
<li>最后调用 eventProcessLoop.post() 将 Job 提交到一个队列中，等待处理。这是一个典型的生产者消费者模式。这些消息都是通过 handleJobSubmitted 来处理。</li>
</ul>
<p>简单看一下 handleJobSubmitted 是如何被调用的。<br>首先是 DAGSchedulerEventProcessLoop#onReceive 调用 </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//TODO 通过模式匹配判断事件的类型 比如任务提交，作业取消 ...</span></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onReceive</span></span>(event: <span class="type">DAGSchedulerEvent</span>): <span class="type">Unit</span> = event <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="comment">//TODO 提交计算任务</span></span><br><span class="line">  <span class="keyword">case</span> <span class="type">JobSubmitted</span>(jobId, rdd, func, partitions, allowLocal, callSite, listener, properties) =&gt;</span><br><span class="line">    <span class="comment">//todo 调用dagScheduler的handlerJobSubmitted方法处理</span></span><br><span class="line">    dagScheduler.handleJobSubmitted(jobId, rdd, func, partitions, allowLocal, callSite,  listener, properties)</span><br><span class="line">  ... ...</span><br></pre></td></tr></table></figure>
<p>DAGSchedulerEventProcessLoop 是 EventLoop 的子类，它重写了 EventLoop 的 onReceive 方法。以后再分析这个 EventLoop。<br>onReceive 会调用 handleJobSubmitted。</p>
<h3 id="stage-的划分"><a href="#stage-的划分" class="headerlink" title="stage 的划分"></a>stage 的划分</h3><p>刚才说到 handleJobSubmitted 会从 eventProcessLoop 中取出 Job 来进行处理，处理的第一步就是将 Job 划分成不同的 stage。handleJobSubmitted 主要 2 个工作，一是进行 stage 的划分，这是这部分要介绍的内容；二是创建一个 activeJob，并生成一个任务，这在下一小节介绍。</p>
<p>还是先看看调用链</p>
<pre><code>handleJobSubmitted
    -&gt;newStage()
      -&gt;getParentStages()//此处会遍历RDD所有依赖
         -&gt;getShuffleMapStage()//如果是ShuffleDependency（宽依赖，获取到一个Map）
             -&gt;newOrUsedStage()//这就可以解释我们常说的遇到宽依赖就会划分stage，并且返回stage                
</code></pre><p>所以最终返回的是一个拥有款依赖的           </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[scheduler] <span class="function"><span class="keyword">def</span> <span class="title">handleJobSubmitted</span></span>(jobId: <span class="type">Int</span>,</span><br><span class="line">    finalRDD: <span class="type">RDD</span>[_],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _,</span><br><span class="line">    partitions: <span class="type">Array</span>[<span class="type">Int</span>],</span><br><span class="line">    callSite: <span class="type">CallSite</span>,</span><br><span class="line">    listener: <span class="type">JobListener</span>,</span><br><span class="line">    properties: <span class="type">Properties</span>) &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">//todo 重要：该方法用于划分stage，主要依赖的是finalStage</span></span><br><span class="line">     finalStage = newStage(finalRDD, partitions.size, <span class="type">None</span>, jobId, callSite)</span><br><span class="line">    .....</span><br><span class="line">  <span class="comment">//TODO 集群模式</span></span><br><span class="line">    activeJobs += job</span><br><span class="line">    ......</span><br><span class="line">  <span class="comment">//todo 提交stage</span></span><br><span class="line">    submitStage(finalStage)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//TODO  开始向集群提交还在等待的stage</span></span><br><span class="line">  submitWaitingStages()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>getParentStages()。<br>因为是从最终的 stage 往回推算的，这需要计算最终 stage 所依赖的各个 stage。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//TODO 用于获取父stage</span></span><br><span class="line"> <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getParentStages</span></span>(rdd: <span class="type">RDD</span>[_], jobId: <span class="type">Int</span>): <span class="type">List</span>[<span class="type">Stage</span>] = &#123;</span><br><span class="line">   <span class="keyword">val</span> parents = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">Stage</span>]</span><br><span class="line">   <span class="keyword">val</span> waitingForVisit = <span class="keyword">new</span> <span class="type">Stack</span>[<span class="type">RDD</span>[_]]</span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">visit</span></span>(r: <span class="type">RDD</span>[_]) &#123;</span><br><span class="line">     <span class="keyword">if</span> (!visited(r)) &#123;</span><br><span class="line">       visited + r</span><br><span class="line">       <span class="keyword">for</span> (dep &lt;- r.dependencies) &#123;</span><br><span class="line">         dep <span class="keyword">match</span> &#123;</span><br><span class="line">           <span class="keyword">case</span> shufDep: <span class="type">ShuffleDependency</span>[_, _, _] =&gt;</span><br><span class="line">             <span class="comment">//TODO 把宽依赖传进去，获得父stage</span></span><br><span class="line">             parents += getShuffleMapStage(shufDep, jobId)</span><br><span class="line">           <span class="keyword">case</span> _ =&gt;</span><br><span class="line">             waitingForVisit.push(dep.rdd)</span><br><span class="line">         &#125;</span><br><span class="line">       &#125;</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   waitingForVisit.push(rdd)</span><br><span class="line">   <span class="keyword">while</span> (!waitingForVisit.isEmpty) &#123;</span><br><span class="line">     visit(waitingForVisit.pop())</span><br><span class="line">   &#125;</span><br><span class="line">   parents.toList</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>###任务的生成<br>回到 handleJobSubmitted 中的代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">submitStage(finalStage)</span><br></pre></td></tr></table></figure>
<p>submitStage 会提交 finalStage，如果这个 stage 的某些 parentStage 未提交，则递归调用 submitStage()，直至所有的 stage 均已计算完成。</p>
<p>submitStage() 会调用 submitMissingTasks():</p>
<p>submitMissingTasks(stage, jobId.get)</p>
<p>而 submitMissingTasks() 会完成 DAGScheduler 最后的工作：它判断出哪些 Partition 需要计算，为每个 Partition 生成 Task，然后这些 Task 就会封闭到 TaskSet</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//TODO  DAG提交stage  根据最后一个stage  开始找到第一个stage递归提交stage</span></span><br><span class="line"> <span class="comment">/** Submits stage, but first recursively submits any missing parents. */</span></span><br><span class="line"> <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitStage</span></span>(stage: <span class="type">Stage</span>) &#123;</span><br><span class="line">   <span class="keyword">val</span> jobId = activeJobForStage(stage)</span><br><span class="line">   <span class="keyword">if</span> (jobId.isDefined) &#123;</span><br><span class="line">     </span><br><span class="line">     <span class="keyword">if</span> (!waitingStages(stage) &amp;&amp; !runningStages(stage) &amp;&amp; !failedStages(stage)) &#123;</span><br><span class="line">       <span class="comment">//TODO 获取他的父stage 没有提交的stage</span></span><br><span class="line">       <span class="keyword">val</span> missing = getMissingParentStages(stage).sortBy(_.id)</span><br><span class="line">       <span class="comment">//todo 判断父stage是否为空，为空就以为着他是第一stage</span></span><br><span class="line">       <span class="keyword">if</span> (missing == <span class="type">Nil</span>) &#123;</span><br><span class="line">      <span class="comment">//TODO 开始提交最前面的stage, DAG提交stage给TaskScheduler 会将stage转换成taskSet</span></span><br><span class="line">         submitMissingTasks(stage, jobId.get)</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">         <span class="comment">//TODO 有父stage  就递归提交</span></span><br><span class="line">         <span class="keyword">for</span> (parent &lt;- missing) &#123;</span><br><span class="line">           submitStage(parent)</span><br><span class="line">         &#125;</span><br><span class="line">         waitingStages += stage</span><br><span class="line">       &#125;</span><br><span class="line">     &#125;</span><br><span class="line">   &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">     abortStage(stage, <span class="string">"No active job for stage "</span> + stage.id)</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>submitMissingTasks在最后提交给 TaskScheduler 进行处理</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">  <span class="comment">//TODO  DAG提交stage给TaskScheduler 会将stage转换成taskSet</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitMissingTasks</span></span>(stage: <span class="type">Stage</span>, jobId: <span class="type">Int</span>) &#123;</span><br><span class="line">...</span><br><span class="line"><span class="comment">//TODO 创建多少个Task</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> tasks: <span class="type">Seq</span>[<span class="type">Task</span>[_]] = <span class="keyword">if</span> (stage.isShuffleMap) &#123;</span><br><span class="line">      partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">        <span class="comment">//TODO 数据存储的最佳位置   移动计算，而不是移动数据</span></span><br><span class="line">        <span class="keyword">val</span> locs = getPreferredLocs(stage.rdd, id)</span><br><span class="line">        <span class="keyword">val</span> part = stage.rdd.partitions(id)</span><br><span class="line">        <span class="comment">//TODO 从上游拉取数据</span></span><br><span class="line">        <span class="keyword">new</span> <span class="type">ShuffleMapTask</span>(stage.id, taskBinary, part, locs)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">val</span> job = stage.resultOfJob.get</span><br><span class="line">      partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">        <span class="keyword">val</span> p: <span class="type">Int</span> = job.partitions(id)</span><br><span class="line">        <span class="keyword">val</span> part = stage.rdd.partitions(p)</span><br><span class="line">        <span class="keyword">val</span> locs = getPreferredLocs(stage.rdd, p)</span><br><span class="line">        <span class="comment">//TODO  将数据写入某个介质里面，nosql hdfs 等等</span></span><br><span class="line">        <span class="keyword">new</span> <span class="type">ResultTask</span>(stage.id, taskBinary, part, locs, id)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//TODO task的数量最好和分区数一样  如果分区数大于0</span></span><br><span class="line"> <span class="comment">//TODO task的数量最好和分区数一样  如果分区数大于0</span></span><br><span class="line">    <span class="keyword">if</span> (tasks.size &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      logInfo(<span class="string">"Submitting "</span> + tasks.size + <span class="string">" missing tasks from "</span> + stage + <span class="string">" ("</span> + stage.rdd + <span class="string">")"</span>)</span><br><span class="line">      stage.pendingTasks ++= tasks</span><br><span class="line"></span><br><span class="line">      <span class="comment">//TODO 调用taskScheduler的submitTasks提交taskSet 现在将task转换成一个array</span></span><br><span class="line">taskScheduler.submitTasks(<span class="keyword">new</span> <span class="type">TaskSet</span>(</span><br><span class="line">        tasks.toArray, stage.id, stage.latestInfo.attemptId, stage.firstJobId, properties))</span><br><span class="line">      stage.latestInfo.submissionTime = <span class="type">Some</span>(clock.getTimeMillis())</span><br><span class="line">      .....</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="TaskScheduler-amp-amp-TaskSchedulerBackend"><a href="#TaskScheduler-amp-amp-TaskSchedulerBackend" class="headerlink" title="TaskScheduler &amp;&amp; TaskSchedulerBackend"></a>TaskScheduler &amp;&amp; TaskSchedulerBackend</h3><p>上文分析到在 DAGScheduler 中最终会执行 taskScheduler.submitTasks() 方法，我们先简单看一下从这里开始往下的执行逻辑：</p>
<pre><code>①taskScheduler.submitTasks()
    -&gt;②schedulableBuilder.addTaskSetManager() 调度模式，是先来先服务还是公平调度模式
    -&gt;③CoarseGrainedSchedulerBackend.reviveOffers() 这个是向driverActor发送消息driverActor ! ReviveOffers
        -&gt;④CoarseGrainedSchedulerBackend.receiveWithLogging 这是driverActor接收消息的部分
            -&gt;⑤CoarseGrainedSchedulerBackend.makeOffers() //case ReviveOffers =&gt;makeOffers()
        这个模式匹配会调用maksOffers方法
                -&gt;⑥launchTasks()调用launchTask向Executor提交task
                    -&gt;⑦ executorData.executorActor ! LaunchTask(new SerializableBuffer(serializedTask))向executor发送序列化好的task，发送一个Task
</code></pre><p>步骤一、二中主要将这组<br>任务的 TaskSet 加入到一个 TaskSetManager 中。TaskSetManager 会根据数据就近原则为 task 分配计算资源，监控 task 的执行状态等，比如失败重试，推测执行等。<br>步骤三、四逻辑较为简单。<br>步骤五为每个 task 具体分配资源，它的输入是一个 Executor 的列表，输出是 TaskDescription 的二维数组。TaskDescription 包含了 TaskID, Executor ID 和 task 执行的依赖信息等。<br>步骤六、七就是将任务真正的发送到 executor 中执行了，并等待 executor 的状态返回。</p>

            

        </div>

        <footer class="article-footer">

        
        <! -- 添加捐赠图标 -->
<div class ="post-donate">
    <div id="donate_board" class="donate_bar center">
        <a id="btn_donate" class="btn_donate" href="javascript:;" title="打赏"></a>
        <span class="donate_txt">
           如果您觉得文章不错，就请我看场ufc直播🤓🤓🤓🤓🤓！
        </span>
        <br>
      </div>  
    <div id="donate_guide" class="donate_bar center hidden" >
        <!-- 支付宝打赏图案 -->
        <img src="/css/images/alipay.jpg" alt="支付宝打赏" > 
        <!-- 微信打赏图案 -->
        <img src="/css/images/wechatpay.jpg" alt="微信打赏" >  
    </div>
    <script type="text/javascript">
        document.getElementById('btn_donate').onclick = function(){
            if($('#donate_guide').hasClass('hidden')){
                $('#donate_guide').removeClass('hidden');
            }else{
                $('#donate_guide').addClass('hidden');
            }
        }
    </script>
</div>
<! -- 添加捐赠图标 -->
        
            <div class="share-container">


    <div class="bdsharebuttonbox">
    <a href="#" class="bds_more" data-cmd="more">分享到：</a>
    <a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间">QQ空间</a>
    <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博">新浪微博</a>
    <a href="#" class="bds_tqq" data-cmd="tqq" title="分享到腾讯微博">腾讯微博</a>
    <a href="#" class="bds_renren" data-cmd="renren" title="分享到人人网">人人网</a>
    <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信">微信</a>
</div>
<script>
window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"16"},"share":{"bdSize":16}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script>
<style>
    .bdshare_popup_box {
        border-radius: 4px;
        border: #e1e1e1 solid 1px;
    }
    .bdshare-button-style0-16 a,
    .bdshare-button-style0-16 .bds_more {
        padding-left: 20px;
        margin: 6px 10px 6px 0;
    }
    .bdshare_dialog_list a,
    .bdshare_popup_list a,
    .bdshare_popup_bottom a {
        font-family: 'Microsoft Yahei';
    }
    .bdshare_popup_top {
        display: none;
    }
    .bdshare_popup_bottom {
        height: auto;
        padding: 5px;
    }
</style>


</div>

            
    
        <a href="http://gangtieguo.cn/2018/08/24/Spark任务执行流程详解/#comments" class="article-comment-link">评论</a>
    

        </footer>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2018/08/30/docs/15355929916048/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">上一篇</strong>
            <div class="article-nav-title">
                
                    (no title)
                
            </div>
        </a>
    
    
        <a href="/2018/08/20/MapReduce中Shuffle中的机制/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">下一篇</strong>
            <div class="article-nav-title">MapReduce中Shuffle中的机制</div>
        </a>
    
</nav>


    
</article>


    
    
        <section id="comments">
    <div id="lv-container" data-id="city" data-uid=MTAyMC8zNjM2MS8xMjg5Ng==></div>
</section>
    

</section>
            
            
                
<aside id="sidebar">
   
        
    <div class="widget-wrap">
        <h3 class="widget-title"><i class="fa fa-book"></i>最新文章</h3>
        <div class="widget">
            <ul id="recent-post" class="no-thumbnail">
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/博客/">博客</a></p>
                            <p class="item-title"><a href="/2018/08/30/docs/15355953289095/" class="title">源文件提交到仓库</a></p>
                            <p class="item-date"><time datetime="2018-08-30T02:15:28.910Z" itemprop="datePublished">2018-08-30</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/碎片知识/">碎片知识</a></p>
                            <p class="item-title"><a href="/2018/08/30/docs/15355953289057/" class="title">命令积累</a></p>
                            <p class="item-date"><time datetime="2018-08-30T02:15:28.906Z" itemprop="datePublished">2018-08-30</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/环境配置/">环境配置</a></p>
                            <p class="item-title"><a href="/2018/08/30/docs/15355953289019/" class="title">Docker安装Hadoop集群【引用】</a></p>
                            <p class="item-date"><time datetime="2018-08-30T02:15:28.902Z" itemprop="datePublished">2018-08-30</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/安装部署/">安装部署</a></p>
                            <p class="item-title"><a href="/2018/08/30/docs/15355953288980/" class="title">FLINK容器的搭建</a></p>
                            <p class="item-date"><time datetime="2018-08-30T02:15:28.898Z" itemprop="datePublished">2018-08-30</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/安装部署/">安装部署</a></p>
                            <p class="item-title"><a href="/2018/08/30/docs/15355953288944/" class="title">Hadoop&amp;Spark组合容器的搭建</a></p>
                            <p class="item-date"><time datetime="2018-08-30T02:15:28.895Z" itemprop="datePublished">2018-08-30</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title"><i class="fa fa-archive"></i>归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">八月 2018</a><span class="archive-list-count">85</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">七月 2018</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a><span class="archive-list-count">12</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title"><i class="fa fa-folder"></i>分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spring/">Spring</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客/">博客</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a><span class="category-list-count">48</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/安装部署/">安装部署</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/工程框架/">工程框架</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/快捷键/">快捷键</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/总结/">总结</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/框架/">框架</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/环境配置/">环境配置</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/碎片知识/">碎片知识</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/组件/">组件</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/语言/">语言</a><span class="category-list-count">2</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title"><i class="fa fa-folder"></i>标签</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ambari/">Ambari</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CDH/">CDH</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Docker/">Docker</a><span class="tag-list-count">28</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Docker-machine/">Docker-machine</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ELK/">ELK</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/FLINK/">FLINK</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Finder/">Finder</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HBase/">HBase</a><span class="tag-list-count">10</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HDFS/">HDFS</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/">Hadoop</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/">Hexo</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hive/">Hive</a><span class="tag-list-count">10</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hue/">Hue</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Idea/">Idea</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/">Java</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Jenkins/">Jenkins</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Json/">Json</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kafka/">Kafka</a><span class="tag-list-count">10</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/">Linux</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mac/">Mac</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mysql/">Mysql</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Other/">Other</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RDD/">RDD</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SSH/">SSH</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Scala/">Scala</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Shell/">Shell</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/">Spark</a><span class="tag-list-count">24</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SparkSQL/">SparkSQL</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SparkStreaming/">SparkStreaming</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/es/">es</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/">git</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/zk/">zk</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/使用/">使用</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/原理/">原理</a><span class="tag-list-count">22</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/命令/">命令</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据/">大数据</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/安装部署/">安装部署</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/开发/">开发</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/快捷键/">快捷键</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/技术/">技术</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/报表/">报表</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/操作/">操作</a><span class="tag-list-count">2</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title"><i class="fa fa-tags"></i>标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/Ambari/" style="font-size: 10px;">Ambari</a> <a href="/tags/CDH/" style="font-size: 10px;">CDH</a> <a href="/tags/Docker/" style="font-size: 20px;">Docker</a> <a href="/tags/Docker-machine/" style="font-size: 10px;">Docker-machine</a> <a href="/tags/ELK/" style="font-size: 11.43px;">ELK</a> <a href="/tags/FLINK/" style="font-size: 10px;">FLINK</a> <a href="/tags/Finder/" style="font-size: 10px;">Finder</a> <a href="/tags/HBase/" style="font-size: 14.29px;">HBase</a> <a href="/tags/HDFS/" style="font-size: 12.86px;">HDFS</a> <a href="/tags/Hadoop/" style="font-size: 15.71px;">Hadoop</a> <a href="/tags/Hexo/" style="font-size: 12.86px;">Hexo</a> <a href="/tags/Hive/" style="font-size: 14.29px;">Hive</a> <a href="/tags/Hue/" style="font-size: 10px;">Hue</a> <a href="/tags/Idea/" style="font-size: 10px;">Idea</a> <a href="/tags/Java/" style="font-size: 11.43px;">Java</a> <a href="/tags/Jenkins/" style="font-size: 10px;">Jenkins</a> <a href="/tags/Json/" style="font-size: 10px;">Json</a> <a href="/tags/Kafka/" style="font-size: 14.29px;">Kafka</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/Mac/" style="font-size: 10px;">Mac</a> <a href="/tags/Mysql/" style="font-size: 10px;">Mysql</a> <a href="/tags/Other/" style="font-size: 10px;">Other</a> <a href="/tags/RDD/" style="font-size: 10px;">RDD</a> <a href="/tags/SSH/" style="font-size: 10px;">SSH</a> <a href="/tags/Scala/" style="font-size: 11.43px;">Scala</a> <a href="/tags/Shell/" style="font-size: 10px;">Shell</a> <a href="/tags/Spark/" style="font-size: 18.57px;">Spark</a> <a href="/tags/SparkSQL/" style="font-size: 11.43px;">SparkSQL</a> <a href="/tags/SparkStreaming/" style="font-size: 11.43px;">SparkStreaming</a> <a href="/tags/es/" style="font-size: 10px;">es</a> <a href="/tags/git/" style="font-size: 11.43px;">git</a> <a href="/tags/linux/" style="font-size: 10px;">linux</a> <a href="/tags/zk/" style="font-size: 10px;">zk</a> <a href="/tags/使用/" style="font-size: 11.43px;">使用</a> <a href="/tags/原理/" style="font-size: 17.14px;">原理</a> <a href="/tags/命令/" style="font-size: 11.43px;">命令</a> <a href="/tags/大数据/" style="font-size: 11.43px;">大数据</a> <a href="/tags/安装部署/" style="font-size: 10px;">安装部署</a> <a href="/tags/开发/" style="font-size: 11.43px;">开发</a> <a href="/tags/快捷键/" style="font-size: 10px;">快捷键</a> <a href="/tags/技术/" style="font-size: 10px;">技术</a> <a href="/tags/报表/" style="font-size: 10px;">报表</a> <a href="/tags/操作/" style="font-size: 10px;">操作</a>
        </div>
    </div>

    
        
    <div class="widget-wrap widget-list">
        <h3 class="widget-title"><i class="fa fa-link"></i>链接</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://gangtieguo.cn"  target="_blank">GTG</a>
                    </li>
                
            </ul>
        </div>
    </div>


    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>

            
        </div>
        <footer id="footer">

<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol ==='https'){
   bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
  }
  else{
  bp.src = 'http://push.zhanzhang.baidu.com/push.js';
  }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2018 GTG<br>
            Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a><br>Analyse with <script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1273739152'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s22.cnzz.com/z_stat.php%3Fid%3D1273739152%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>

<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1273739152'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s22.cnzz.com/z_stat.php%3Fid%3D1273739152%26online%3D1%26show%3Dline' type='text/javascript'%3E%3C/script%3E"));</script>
        </div>
    </div>
</footer>
        
    
    
    <!-- 来必力City版安装代码 -->
    <script type="text/javascript">
     (function(d, s) {
         var j, e = d.getElementsByTagName(s)[0];

         if (typeof LivereTower === 'function') { return; }

         j = d.createElement(s);
         j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
         j.async = true;

         e.parentNode.insertBefore(j, e);
     })(document, 'script');
    </script>
  <noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
  <!-- City版安装代码已完成 -->





    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>