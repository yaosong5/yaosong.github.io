<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="纵浪大化中，不喜亦不悲"><title>Kafka集群配置及配置文件 | 钢铁锅</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Kafka集群配置及配置文件</h1><a id="logo" href="/.">钢铁锅</a><p class="description">应尽便须尽，无复独多虑</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Kafka集群配置及配置文件</h1><div class="post-meta">Aug 13, 2018<span> | </span><span class="category"><a href="/categories/安装部署/">安装部署</a></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Kafka集群部署"><span class="toc-number">1.</span> <span class="toc-text">Kafka集群部署</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1、下载安装包"><span class="toc-number">2.</span> <span class="toc-text">1、下载安装包</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2、解压安装包"><span class="toc-number">3.</span> <span class="toc-text">2、解压安装包</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3、修改配置文件"><span class="toc-number">4.</span> <span class="toc-text">3、修改配置文件</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#配置文件及注释"><span class="toc-number">5.</span> <span class="toc-text">配置文件及注释</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#常用"><span class="toc-number">6.</span> <span class="toc-text">常用</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#详解"><span class="toc-number">7.</span> <span class="toc-text">详解</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#以下是kafka中Leader-replicas配置参数"><span class="toc-number">8.</span> <span class="toc-text">以下是kafka中Leader,replicas配置参数</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#kafka中zookeeper参数配置"><span class="toc-number">9.</span> <span class="toc-text">kafka中zookeeper参数配置</span></a></li></ol></div></div><div class="post-content"><p>[TOC]</p>
<h1 id="Kafka集群部署"><a href="#Kafka集群部署" class="headerlink" title="Kafka集群部署"></a>Kafka集群部署</h1><p>kafka默认推荐的是2.11开头的，如果系统中没有其他软件依赖于Scala的话，就使用2.11版本的<br>scala是依赖于zookeeper的，所以需要给zookeeper配置地址</p>
<a id="more"></a>
<h1 id="1、下载安装包"><a href="#1、下载安装包" class="headerlink" title="1、下载安装包"></a>1、下载安装包</h1><p><a href="http://kafka.apache.org/downloads.html" target="_blank" rel="noopener">http://kafka.apache.org/downloads.html</a><br>在linux中使用wget命令下载安装包<br>wget <a href="http://mirrors.hust.edu.cn/apache/kafka/0.8.2.2/kafka_2.11-0.8.2.2.tgz" target="_blank" rel="noopener">http://mirrors.hust.edu.cn/apache/kafka/0.8.2.2/kafka_2.11-0.8.2.2.tgz</a></p>
<h1 id="2、解压安装包"><a href="#2、解压安装包" class="headerlink" title="2、解压安装包"></a>2、解压安装包</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf kafka_2.11-0.8.2.2.tgz -C /home/bigdata/apps/kafka/</span><br><span class="line">cd /home/bigdata/apps/kafka/</span><br><span class="line">ln -s kafka_2.11-0.8.2.2 kafka</span><br></pre></td></tr></table></figure>
<h1 id="3、修改配置文件"><a href="#3、修改配置文件" class="headerlink" title="3、修改配置文件"></a>3、修改配置文件</h1><p>配置文件有4个点</p>
<p>hostname应该保持一致</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">broker.id =0</span><br><span class="line">#每一个broker在集群中的唯一表示，要求是正数。当该服务器的IP地址发生改变时，broker.id没有变化，则不会影响consumers的消息情况</span><br><span class="line">  log.dirs=/home/bigdata/logs/kafka-logs</span><br><span class="line">#kafka数据的存放地址，多个地址的话用逗号分割 /data/kafka-logs-1，/data/kafka-logs-2</span><br><span class="line">  port =9092</span><br><span class="line">#broker server服务端口</span><br><span class="line">  message.max.bytes =6525000</span><br><span class="line">#表示消息体的最大大小，单位是字节</span><br><span class="line">  num.network.threads =3</span><br><span class="line">#broker处理消息的最大线程数，一般情况下不需要去修改 配置了三台服务器，所以选择三个</span><br><span class="line">  #num.io.threads =8</span><br><span class="line">#broker处理磁盘IO的线程数，数值应该大于你的硬盘数</span><br><span class="line">  #background.threads =4</span><br><span class="line">#一些后台任务处理的线程数，例如过期消息文件的删除等，一般情况下不需要去做修改</span><br><span class="line">  queued.max.requests =500</span><br><span class="line">#等待IO线程处理的请求队列最大数，若是等待IO的请求超过这个数值，那么会停止接受外部消息，应该是一种自我保护机制。</span><br><span class="line">#broker的主机地址，若是设置了，那么会绑定到这个地址上，若是没有，会绑定到所有的接口上，并将其中之一发送到ZK，一般不设置</span><br><span class="line">  socket.send.buffer.bytes=102400</span><br><span class="line">#socket的发送缓冲区，socket的调优参数SO_SNDBUFF</span><br><span class="line">  socket.receive.buffer.bytes =102400</span><br><span class="line">#socket的接受缓冲区，socket的调优参数SO_RCVBUFF</span><br><span class="line">  socket.request.max.bytes =104857600</span><br><span class="line">#socket请求的最大数值，防止serverOOM，message.max.bytes必然要小于socket.request.max.bytes，会被topic创建时的指定参数覆盖</span><br><span class="line">   #log.segment.bytes =1024*1024*1024</span><br><span class="line">#topic的分区是以一堆segment文件存储的，这个控制每个segment的大小，会被topic创建时的指定参数覆盖</span><br><span class="line">  log.roll.hours =168</span><br><span class="line">  zookeeper.connect = bigdata1:2181,bigdata2:2181,bigdata3:2181</span><br><span class="line">#zookeeper集群的地址，可以是多个，多个之间用逗号分割 hostname1:port1,hostname2:port2,hostname3:port3</span><br><span class="line">  zookeeper.session.timeout.ms=6000</span><br><span class="line">#ZooKeeper的最大超时时间，就是心跳的间隔，若是没有反映，那么认为已经死了，不易过大</span><br><span class="line">  zookeeper.connection.timeout.ms =6000</span><br><span class="line">#ZooKeeper的连接超时时间</span><br><span class="line">  zookeeper.sync.time.ms =2000</span><br><span class="line">#host.name=bigdata1</span><br><span class="line"> #broker的主机地址，若是设置了，那么会绑定到这个地址上，若是没有，会绑定到所有的接口上，并将其中之一发送到ZK，一般不设置,hostname为主机</span><br><span class="line"> </span><br><span class="line"># 这个是轻量的配置文件</span><br><span class="line">#broker的全局唯一编号，不能重复</span><br><span class="line">broker.id=0</span><br><span class="line">#用来监听连接的端口，producer或consumer将在此端口建立连接</span><br><span class="line">port=9092</span><br><span class="line">#处理网络请求的线程数量，集群中有几个节点就设置几个</span><br><span class="line">num.network.threads=3</span><br><span class="line">#用来处理磁盘io的线程数量</span><br><span class="line">num.io.threads=8</span><br><span class="line">#发送套接字的缓冲区大小</span><br><span class="line">socket.send.buffer.bytes=102400</span><br><span class="line">#接受套接字的缓冲区大小</span><br><span class="line">socket.receive.buffer.bytes=102400</span><br><span class="line">#请求套接字的缓冲区大小</span><br><span class="line">socket.request.max.bytes=104857600</span><br><span class="line">#kafka运行日志存放的路径</span><br><span class="line">log.dirs=/home/hadoop/logs/kafka</span><br><span class="line">#topic在当前broker上的分片个数</span><br><span class="line">num.partitions=2</span><br><span class="line">#用来恢复和清理data下数据的线程数量</span><br><span class="line">num.recovery.threads.per.data.dir=1</span><br><span class="line">#segment文件保留的最长时间。超时将会被删除</span><br><span class="line">log.retention.hours=168</span><br><span class="line">#滚动删除生成心得segment文件的最大时间</span><br><span class="line">log.roll.hour=168</span><br></pre></td></tr></table></figure>
<p> <code>------------------</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ip（重要），如果不改，则客户端会抛出：producer connection to localhost:9092 unsuccessful错误，</span><br><span class="line">advertised.host.name=192.168.11.11</span><br></pre></td></tr></table></figure>
<p>\<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p>cp  /home/bigdata/apps/kafka/config/server.properties /home/bigdata/apps/kafka/config/server.properties.bak<br>vi  /home/bigdata/apps/kafka/config/server.properties</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 4、分发安装包</span><br></pre></td></tr></table></figure>
<p>scp -r /home/bigdata/apps/kafka/ bigdata2:/home/bigdata/apps/</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">然后分别在各机器上创建软连</span><br></pre></td></tr></table></figure>
<p>cd /home/bigdata/apps/kafka<br>ln -s kafka_2.11-0.8.2.2 kafka</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 5、再次修改配置文件（重要）</span><br></pre></td></tr></table></figure>
<p>依次修改各服务器上配置文件的的broker.id，分别是0,1,2不得重复。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 需要配置kafka的环境变量</span><br><span class="line"></span><br><span class="line"># 6、启动集群</span><br><span class="line"></span><br><span class="line">**依次在各节点上启动kafka** </span><br><span class="line">后台启动 `nohup最后加一个&amp;` </span><br><span class="line"></span><br><span class="line">```bash</span><br><span class="line">KAFKA_HOME/bin/kafka-server-start.sh  KAFKA_HOME/config/server.properties &amp;</span><br></pre></td></tr></table></figure></p>
<h1 id="配置文件及注释"><a href="#配置文件及注释" class="headerlink" title="配置文件及注释"></a>配置文件及注释</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">broker.id=0</span><br><span class="line">#当前机器在集群中的唯一标识，和zookeeper的myid性质一样</span><br><span class="line">port=9092</span><br><span class="line">#当前kafka对外提供服务的端口默认是9092</span><br><span class="line">host.name=192.168.11.11</span><br><span class="line">advertised.host.name=192.168.11.11</span><br><span class="line">#这个参数默认是关闭的，在0.8.1有个bug，DNS解析问题，失败率的问题。</span><br><span class="line">num.network.threads=3</span><br><span class="line">#这个是borker进行网络处理的线程数</span><br><span class="line">num.io.threads=8</span><br><span class="line">#这个是borker进行I/O处理的线程数</span><br><span class="line">log.dirs=/home/bigdata/apps/kafka/kafkalogs/</span><br><span class="line">#消息存放的目录，这个目录可以配置为“，”逗号分割的表达式，上面的num.io.threads要大于这个目录的个数这个目录，如果配置多个目录，新创建的topic他把消息持久化的地方是，当前以逗号分割的目录中，那个分区数最少就放那一个</span><br><span class="line">socket.send.buffer.bytes=102400</span><br><span class="line">#发送缓冲区buffer大小，数据不是一下子就发送的，先回存储到缓冲区了到达一定的大小后在发送，能提高性能</span><br><span class="line">socket.receive.buffer.bytes=102400</span><br><span class="line">#kafka接收缓冲区大小，当数据到达一定大小后在序列化到磁盘</span><br><span class="line">socket.request.max.bytes=104857600</span><br><span class="line">#这个参数是向kafka请求消息或者向kafka发送消息的请请求的最大数，这个值不能超过java的堆栈大小</span><br><span class="line">num.partitions=1</span><br><span class="line">#默认的分区数，一个topic默认1个分区数</span><br><span class="line">log.retention.hours=168</span><br><span class="line">#默认消息的最大持久化时间，168小时，7天</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">message.max.bytes=5242880</span><br><span class="line">#消息保存的最大值5M</span><br><span class="line">default.replication.factor=2</span><br><span class="line">#kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务</span><br><span class="line">replica.fetch.max.bytes=5242880</span><br><span class="line">#取消息的最大直接数</span><br><span class="line">log.segment.bytes=1073741824</span><br><span class="line">#这个参数是：因为kafka的消息是以追加的形式落地到文件，当超过这个值的时候，kafka会新起一个文件</span><br><span class="line">log.retention.check.interval.ms=300000</span><br><span class="line">#每隔300000毫秒去检查上面配置的log失效时间（log.retention.hours=168 ），到目录查看是否有过期的消息如果有，删除</span><br><span class="line">log.cleaner.enable=false</span><br><span class="line">#是否启用log压缩，一般不用启用，启用的话可以提高性能</span><br><span class="line">zookeeper.connect=192.168.11.11:2181,192.168.11.12:2181,192.168.11.13:2181</span><br><span class="line">#设置zookeeper的连接端口</span><br></pre></td></tr></table></figure>
<h1 id="常用"><a href="#常用" class="headerlink" title="常用"></a>常用</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">broker.id =0</span><br><span class="line">#每一个broker在集群中的唯一表示，要求是正数。当该服务器的IP地址发生改变时，broker.id没有变化，则不会影响consumers的消息情况</span><br><span class="line">log.dirs=/data/kafka-logs</span><br><span class="line">#kafka数据的存放地址，多个地址的话用逗号分割 /data/kafka-logs-1，/data/kafka-logs-2</span><br><span class="line">port =9092</span><br><span class="line">#broker server服务端口</span><br><span class="line">message.max.bytes =6525000</span><br><span class="line">#表示消息体的最大大小，单位是字节</span><br><span class="line">num.network.threads =3</span><br><span class="line">#broker处理消息的最大线程数，一般情况下不需要去修改 配置了三台服务器，所以选择三个</span><br><span class="line">num.io.threads =8</span><br><span class="line">#broker处理磁盘IO的线程数，数值应该大于你的硬盘数</span><br><span class="line">background.threads =4</span><br><span class="line">#一些后台任务处理的线程数，例如过期消息文件的删除等，一般情况下不需要去做修改</span><br><span class="line">queued.max.requests =500</span><br><span class="line">#等待IO线程处理的请求队列最大数，若是等待IO的请求超过这个数值，那么会停止接受外部消息，应该是一种自我保护机制。</span><br><span class="line">socket.send.buffer.bytes=100*1024</span><br><span class="line">#socket的发送缓冲区，socket的调优参数SO_SNDBUFF</span><br><span class="line">socket.receive.buffer.bytes =100*1024</span><br><span class="line">#socket的接受缓冲区，socket的调优参数SO_RCVBUFF</span><br><span class="line">socket.request.max.bytes =100*1024*1024</span><br><span class="line">#socket请求的最大数值，防止serverOOM，message.max.bytes必然要小于socket.request.max.bytes，会被topic创建时的指定参数覆盖</span><br><span class="line">log.segment.bytes =1024*1024*1024</span><br><span class="line">#topic的分区是以一堆segment文件存储的，这个控制每个segment的大小，会被topic创建时的指定参数覆盖</span><br><span class="line">log.roll.hours =24*7</span><br></pre></td></tr></table></figure>
<h1 id="详解"><a href="#详解" class="headerlink" title="详解"></a>详解</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line">broker.id =0</span><br><span class="line">#每一个broker在集群中的唯一表示，要求是正数。当该服务器的IP地址发生改变时，broker.id没有变化，则不会影响consumers的消息情况</span><br><span class="line">log.dirs=/data/kafka-logs</span><br><span class="line">#kafka数据的存放地址，多个地址的话用逗号分割 /data/kafka-logs-1，/data/kafka-logs-2</span><br><span class="line">port =9092</span><br><span class="line">#broker server服务端口</span><br><span class="line">message.max.bytes =6525000</span><br><span class="line">#表示消息体的最大大小，单位是字节</span><br><span class="line">num.network.threads =4</span><br><span class="line">#broker处理消息的最大线程数，一般情况下不需要去修改</span><br><span class="line">num.io.threads =8</span><br><span class="line">#broker处理磁盘IO的线程数，数值应该大于你的硬盘数</span><br><span class="line">background.threads =4</span><br><span class="line">#一些后台任务处理的线程数，例如过期消息文件的删除等，一般情况下不需要去做修改</span><br><span class="line">queued.max.requests =500</span><br><span class="line">#等待IO线程处理的请求队列最大数，若是等待IO的请求超过这个数值，那么会停止接受外部消息，应该是一种自我保护机制。</span><br><span class="line">host.name</span><br><span class="line">#broker的主机地址，若是设置了，那么会绑定到这个地址上，若是没有，会绑定到所有的接口上，并将其中之一发送到ZK，一般不设置</span><br><span class="line">socket.send.buffer.bytes=100*1024</span><br><span class="line">#socket的发送缓冲区，socket的调优参数SO_SNDBUFF</span><br><span class="line">socket.receive.buffer.bytes =100*1024</span><br><span class="line">#socket的接受缓冲区，socket的调优参数SO_RCVBUFF</span><br><span class="line">socket.request.max.bytes =100*1024*1024</span><br><span class="line">#socket请求的最大数值，防止serverOOM，message.max.bytes必然要小于socket.request.max.bytes，会被topic创建时的指定参数覆盖</span><br><span class="line">log.segment.bytes =1024*1024*1024</span><br><span class="line">#topic的分区是以一堆segment文件存储的，这个控制每个segment的大小，会被topic创建时的指定参数覆盖</span><br><span class="line">log.roll.hours =24*7</span><br><span class="line">#这个参数会在日志segment没有达到log.segment.bytes设置的大小，也会强制新建一个segment会被 topic创建时的指定参数覆盖</span><br><span class="line">log.cleanup.policy = delete</span><br><span class="line">#日志清理策略选择有：delete和compact主要针对过期数据的处理，或是日志文件达到限制的额度，会被 topic创建时的指定参数覆盖</span><br><span class="line">log.retention.minutes=60*24 # 一天后删除</span><br><span class="line">#数据存储的最大时间超过这个时间会根据log.cleanup.policy设置的策略处理数据，也就是消费端能够多久去消费数据</span><br><span class="line">#log.retention.bytes和log.retention.minutes任意一个达到要求，都会执行删除，会被topic创建时的指定参数覆盖</span><br><span class="line">log.retention.bytes=-1</span><br><span class="line">#topic每个分区的最大文件大小，一个topic的大小限制 = 分区数*log.retention.bytes。-1没有大小限log.retention.bytes和log.retention.minutes任意一个达到要求，都会执行删除，会被topic创建时的指定参数覆盖</span><br><span class="line">log.retention.check.interval.ms=5minutes</span><br><span class="line">#文件大小检查的周期时间，是否处罚 log.cleanup.policy中设置的策略</span><br><span class="line">log.cleaner.enable=false</span><br><span class="line">#是否开启日志压缩</span><br><span class="line">log.cleaner.threads = 2</span><br><span class="line">#日志压缩运行的线程数</span><br><span class="line">log.cleaner.io.max.bytes.per.second=None</span><br><span class="line">#日志压缩时候处理的最大大小</span><br><span class="line">log.cleaner.dedupe.buffer.size=500*1024*1024</span><br><span class="line">#日志压缩去重时候的缓存空间，在空间允许的情况下，越大越好</span><br><span class="line">log.cleaner.io.buffer.size=512*1024</span><br><span class="line">#日志清理时候用到的IO块大小一般不需要修改</span><br><span class="line">log.cleaner.io.buffer.load.factor =0.9</span><br><span class="line">#日志清理中hash表的扩大因子一般不需要修改</span><br><span class="line">log.cleaner.backoff.ms =15000</span><br><span class="line">#检查是否处罚日志清理的间隔</span><br><span class="line">log.cleaner.min.cleanable.ratio=0.5</span><br><span class="line">#日志清理的频率控制，越大意味着更高效的清理，同时会存在一些空间上的浪费，会被topic创建时的指定参数覆盖</span><br><span class="line">log.cleaner.delete.retention.ms =1day</span><br><span class="line">#对于压缩的日志保留的最长时间，也是客户端消费消息的最长时间，同log.retention.minutes的区别在于一个控制未压缩数据，一个控制压缩后的数据。会被topic创建时的指定参数覆盖</span><br><span class="line">log.index.size.max.bytes =10*1024*1024</span><br><span class="line">#对于segment日志的索引文件大小限制，会被topic创建时的指定参数覆盖</span><br><span class="line">log.index.interval.bytes =4096</span><br><span class="line">#当执行一个fetch操作后，需要一定的空间来扫描最近的offset大小，设置越大，代表扫描速度越快，但是也更好内存，一般情况下不需要搭理这个参数</span><br><span class="line">log.flush.interval.messages=None</span><br><span class="line">#log文件”sync”到磁盘之前累积的消息条数,因为磁盘IO操作是一个慢操作,但又是一个”数据可靠性&quot;的必要手段,所以此参数的设置,需要在&quot;数据可靠性&quot;与&quot;性能&quot;之间做必要的权衡.如果此值过大,将会导致每次&quot;fsync&quot;的时间较长(IO阻塞),如果此值过小,将会导致&quot;fsync&quot;的次数较多,这也意味着整体的client请求有一定的延迟.物理server故障,将会导致没有fsync的消息丢失.</span><br><span class="line">log.flush.scheduler.interval.ms =3000</span><br><span class="line">#检查是否需要固化到硬盘的时间间隔</span><br><span class="line">log.flush.interval.ms = None</span><br><span class="line">#仅仅通过interval来控制消息的磁盘写入时机,是不足的.此参数用于控制&quot;fsync&quot;的时间间隔,如果消息量始终没有达到阀值,但是离上一次磁盘同步的时间间隔达到阀值,也将触发.</span><br><span class="line">log.delete.delay.ms =60000</span><br><span class="line">#文件在索引中清除后保留的时间一般不需要去修改</span><br><span class="line">log.flush.offset.checkpoint.interval.ms =60000</span><br><span class="line">#控制上次固化硬盘的时间点，以便于数据恢复一般不需要去修改</span><br><span class="line">auto.create.topics.enable =true</span><br><span class="line">#是否允许自动创建topic，若是false，就需要通过命令创建topic</span><br><span class="line">default.replication.factor =1</span><br><span class="line">#是否允许自动创建topic，若是false，就需要通过命令创建topic</span><br><span class="line">num.partitions =1</span><br><span class="line">#每个topic的分区个数，若是在topic创建时候没有指定的话会被topic创建时的指定参数覆盖</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">##这是轻量级的配置文件</span><br><span class="line">broker.id=0</span><br><span class="line">#当前机器在集群中的唯一标识，和zookeeper的myid性质一样</span><br><span class="line">port=9092</span><br><span class="line">#当前kafka对外提供服务的端口默认是9092</span><br><span class="line">host.name=192.168.11.11</span><br><span class="line">#这个参数默认是关闭的，在0.8.1有个bug，DNS解析问题，失败率的问题。</span><br><span class="line">num.network.threads=3</span><br><span class="line">#这个是borker进行网络处理的线程数</span><br><span class="line">num.io.threads=8</span><br><span class="line">#这个是borker进行I/O处理的线程数</span><br><span class="line">log.dirs=/home/hadoop/logs/kafka-logs </span><br><span class="line">#消息存放的目录，这个目录可以配置为“，”逗号分割的表达式，上面的num.io.threads要大于这个目录的个数这个目录，如果配置多个目录，新创建的topic他把消息持久化的地方是，当前以逗号分割的目录中，那个分区数最少就放那一个</span><br><span class="line">socket.send.buffer.bytes=102400</span><br><span class="line">#发送缓冲区buffer大小，数据不是一下子就发送的，先回存储到缓冲区了到达一定的大小后在发送，能提高性能</span><br><span class="line">socket.receive.buffer.bytes=102400</span><br><span class="line">#kafka接收缓冲区大小，当数据到达一定大小后在序列化到磁盘</span><br><span class="line">socket.request.max.bytes=104857600</span><br><span class="line">#这个参数是向kafka请求消息或者向kafka发送消息的请请求的最大数，这个值不能超过java的堆栈大小</span><br><span class="line">num.partitions=1</span><br><span class="line">#默认的分区数，一个topic默认1个分区数</span><br><span class="line">log.retention.hours=168</span><br><span class="line">#默认消息的最大持久化时间，168小时，7天</span><br><span class="line">message.max.byte=5242880</span><br><span class="line">#消息保存的最大值5M</span><br><span class="line">default.replication.factor=2</span><br><span class="line">#kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务</span><br><span class="line">replica.fetch.max.bytes=5242880</span><br><span class="line">#取消息的最大直接数</span><br><span class="line">log.segment.bytes=1073741824</span><br><span class="line">#这个参数是：因为kafka的消息是以追加的形式落地到文件，当超过这个值的时候，kafka会新起一个文件</span><br><span class="line">log.retention.check.interval.ms=300000</span><br><span class="line">#每隔300000毫秒去检查上面配置的log失效时间（log.retention.hours=168 ），到目录查看是否有过期的消息如果有，删除</span><br><span class="line">log.cleaner.enable=false</span><br><span class="line">#是否启用log压缩，一般不用启用，启用的话可以提高性能</span><br><span class="line">zookeeper.connect=192.168.11.11:2181,192.168.11.12:2181,192.168.11.13:2181</span><br><span class="line">#设置zookeeper的连接端口</span><br></pre></td></tr></table></figure>
<h1 id="以下是kafka中Leader-replicas配置参数"><a href="#以下是kafka中Leader-replicas配置参数" class="headerlink" title="以下是kafka中Leader,replicas配置参数"></a>以下是kafka中Leader,replicas配置参数</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">controller.socket.timeout.ms =30000</span><br><span class="line">#partition leader与replicas之间通讯时,socket的超时时间</span><br><span class="line">controller.message.queue.size=10</span><br><span class="line">#partition leader与replicas数据同步时,消息的队列尺寸</span><br><span class="line">replica.lag.time.max.ms =10000</span><br><span class="line">#replicas响应partition leader的最长等待时间，若是超过这个时间，就将replicas列入ISR(in-sync replicas)，并认为它是死的，不会再加入管理中</span><br><span class="line">replica.lag.max.messages =4000</span><br><span class="line">#如果follower落后与leader太多,将会认为此follower[或者说partition relicas]已经失效</span><br><span class="line">###通常,在follower与leader通讯时,因为网络延迟或者链接断开,总会导致replicas中消息同步滞后</span><br><span class="line">##如果消息之后太多,leader将认为此follower网络延迟较大或者消息吞吐能力有限,将会把此replicas迁移</span><br><span class="line">##到其他follower中.</span><br><span class="line">##在broker数量较少,或者网络不足的环境中,建议提高此值.</span><br><span class="line">replica.socket.timeout.ms=30*1000</span><br><span class="line">#follower与leader之间的socket超时时间</span><br><span class="line">replica.socket.receive.buffer.bytes=64*1024</span><br><span class="line">#leader复制时候的socket缓存大小</span><br><span class="line">replica.fetch.max.bytes =1024*1024</span><br><span class="line">#replicas每次获取数据的最大大小</span><br><span class="line">replica.fetch.wait.max.ms =500</span><br><span class="line">#replicas同leader之间通信的最大等待时间，失败了会重试</span><br><span class="line">replica.fetch.min.bytes =1</span><br><span class="line">#fetch的最小数据尺寸,如果leader中尚未同步的数据不足此值,将会阻塞,直到满足条件</span><br><span class="line">num.replica.fetchers=1</span><br><span class="line">#leader进行复制的线程数，增大这个数值会增加follower的IO</span><br><span class="line">replica.high.watermark.checkpoint.interval.ms =5000</span><br><span class="line">#每个replica检查是否将最高水位进行固化的频率</span><br><span class="line">controlled.shutdown.enable =false</span><br><span class="line">#是否允许控制器关闭broker ,若是设置为true,会关闭所有在这个broker上的leader，并转移到其他broker</span><br><span class="line">controlled.shutdown.max.retries =3</span><br><span class="line">#控制器关闭的尝试次数</span><br><span class="line">controlled.shutdown.retry.backoff.ms =5000</span><br><span class="line">#每次关闭尝试的时间间隔</span><br><span class="line">leader.imbalance.per.broker.percentage =10</span><br><span class="line">#leader的不平衡比例，若是超过这个数值，会对分区进行重新的平衡</span><br><span class="line">leader.imbalance.check.interval.seconds =300</span><br><span class="line">#检查leader是否不平衡的时间间隔</span><br><span class="line">offset.metadata.max.bytes</span><br><span class="line">#客户端保留offset信息的最大空间大小</span><br></pre></td></tr></table></figure>
<h1 id="kafka中zookeeper参数配置"><a href="#kafka中zookeeper参数配置" class="headerlink" title="kafka中zookeeper参数配置"></a>kafka中zookeeper参数配置</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">zookeeper.connect = bigdata1:2181,bigdata2:2181,bigdata3:2181</span><br><span class="line">#zookeeper集群的地址，可以是多个，多个之间用逗号分割 hostname1:port1,hostname2:port2,hostname3:port3</span><br><span class="line">zookeeper.session.timeout.ms=6000</span><br><span class="line">#ZooKeeper的最大超时时间，就是心跳的间隔，若是没有反映，那么认为已经死了，不易过大</span><br><span class="line">zookeeper.connection.timeout.ms =6000</span><br><span class="line">#ZooKeeper的连接超时时间</span><br><span class="line">zookeeper.sync.time.ms =2000</span><br></pre></td></tr></table></figure></div><div class="tags"><a href="/tags/Kafka/">Kafka</a><a href="/tags/大数据/">大数据</a></div><div class="post-nav"><a class="pre" href="/2018/08/14/Kafka深入解析/">Kafka深入解析</a><a class="next" href="/2018/08/13/Kafka小知识点/">Kafka初步总结</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://gangtieguo.cn"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spark-On-Yarn/">Spark-On-Yarn</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spring/">Spring</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客/">博客</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/安装部署/">安装部署</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/工程框架/">工程框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/快捷键/">快捷键</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/总结/">总结</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/框架/">框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/环境配置/">环境配置</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/碎片知识/">碎片知识</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/组件/">组件</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/语言/">语言</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/大数据/" style="font-size: 15px;">大数据</a> <a href="/tags/Docker/" style="font-size: 15px;">Docker</a> <a href="/tags/CDH/" style="font-size: 15px;">CDH</a> <a href="/tags/Docker-machine/" style="font-size: 15px;">Docker-machine</a> <a href="/tags/安装部署/" style="font-size: 15px;">安装部署</a> <a href="/tags/Jenkins/" style="font-size: 15px;">Jenkins</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/HBase/" style="font-size: 15px;">HBase</a> <a href="/tags/原理/" style="font-size: 15px;">原理</a> <a href="/tags/操作/" style="font-size: 15px;">操作</a> <a href="/tags/HDFS/" style="font-size: 15px;">HDFS</a> <a href="/tags/Shell/" style="font-size: 15px;">Shell</a> <a href="/tags/Hive/" style="font-size: 15px;">Hive</a> <a href="/tags/使用/" style="font-size: 15px;">使用</a> <a href="/tags/报表/" style="font-size: 15px;">报表</a> <a href="/tags/Json/" style="font-size: 15px;">Json</a> <a href="/tags/Scala/" style="font-size: 15px;">Scala</a> <a href="/tags/Kafka/" style="font-size: 15px;">Kafka</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Mysql/" style="font-size: 15px;">Mysql</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/开发/" style="font-size: 15px;">开发</a> <a href="/tags/Ambari/" style="font-size: 15px;">Ambari</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/SSH/" style="font-size: 15px;">SSH</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/Yarn/" style="font-size: 15px;">Yarn</a> <a href="/tags/RDD/" style="font-size: 15px;">RDD</a> <a href="/tags/SparkStreaming/" style="font-size: 15px;">SparkStreaming</a> <a href="/tags/SparkSQL/" style="font-size: 15px;">SparkSQL</a> <a href="/tags/ELK/" style="font-size: 15px;">ELK</a> <a href="/tags/es/" style="font-size: 15px;">es</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/FLINK/" style="font-size: 15px;">FLINK</a> <a href="/tags/命令/" style="font-size: 15px;">命令</a> <a href="/tags/Hue/" style="font-size: 15px;">Hue</a> <a href="/tags/技术/" style="font-size: 15px;">技术</a> <a href="/tags/zk/" style="font-size: 15px;">zk</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/快捷键/" style="font-size: 15px;">快捷键</a> <a href="/tags/Mac/" style="font-size: 15px;">Mac</a> <a href="/tags/Idea/" style="font-size: 15px;">Idea</a> <a href="/tags/Finder/" style="font-size: 15px;">Finder</a> <a href="/tags/Other/" style="font-size: 15px;">Other</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(四)Spark业务代码的执行及其任务分配调度stage划分/">Spark-on-Yarn源码解析(四)Spark业务代码的执行及其任务分配调度stage划分</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(三)client做的事情/">Spark-on-Yarn源码解析(三)client做的事情</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(二)Spark-Submit解析/">Spark-on-Yarn源码解析(二)Spark-Submit解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(一)Yarn任务解析/">Spark-on-Yarn源码解析(一)Yarn任务解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/20/MapReduce中Shuffle中的机制/">MapReduce中Shuffle中的机制</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/SparkSQL介绍/">SparkSQL介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/Spark-On-yarn/">Spark-On-Yarn模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/SparkStreaming介绍/">SparkStreaming介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/SparkRDD介绍/">SparkRDD介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/Hadoop零碎知识点/">Hadoop零碎知识点</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">钢铁锅.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>