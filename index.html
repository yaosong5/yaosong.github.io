<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="纵浪大化中，不喜亦不悲"><title>钢铁锅 | 应尽便须尽，无复独多虑</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">钢铁锅</h1><a id="logo" href="/.">钢铁锅</a><p class="description">应尽便须尽，无复独多虑</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title"><a href="/2018/09/04/Spark-on-Yarn源码解析(四)Spark业务代码的执行及其任务分配调度stage划分/">Spark-on-Yarn源码解析(四)Spark业务代码的执行及其任务分配调度stage划分</a></h1><div class="post-meta">2018-09-04</div><div class="post-content"><p>spark-on-yarn系列</p>
<p><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B8%80" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (一)Yarn 任务解析</a>Yarn%E4%BB%BB%E5%8A%A1%E8%A7%A3%E6%9E%90/)<br><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%BA%8C" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (二)Spark-Submit 解析</a>Spark-Submit%E8%A7%A3%E6%9E%90/)<br><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B8%89" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (三)client 做的事情</a>client%E5%81%9A%E7%9A%84%E4%BA%8B%E6%83%85/)<br><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E5%9B%9B" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (四)Spark 业务代码的执行及其任务分配调度 stage 划分</a>Spark%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E7%9A%84%E6%89%A7%E8%A1%8C%E5%8F%8A%E5%85%B6%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D%E8%B0%83%E5%BA%A6stage%E5%88%92%E5%88%86/)</p>
<h1 id="看看自定义的类"><a href="#看看自定义的类" class="headerlink" title="看看自定义的类"></a>看看自定义的类</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"yaoWordCount"</span>).setMaster(<span class="string">"local[2]"</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="keyword">var</span> hadoopRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(args(<span class="number">0</span>))</span><br><span class="line">    <span class="keyword">var</span> hdfsRDD: <span class="type">RDD</span>[<span class="type">String</span>] = hadoopRDD.flatMap(_.split(<span class="string">""</span>))</span><br><span class="line">    <span class="comment">//单词和出现的次数，构建RDD并且调用了他的Transformation</span></span><br><span class="line">    <span class="comment">//返回的是一个hadoopRDD</span></span><br><span class="line">    <span class="comment">//transFormation都是返回的RDD</span></span><br><span class="line">    <span class="keyword">var</span> wordAndCount: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = hdfsRDD.map((_, <span class="number">1</span>))</span><br><span class="line">    <span class="comment">//创建RDD 这里面有两个RDD,一个是hadoopRDD，然后会生成一个paritionRDD</span></span><br><span class="line">    <span class="comment">//savaasTextfile还会产生一个RDD,因为会调用mapPartitons</span></span><br><span class="line">    <span class="comment">//调用RDD的action 开始真正提交任务</span></span><br><span class="line">    <span class="keyword">var</span> reducedRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordAndCount.reduceByKey(_ + _)</span><br><span class="line">    reducedRDD.saveAsTextFile(args(<span class="number">1</span>))</span><br><span class="line">    <span class="comment">//关闭saprkContext资源</span></span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><p class="readmore"><a href="/2018/09/04/Spark-on-Yarn源码解析(四)Spark业务代码的执行及其任务分配调度stage划分/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/09/04/Spark-on-Yarn源码解析(三)client做的事情/">Spark-on-Yarn源码解析(三)client做的事情</a></h1><div class="post-meta">2018-09-04</div><div class="post-content"><p>[TOC]</p>
<p>spark-on-yarn系列</p>
<p><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B8%80" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (一)Yarn 任务解析</a>Yarn%E4%BB%BB%E5%8A%A1%E8%A7%A3%E6%9E%90/)<br><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%BA%8C" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (二)Spark-Submit 解析</a>Spark-Submit%E8%A7%A3%E6%9E%90/)<br><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B8%89" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (三)client 做的事情</a>client%E5%81%9A%E7%9A%84%E4%BA%8B%E6%83%85/)<br><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E5%9B%9B" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (四)Spark 业务代码的执行及其任务分配调度 stage 划分</a>Spark%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E7%9A%84%E6%89%A7%E8%A1%8C%E5%8F%8A%E5%85%B6%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D%E8%B0%83%E5%BA%A6stage%E5%88%92%E5%88%86/)</p>
<p>org.apache.spark.deploy.yarn.Client</p>
<p>话不多说，先上源码，当然还是简洁版本的</p>
<p>这儿我先上一下最简洁的调用链。</p>
<pre><code>Client.main()
    -&gt;new Client().run()
         -&gt;monitorApplication(submitApplication())
            -&gt;submitApplication()
                -&gt;createContainerLaunchContext()会封装一些启动信息如我们启动的类 --class
                    -&gt;userClass
                    -&gt;amArgs
                    -&gt;commands
                    -&gt;printableCommands
                    -&gt;amClass applicationMaster启动的真实类

                -&gt;createApplicationSubmissionContext()
                    -&gt;Records.newRecord(classOf[Resource])启动
                -&gt;yarnClientImpl.submitApplication(appContext)                
</code></pre></div><p class="readmore"><a href="/2018/09/04/Spark-on-Yarn源码解析(三)client做的事情/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/09/04/Spark-on-Yarn源码解析(二)Spark-Submit解析/">Spark-on-Yarn源码解析(二)Spark-Submit解析</a></h1><div class="post-meta">2018-09-04</div><div class="post-content"><p>[TOC]</p>
<p>spark-on-yarn系列</p>
<p><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B8%80" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (一)Yarn 任务解析</a>Yarn%E4%BB%BB%E5%8A%A1%E8%A7%A3%E6%9E%90/)<br><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%BA%8C" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (二)Spark-Submit 解析</a>Spark-Submit%E8%A7%A3%E6%9E%90/)<br><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B8%89" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (三)client 做的事情</a>client%E5%81%9A%E7%9A%84%E4%BA%8B%E6%83%85/)<br><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E5%9B%9B" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (四)Spark 业务代码的执行及其任务分配调度 stage 划分</a>Spark%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E7%9A%84%E6%89%A7%E8%A1%8C%E5%8F%8A%E5%85%B6%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D%E8%B0%83%E5%BA%A6stage%E5%88%92%E5%88%86/)</p>
<p>上文我们了解到了yarn的架构和执行任务的流程，接下来我们看看</p>
<h1 id="spark-submit命令"><a href="#spark-submit命令" class="headerlink" title="spark-submit命令"></a>spark-submit命令</h1><pre><code>$SPARK_HOME/bin/spark-submit \
--master yarn \ //提交模式 yarn
--deploy-mode cluster \ //运行的模式，还有一种client模式，但大多用于调试，此处使用cluster模式
--class me.yao.spark.me.yao.spark.WordCount \ //提交的任务
--name &quot;wc&quot; \ //任务名字
--queue root.default \ //提交的队列
--driver-memory 3g \ //为driver申请的内存
--num-executors 1 \ //executors的数量，可以理解为线程数，对应yarn中的Container个数
--executor-memory 6g \ //为每一个executor申请的内存
--executor-cores 4 \ //为每一个executor申请的core
--conf spark.yarn.driver.memoryOverhead=1g \ //driver可使用的非堆内存，这些内存用于如VM，字符 串常量池以及其他额外本地开销等
--conf spark.yarn.executor.memoryOverhead=2g \ //每个executor可使用的非堆内存，这些内存用于如 VM，字符串常量池以及其他额外本地开销等
</code></pre><p>这是通常我们提交spark程序的submit命令，以此为切入点，对spark程序的运行流程做一个跟踪和分析。<br></div><p class="readmore"><a href="/2018/09/04/Spark-on-Yarn源码解析(二)Spark-Submit解析/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/09/04/Spark-on-Yarn源码解析(一)Yarn任务解析/">Spark-on-Yarn源码解析(一)Yarn任务解析</a></h1><div class="post-meta">2018-09-04</div><div class="post-content"><p>[TOC]</p>
<p>spark-on-yarn系列</p>
<p><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B8%80" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (一)Yarn 任务解析</a>Yarn%E4%BB%BB%E5%8A%A1%E8%A7%A3%E6%9E%90/)<br><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%BA%8C" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (二)Spark-Submit 解析</a>Spark-Submit%E8%A7%A3%E6%9E%90/)<br><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B8%89" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (三)client 做的事情</a>client%E5%81%9A%E7%9A%84%E4%BA%8B%E6%83%85/)<br><a href="http://www.gangtieguo.cn/2018/09/04/Spark-on-Yarn%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E5%9B%9B" target="_blank" rel="noopener">Spark-on-Yarn 源码解析 (四)Spark 业务代码的执行及其任务分配调度 stage 划分</a>Spark%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E7%9A%84%E6%89%A7%E8%A1%8C%E5%8F%8A%E5%85%B6%E4%BB%BB%E5%8A%A1%E5%88%86%E9%85%8D%E8%B0%83%E5%BA%A6stage%E5%88%92%E5%88%86/)</p>
<p>了解spark-on-yarn,首先我们了解一下yarn提交的流程，俗话说，欲练此功，错了，我们还是先看吧</p>
<h1 id="yarn任务的提交"><a href="#yarn任务的提交" class="headerlink" title="yarn任务的提交"></a>yarn任务的提交</h1><p>YARN 的基本架构和工作流程</p>
<p><img src="http://pebgsxjpj.bkt.clouddn.com/15358192541466.jpg" alt=""></p>
<p>YARN 的基本架构如上图所示，由三大功能模块组成，分别是 1) RM (ResourceManager) 2) NM (Node Manager) 3) AM(Application Master)<br></div><p class="readmore"><a href="/2018/09/04/Spark-on-Yarn源码解析(一)Yarn任务解析/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/08/20/MapReduce中Shuffle中的机制/">MapReduce中Shuffle中的机制</a></h1><div class="post-meta">2018-08-20</div><div class="post-content"><p>[TOC]</p>
<p>官方的shuffle流程</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNbRwgy1fuhbmle6ksj30ff07dglu.jpg" alt=""></p>
<h1 id="shuffle原理"><a href="#shuffle原理" class="headerlink" title="shuffle原理"></a>shuffle原理</h1><p>提到MapReduce，就不得不提一下shuffle。</p>
<p>MapReduce 框架的核心步骤主要分两部分：Map 和Reduce，一个是独立并发，一个是汇聚。当你向MapReduce 框架提交一个计算作业时，它会首先把计算作业拆分成若干个Map 任务，然后分配到不同的节点上去执行，每一个Map 任务处理输入数据中的一部分，当Map 任务完成后，它会生成一些中间文件，这些中间文件将会作为Reduce 任务的输入数据。Reduce 任务的主要目标就是把前面若干个Map 的输出汇总到一起并输出。</p></div><p class="readmore"><a href="/2018/08/20/MapReduce中Shuffle中的机制/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/08/16/SparkSQL介绍/">SparkSQL介绍</a></h1><div class="post-meta">2018-08-16</div><div class="post-content"><p>[TOC]</p>
<p>Hive，它是将Hive SQL转换成MapReduce然后提交到集群上执行，大大简化了编写MapReduce的程序的复杂性，由于MapReduce这种计算模型执行效率比较慢。所有Spark SQL的应运而生，它是将Spark SQL转换成RDD，然后提交到集群执行，执行效率非常快！</p></div><p class="readmore"><a href="/2018/08/16/SparkSQL介绍/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/08/16/Spark-On-yarn/">Spark-On-Yarn模式</a></h1><div class="post-meta">2018-08-16</div><div class="post-content"><p>[TOC]</p>
<h1 id="SparkOnYarn"><a href="#SparkOnYarn" class="headerlink" title="SparkOnYarn"></a>SparkOnYarn</h1><h1 id="两种模式区别"><a href="#两种模式区别" class="headerlink" title="两种模式区别"></a>两种模式区别</h1><h2 id="cluster模式："><a href="#cluster模式：" class="headerlink" title="cluster模式："></a>cluster模式：</h2><p>Driver程序在YARN中运行，应用的运行结果不能在客户端显示，所以最好运行那些将结果最终保存在外部存储介质（如HDFS、Redis、Mysql）而非stdout输出的应用程序，客户端的终端显示的仅是作为YARN的job的简单运行状况。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit --class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master yarn \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">--driver-memory 1g \</span><br><span class="line">--executor-memory 1g \</span><br><span class="line">--executor-cores 2 \</span><br><span class="line">--queue default \</span><br><span class="line">lib/spark-examples*.jar \</span><br><span class="line">10</span><br><span class="line"></span><br><span class="line">./bin/spark-submit --class cn.itcast.spark.day1.WordCount \</span><br><span class="line">--master yarn \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">--driver-memory 1g \</span><br><span class="line">--executor-memory 1g \</span><br><span class="line">--executor-cores 2 \</span><br><span class="line">--queue default \</span><br><span class="line">/home/bigdata/hello-spark-1.0.jar \</span><br><span class="line">hdfs://master:9000/wc hdfs://master:9000/out-yarn-1</span><br></pre></td></tr></table></figure></div><p class="readmore"><a href="/2018/08/16/Spark-On-yarn/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/08/16/SparkStreaming介绍/">SparkStreaming介绍</a></h1><div class="post-meta">2018-08-16</div><div class="post-content"><p>[TOC]</p>
<p>大数据领域，分为离线计算和实时计算 </p>
<p><img src="https://ws2.sinaimg.cn/large/006tNbRwgy1fuaxkz7halj30i6057dfw.jpg" alt=""></p>
<p><img src="https://ws2.sinaimg.cn/large/006tNbRwgy1fuaxl270fuj30kj034jrd.jpg" alt=""></p></div><p class="readmore"><a href="/2018/08/16/SparkStreaming介绍/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/08/16/SparkRDD介绍/">SparkRDD介绍</a></h1><div class="post-meta">2018-08-16</div><div class="post-content"><p>[TOC]</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc.textfile(<span class="string">"hdfs://master:9000/wc"</span>).flatMap(_.split(<span class="string">"分隔符"</span>)).map((_,<span class="number">1</span>)).reduceByKey(_+_).saveAsTextFile(<span class="string">"hdfs://master:9000/wcResult"</span>)</span><br></pre></td></tr></table></figure></div><p class="readmore"><a href="/2018/08/16/SparkRDD介绍/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/08/16/Hadoop零碎知识点/">Hadoop零碎知识点</a></h1><div class="post-meta">2018-08-16</div><div class="post-content"><p>[TOC]</p></div><p class="readmore"><a href="/2018/08/16/Hadoop零碎知识点/">阅读全文</a></p></div><nav class="page-navigator"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/2/">下一页</a></nav></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://gangtieguo.cn"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spark-On-Yarn/">Spark-On-Yarn</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spring/">Spring</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客/">博客</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/安装部署/">安装部署</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/工程框架/">工程框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/快捷键/">快捷键</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/总结/">总结</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/框架/">框架</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/环境配置/">环境配置</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/碎片知识/">碎片知识</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/组件/">组件</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/语言/">语言</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Mysql/" style="font-size: 15px;">Mysql</a> <a href="/tags/Docker/" style="font-size: 15px;">Docker</a> <a href="/tags/Jenkins/" style="font-size: 15px;">Jenkins</a> <a href="/tags/CDH/" style="font-size: 15px;">CDH</a> <a href="/tags/Docker-machine/" style="font-size: 15px;">Docker-machine</a> <a href="/tags/安装部署/" style="font-size: 15px;">安装部署</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/HBase/" style="font-size: 15px;">HBase</a> <a href="/tags/原理/" style="font-size: 15px;">原理</a> <a href="/tags/操作/" style="font-size: 15px;">操作</a> <a href="/tags/HDFS/" style="font-size: 15px;">HDFS</a> <a href="/tags/Shell/" style="font-size: 15px;">Shell</a> <a href="/tags/Hive/" style="font-size: 15px;">Hive</a> <a href="/tags/使用/" style="font-size: 15px;">使用</a> <a href="/tags/报表/" style="font-size: 15px;">报表</a> <a href="/tags/Json/" style="font-size: 15px;">Json</a> <a href="/tags/Scala/" style="font-size: 15px;">Scala</a> <a href="/tags/Kafka/" style="font-size: 15px;">Kafka</a> <a href="/tags/大数据/" style="font-size: 15px;">大数据</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/开发/" style="font-size: 15px;">开发</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Ambari/" style="font-size: 15px;">Ambari</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/SSH/" style="font-size: 15px;">SSH</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/Yarn/" style="font-size: 15px;">Yarn</a> <a href="/tags/RDD/" style="font-size: 15px;">RDD</a> <a href="/tags/SparkSQL/" style="font-size: 15px;">SparkSQL</a> <a href="/tags/SparkStreaming/" style="font-size: 15px;">SparkStreaming</a> <a href="/tags/ELK/" style="font-size: 15px;">ELK</a> <a href="/tags/es/" style="font-size: 15px;">es</a> <a href="/tags/FLINK/" style="font-size: 15px;">FLINK</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/Hue/" style="font-size: 15px;">Hue</a> <a href="/tags/命令/" style="font-size: 15px;">命令</a> <a href="/tags/zk/" style="font-size: 15px;">zk</a> <a href="/tags/技术/" style="font-size: 15px;">技术</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/Other/" style="font-size: 15px;">Other</a> <a href="/tags/快捷键/" style="font-size: 15px;">快捷键</a> <a href="/tags/Mac/" style="font-size: 15px;">Mac</a> <a href="/tags/Idea/" style="font-size: 15px;">Idea</a> <a href="/tags/Finder/" style="font-size: 15px;">Finder</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(四)Spark业务代码的执行及其任务分配调度stage划分/">Spark-on-Yarn源码解析(四)Spark业务代码的执行及其任务分配调度stage划分</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(三)client做的事情/">Spark-on-Yarn源码解析(三)client做的事情</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(二)Spark-Submit解析/">Spark-on-Yarn源码解析(二)Spark-Submit解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/Spark-on-Yarn源码解析(一)Yarn任务解析/">Spark-on-Yarn源码解析(一)Yarn任务解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/20/MapReduce中Shuffle中的机制/">MapReduce中Shuffle中的机制</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/SparkSQL介绍/">SparkSQL介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/Spark-On-yarn/">Spark-On-Yarn模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/SparkStreaming介绍/">SparkStreaming介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/SparkRDD介绍/">SparkRDD介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/16/Hadoop零碎知识点/">Hadoop零碎知识点</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">钢铁锅.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>