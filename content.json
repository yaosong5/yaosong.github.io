{"meta":{"title":"钢铁锅","subtitle":"应尽便须尽，无复独多虑","description":"纵浪大化中，不喜亦不悲","author":"GTG","url":"http://gangtieguo.cn"},"pages":[{"title":"","date":"2018-05-18T06:50:40.014Z","updated":"2018-05-17T01:53:01.988Z","comments":true,"path":"baidu_verify_WHXmBFaAkY.html","permalink":"http://gangtieguo.cn/baidu_verify_WHXmBFaAkY.html","excerpt":"","text":"WHXmBFaAkY"},{"title":"","date":"2018-05-18T06:50:40.022Z","updated":"2018-05-17T02:15:40.515Z","comments":true,"path":"google00655d7c846aab3a.html","permalink":"http://gangtieguo.cn/google00655d7c846aab3a.html","excerpt":"","text":"google-site-verification: google00655d7c846aab3a.html"},{"title":"404 Not Found：该页无法显示","date":"2018-05-18T06:50:42.172Z","updated":"2018-05-08T10:00:51.508Z","comments":false,"path":"/404.html","permalink":"http://gangtieguo.cn//404.html","excerpt":"","text":""},{"title":"Categories","date":"2018-05-18T06:50:42.194Z","updated":"2018-04-30T00:06:32.000Z","comments":true,"path":"categories/index.html","permalink":"http://gangtieguo.cn/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2018-05-08T07:52:07.000Z","updated":"2018-05-08T07:53:31.549Z","comments":true,"path":"about/index.html","permalink":"http://gangtieguo.cn/about/index.html","excerpt":"","text":"nothing"},{"title":"Tags","date":"2018-05-18T06:50:42.204Z","updated":"2018-04-30T00:06:32.000Z","comments":true,"path":"tags/index.html","permalink":"http://gangtieguo.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Linux安装mysql","slug":"Linux安装mysql","date":"2018-07-24T15:42:18.647Z","updated":"2018-08-06T18:18:12.944Z","comments":true,"path":"2018/07/24/Linux安装mysql/","link":"","permalink":"http://gangtieguo.cn/2018/07/24/Linux安装mysql/","excerpt":"","text":"12345678910111213141516171819yum install -y mysql-serverchkconfig --add mysqldchkconfig mysqld onchkconfig --list mysqldservice mysqld startmysql -u root -pEnter password: //默认密码为空，输入后回车即可set password for root@localhost=password('root'); 密码设置为rootset password for root@=password('root');默认情况下Mysql只允许本地登录，所以只需配置root@localhost就好设置所有ip访问密码为rootset password for root@%=password('root'); 密码设置为root （其实这一步可以不配）设置master访问密码为rootset password for root@master=password('root'); 密码设置为root （其实这一步可以不配）查询密码select user,host,password from mysql.user; 查看密码是否设置成功设置所有ip可以通过root访问GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'root' WITH GRANT OPTION;GRANT ALL PRIVILEGES ON *.* TO 'hive'@'%' IDENTIFIED BY 'hive' WITH GRANT OPTION;","categories":[{"name":"部署安装","slug":"部署安装","permalink":"http://gangtieguo.cn/categories/部署安装/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://gangtieguo.cn/tags/Linux/"},{"name":"Mysql","slug":"Mysql","permalink":"http://gangtieguo.cn/tags/Mysql/"}]},{"title":"Docker-machine的创建，mac宿主机和docker容器网络互通Docker容器与宿主机在同一ip段下","slug":"Docker-machine的搭建(与宿主机在同一ip段下)","date":"2018-07-19T19:02:08.124Z","updated":"2018-08-06T17:30:23.775Z","comments":true,"path":"2018/07/20/Docker-machine的搭建(与宿主机在同一ip段下)/","link":"","permalink":"http://gangtieguo.cn/2018/07/20/Docker-machine的搭建(与宿主机在同一ip段下)/","excerpt":"此文纯属命令记录，后续更新原理解说 更改virtual0的ip VBoxManage hostonlyif ipconfig vboxnet0 –ip 192.168.33.253 –netmask 255.255.255.0","text":"此文纯属命令记录，后续更新原理解说 更改virtual0的ip VBoxManage hostonlyif ipconfig vboxnet0 –ip 192.168.33.253 –netmask 255.255.255.0 ifconfig 查看创建虚拟机配置文件 Vagrantfile 也可以vagrant init 会生成一个空白的Vagrantfile vi Vagrantfile1234567891011121314151617181920212223Vagrant.configure(2) do |config| config.vm.box = \"dolbager/centos-7-docker\" config.vm.hostname = \"default\" config.vm.network \"private_network\", ip: \"192.168.33.1\",netmask: \"255.255.255.0\" config.vm.provider \"virtualbox\" do |v| v.name = \"default\" v.memory = \"2048\" # Change the network adapter type and promiscuous mode v.customize ['modifyvm', :id, '--nictype1', 'Am79C973'] v.customize ['modifyvm', :id, '--nicpromisc1', 'allow-all'] v.customize ['modifyvm', :id, '--nictype2', 'Am79C973'] v.customize ['modifyvm', :id, '--nicpromisc2', 'allow-all'] end # Install bridge-utils config.vm.provision \"shell\", inline: &lt;&lt;-SHELL curl -o /etc/yum.repos.d/CentOS-Base.repohttp://mirrors.aliyun.com/repo/Centos-7.repo curl -o /etc/yum.repos.d/epel.repohttp://mirrors.aliyun.com/repo/epel-7.repo yum clean all yum makecache yum update -y yum install bridge-utils net-tools -y SHELLend vagrant upvagrant ssh vagrant ssh-config 1scp ~/.vagrant.d/boxes/dolbager-VAGRANTSLASH-centos-7-docker/0.2/virtualbox/vagrant_private_key .vagrant/machines/default/virtualbox/private_key vagrant exit 1234567docker-machine create \\ --driver \"generic\" \\ --generic-ip-address 192.168.33.1 \\ --generic-ssh-user vagrant \\ --generic-ssh-key .vagrant/machines/default/virtualbox/private_key \\ --generic-ssh-port 22 \\ default 创建网桥docker1 和 docker network br通过vagrant 从虚拟机的 eth0 登录到虚拟机 vagrant sship -4 addr 创建 docker network br 123456789sudo docker network create \\ --driver bridge \\ --subnet=192.168.33.0/24 \\ --gateway=192.168.33.1 \\ --opt \"com.docker.network.bridge.enable_icc\"=\"true\" \\ --opt \"com.docker.network.bridge.enable_ip_masquerade\"=\"true\" \\ --opt \"com.docker.network.bridge.name\"=\"docker1\" \\ --opt \"com.docker.network.driver.mtu\"=\"1500\" \\ br 创建网桥配置文件docker1 vim /etc/sysconfig/network-scripts/ifcfg-docker1 123456789DEVICE=docker1TYPE=BridgeBOOTPROTO=staticONBOOT=yesSTP=onIPADDR=NETMASK=GATEWAY=DNS1= 修改网卡配置 eth1 :sudo vi /etc/sysconfig/network-scripts/ifcfg-eth1 12345678DEVICE=eth1BOOTPROTO=staticHWADDR=ONBOOT=yesNETMASK=GATEWAY=BRIDGE=docker1TYPE=Ethernet 参考：https://github.com/SixQuant/engineering-excellence/blob/master/docker/docker-install-mac-vm-centos.md","categories":[{"name":"Docker部署安装","slug":"Docker部署安装","permalink":"http://gangtieguo.cn/categories/Docker部署安装/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"},{"name":"Docker-machine","slug":"Docker-machine","permalink":"http://gangtieguo.cn/tags/Docker-machine/"}]},{"title":"Docker中hadoop，spark镜像搭建","slug":"Docker中hadoop spark集群搭建","date":"2018-07-19T18:53:35.738Z","updated":"2018-07-20T09:45:27.184Z","comments":true,"path":"2018/07/20/Docker中hadoop spark集群搭建/","link":"","permalink":"http://gangtieguo.cn/2018/07/20/Docker中hadoop spark集群搭建/","excerpt":"[toc] 配置centos集群 hadoop spark组件启动容器各组件版本对应hbase1.2 hive 版本 2.0.0 hbase1.x ZooKeeper 3.4.x is required as of HBase 1.0.0","text":"[toc] 配置centos集群 hadoop spark组件启动容器各组件版本对应hbase1.2 hive 版本 2.0.0 hbase1.x ZooKeeper 3.4.x is required as of HBase 1.0.0 拷贝文件到容器命令格式docker cp 本地文件路径 容器id或者容器名称:将所有组件下载解压并拷贝到容器1234567891011121314docker cp /Users/yaosong/Downloads/hadoop-2.8.0.tar.gz yaobigdata:/docker cp /Users/yaosong/Downloads/spark-2.2.0-bin-without-hadoop.tgz yaobigdata:/docker cp /Users/yaosong/Downloads/jdk-8u144-linux-x64.rpm yaobigdata:/docker cp /Users/yaosong/Downloads/spark-2.1.0-bin-hadoop2.6.tgz yaobigdata:/docker cp /Users/yaosong/Yao/spark源包/hive yaobigdata:/usrdocker cp /Users/yaosong/Downloads/jdk-8u144-linux-x64.rpm yaobigdata:/docker cp /Users/yaosong/Downloads/hadoop-2.8.0.tar.gz yaobigdata:/docker cp /Users/yaosong/Downloads/spark-2.2.0-bin-without-hadoop.tgz yaobigdata:/docker cp /Users/yaosong/Downloads/spark-2.1.0-bin-hadoop2.6.tgz yaobigdata:/docker cp /Users/yaosong/Yao/spark源包/hbase yaobigdata:/usrdocker cp /Users/yaosong/Yao/spark源包/zk yaobigdata:/usrdocker cp /Users/yaosong/Yao/ant yaobigdata:/usrdocker cp /Users/yaosong/Yao/maven yaobigdata:/usrdocker cp /Users/yaosong/Yao/hue4 yaobigdata:/usr \b创建homevim /etc/profilemac: vim ~/.bashrc添加以下内容123456789101112131415161718192021222324252627export JAVA_HOME=/usr/java/jdk1.8.0_144/export PATH=$JAVA_HOME:$PATHexport SCALA_HOME=/usr/scala-2.12.3/export HADOOP_HOME=/usr/hadoopexport HADOOP_CONFIG_HOME=$HADOOP_HOME/etc/hadoopexport HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoopexport PATH=$PATH:$HADOOP_HOME/binexport PATH=$PATH:$HADOOP_HOME/sbinexport SPARK_DIST_CLASSPATH=$(hadoop classpath)SPARK_MASTER_IP=masterSPARK_LOCAL_DIRS=/usr/spark-2.2.0-bin-without-hadoopSPARK_DRIVER_MEMORY=1Gexport SPARK_HOME=/usr/spark-2.2.0-bin-without-hadoopexport PATH=$SPARK_HOME/bin:$PATHexport PATH=$SPARK_HOME/sbin:$PATHMAVEN_HOME=/usr/mavenexport MAVEN_HOMEexport PATH=$&#123;PATH&#125;:$&#123;MAVEN_HOME&#125;/binANT_HOME=/usr/antPATH=$JAVA_HOME/bin:$ANT_HOME/bin:$PATHexport ANT_HOME PATHHUE_HOME=/usr/hue4export ZK_HOME=/usr/zkexport HBASE_HOME=/usr/hbaseexport PATH=$HBASE_HOME/bin:$PATHexport PATH=$ZK_HOME/bin:$PATH 创建镜像docker commit -m “bigdata + hue + zk + kafka” mm yaosong5/bigdata:2.0 创建容器123docker run -itd --net=br --name master --hostname master yaosong5/bigdata:2.0 &amp;&gt; /dev/nulldocker run -itd --net=br --name slave01 --hostname slave01 yaosong5/bigdata:2.0 &amp;&gt; /dev/nulldocker run -itd --net=br --name slave02 --hostname slave02 yaosong5/bigdata:2.0 &amp;&gt; /dev/null 停止and 删除容器123456docker stop masterdocker stop slave01docker stop slave02docker rm masterdocker rm slave01docker rm slave02 安装准备创建 hadoop 集群所需目录：12345cd $HADOOP_HOME;mkdir tmpmkdir namenodemkdir datanodecd $HADOOP_CONFIG_HOME/ 更改配置文件cd $HADOOP_CONFIG_HOME/ hdfs slavesslave01 slave02 core-site.xml：123456789101112131415161718192021222324252627282930313233343536373839 &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/hadoop/tmp&lt;/value&gt; &lt;description&gt;A base for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;final&gt;true&lt;/final&gt; &lt;description&gt;The name of the default file system. A URI whose scheme and authority determine the FileSystem implementation. The uri's scheme determines the config property (fs.SCHEME.impl) naming the FileSystem implementation class. The uri's authority is used to determine the host, port, etc. for a filesystem. &lt;/description&gt; &lt;/property&gt; &lt;!--hive的配置，参考https://blog.csdn.net/lblblblblzdx/article/details/79760959--&gt; &lt;property&gt; &lt;name&gt;hive.server2.authentication&lt;/name&gt; &lt;value&gt;NONE&lt;/value&gt; &lt;/property&gt; &lt;!--hive的配置hadoop代理用户 root用户提交的任务可以在任意机器上以任意组的所有用户的身份执行。--&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt; &lt;!--HUE 增加一个值开启 hdfs 的 web 交互--&gt;&lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;!--HUE 增加一个值开启 hdfs 的 web 交互--&gt; hdfs-site.xml：12345678910111213141516171819202122232425262728293031 &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;final&gt;true&lt;/final&gt; &lt;description&gt;Default block replication. The actual number of replications can be specified when the file is created. The default is used if replication is not specified in create time. &lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/usr/hadoop/namenode&lt;/value&gt; &lt;final&gt;true&lt;/final&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/usr/hadoop/datanode&lt;/value&gt; &lt;final&gt;true&lt;/final&gt; &lt;/property&gt;&lt;!--《为了让 hue 能够访问 hdfs，需要在 hdfs-site.xml 里面配置一些内容--&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;!--《为了让 hue 能够访问 hdfs，需要在 hdfs-site.xml 里面配置一些内容--&gt; mapred-site.xml：12345678&lt;property&gt; &lt;name&gt;mapred.job.tracker&lt;/name&gt; &lt;value&gt;master:9001&lt;/value&gt; &lt;description&gt;The host and port that the MapReduce job tracker runs at. If \"local\", then jobs are run in-process as a single map and reduce task. &lt;/description&gt;&lt;/property&gt; yarn-site.xml：12345678910111213141516171819202122232425 &lt;property&gt; &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;description&gt;Whether virtual memory limits will be enforced for containers&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt; &lt;value&gt;256mvalue&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;master:8032&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;master:8030&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;master:8031&lt;/value&gt; &lt;/property&gt; 格式化namenode1$HADOOP_HOME/bin/hadoop namenode -format 启动服务测试 yarn 8088端口 hdfs 50070端口 spark只需要在slaves中添加slave01 slave02 **sparkUI端口8080** 执行spark on yarn命令行模式1234567spark-shell --master yarn --deploy-mode client --driver-memory 1g --executor-memory 1g --executor-cores 1spark-shell --master yarn --deploy-mode client --driver-memory 512m --executor-memory 512m --executor-cores 1spark-shell --master yarn --deploy-mode client --driver-memory 350m --executor-memory 350m --executor-cores 1spark-shell --master yarn --deploy-mode client --driver-memory 650m --executor-memory 650m --executor-cores 1 整个搭建过程中首先是参照搭建网卡，创建一个centos虚拟机，在虚拟机的基础上创建了一个docker-machine(非mac可使用pipework的方式） 引用文章https://github.com/SixQuant/engineering-excellence/blob/master/docker/docker-install-mac-vm-centos.md 引用的是有ssh服务的Docker镜像**kinogmt/centos-ssh:6.7**，生成容器os 再在此基础上进行组件的安装，最后保存为镜像centos:hadoop-spark 参考文章https://blog.csdn.net/GOGO_YAO/article/details/76863201 创建了master slave01 slave02容器 yao/os：1.0 拥有sshd服务，并且开机启动，安装了rz vim等 是在yaoos容器基础上保存的建立的 yaoos是一个基础，不能删除 sz rz与服务器交互上传下载文件sudo yum install lrzsz -y","categories":[{"name":"部署安装","slug":"部署安装","permalink":"http://gangtieguo.cn/categories/部署安装/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"},{"name":"Hadoop","slug":"Hadoop","permalink":"http://gangtieguo.cn/tags/Hadoop/"},{"name":"Spark","slug":"Spark","permalink":"http://gangtieguo.cn/tags/Spark/"}]},{"title":"HIVE搭建","slug":"hive搭建","date":"2018-07-19T18:51:21.978Z","updated":"2018-08-06T18:21:59.446Z","comments":true,"path":"2018/07/20/hive搭建/","link":"","permalink":"http://gangtieguo.cn/2018/07/20/hive搭建/","excerpt":"[TOC] 配置HOME下载hive包，并解压 1http://archive.apache.org/dist/ ln -s hive-2.1.1 /usr/hive vi ~/.bashrc 1234567export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar$HIVE_HOME/bin/hiveexport HIVE_HOME=/usr/hivePATH=$HIVE_HOME/bin:$PATH#hive依赖于hadoop(可以不运行在同一主机，但是需要hadoop的配置)$HADOOP_HOME=/usr/hadoop source ~/.bashrc","text":"[TOC] 配置HOME下载hive包，并解压 1http://archive.apache.org/dist/ ln -s hive-2.1.1 /usr/hive vi ~/.bashrc 1234567export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar$HIVE_HOME/bin/hiveexport HIVE_HOME=/usr/hivePATH=$HIVE_HOME/bin:$PATH#hive依赖于hadoop(可以不运行在同一主机，但是需要hadoop的配置)$HADOOP_HOME=/usr/hadoop source ~/.bashrc 安装mysql Hive元数据介绍Hive 将元数据存储在 RDBMS 中，一般常用 MySQL 和 Derby。默认情况下，Hive 元数据保存在内嵌的 Derby 数据库中，只能允许一个会话连接，只适合简单的测试。实际生产环境中不适用， 为了支持多用户会话，则需要一个独立的元数据库，使用 MySQL 作为元数据库，Hive 内部对 MySQL 提供了很好的支持，配置一个独立的元数据库 1234567891011121314151617181920212223242526yum install -y mysql-serverchkconfig --add mysqldchkconfig mysqld onchkconfig --list mysqldservice mysqld startmysql -u root -pEnter password: //默认密码为空，输入后回车即可set password for root@localhost=password('root'); 密码设置为rootset password for root@=password('root');默认情况下Mysql只允许本地登录，所以只需配置root@localhost就好设置所有ip访问密码为rootset password for root@%=password('root'); 密码设置为root （其实这一步可以不配）设置master访问密码为rootset password for root@master=password('root'); 密码设置为root （其实这一步可以不配）查询密码select user,host,password from mysql.user; 查看密码是否设置成功设置所有ip可以通过root访问GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'root' WITH GRANT OPTION;GRANT ALL PRIVILEGES ON *.* TO 'hive'@'%' IDENTIFIED BY 'hive' WITH GRANT OPTION;mysql -uroot -prootcreate user 'hive' identified by 'hive';create user 'hive'@'%' identified by 'hive';create database hive; 配置Hivemkdir iotmp cp hive-default.xml.template hive-site.xml vim hive-site.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;configuration&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://localhost:3306/hive?characterEncoding=UTF-8&lt;/value&gt; &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;description&gt;Username to use against metastore database&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;description&gt;password to use against metastore database&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.querylog.location&lt;/name&gt; &lt;value&gt;/usr/hive/iotmp&lt;/value&gt; &lt;description&gt;Location of Hive run time structured log file&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.exec.local.scratchdir&lt;/name&gt; &lt;value&gt;/usr/hive/iotmp&lt;/value&gt; &lt;description&gt;Local scratch space for Hive jobs&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.downloaded.resources.dir&lt;/name&gt; &lt;value&gt;/usr/hive/iotmp&lt;/value&gt; &lt;description&gt;Temporary local directory for added resources in the remote file system.&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.metastore.uris&lt;/name&gt; &lt;value&gt;thrift://master:9083&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; Hive 的元数据可以存储在本地的 MySQL 中，但是大多数情况会是一个 mysql 集群，而且不在本地。所以在 hive 中需要开启远程 metastore。由于我是本地的 mysql，我就不配置下列属性了，但是如果是远程的 metastore，配置下面的属性。123456789101112&lt;property&gt; &lt;name&gt;hive.metastore.uris&lt;/name&gt; &lt;value&gt;&lt;/value&gt; &lt;description&gt;Thrift URI for the remote metastore. Used by metastore client to connect to remote metastore.&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.server2.transport.mode&lt;/name&gt; &lt;value&gt;http&lt;/value&gt; &lt;description&gt;Server transport mode. \"binary\" or \"http\".&lt;/description&gt;&lt;/property&gt;链接：https://www.jianshu.com/p/87b76a686216 Hive命令启动hiveserver21$HIVE_HOME/bin/hive --service hiveserver2 hiveserver端口号默认是10000 hiveserver2是否启动netstat -nl|grep 10000 启动hive123$HIVE_HOME/bin/hive如果调试，可以加上参数$HIVE_HOME/bin/hivehive -hiveconf hive.root.logger=DEBUG,console beeline工具测试使用jdbc方式连接1$HIVE_HOME/bin/beeline -u jdbc:hive2://localhost:10000 使用beeline通过jdbc连接上之后就可以像client一样操作。 hiveserver2会同时启动一个webui，端口号默认为10002，可以通过http://localhost:10002/访问界面中可以看到Session/Query/Software等信息。(此网页只可查看，不可以操作hive数据仓库) 参考https://blog.csdn.net/lblblblblzdx/article/details/79760959 参考https://www.cnblogs.com/netuml/p/7841387.html 报错 报错 Hive 2.3.3 MetaException(message:Version information not found in metastore.) 1schematool -initSchema -dbType mysql 参考https://stackoverflow.com/questions/50230515/hive-2-3-3-metaexceptionmessageversion-information-not-found-in-metastore http://sishuok.com/forum/blogPost/list/6221.html https://blog.csdn.net/nokia_hp/article/details/79054079","categories":[{"name":"部署安装","slug":"部署安装","permalink":"http://gangtieguo.cn/categories/部署安装/"}],"tags":[{"name":"DOCKER","slug":"DOCKER","permalink":"http://gangtieguo.cn/tags/DOCKER/"},{"name":"HIVE","slug":"HIVE","permalink":"http://gangtieguo.cn/tags/HIVE/"}]},{"title":"docker构建免密ssh登录镜像","slug":"Docker构建免密登录镜像","date":"2018-07-19T18:49:08.996Z","updated":"2018-08-06T16:53:17.979Z","comments":true,"path":"2018/07/20/Docker构建免密登录镜像/","link":"","permalink":"http://gangtieguo.cn/2018/07/20/Docker构建免密登录镜像/","excerpt":"免密登录参考的是http://www.shushilvshe.com/data/docker-ssh.html文中涉及命令12345sudo yum -y install openssh-server openssh-clientsssh-keygen -t rsacp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keyschmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys","text":"免密登录参考的是http://www.shushilvshe.com/data/docker-ssh.html文中涉及命令12345sudo yum -y install openssh-server openssh-clientsssh-keygen -t rsacp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keyschmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys vim /etc/ssh/sshd_config 找到以下内容，并去掉注释符”#“ 123RSAAuthentication yesPubkeyAuthentication yesAuthorizedKeysFile .ssh/authorized_keys vim /etc/ssh/ssh_config 123Host * StrictHostKeyChecking no UserKnownHostsFile=/dev/null ​ 此文也可参考 http://www.voidcn.com/article/p-gxkeusey-ma.html https://blog.csdn.net/a85820069/article/details/78745899坑使用 docker run -i -t –name c1 centos6.6:basic /bin/bash 运行容器，sshd 服务是不开启的，必须先 - d 在用 exec 切入。 https://www.cnblogs.com/aiweixiao/p/5516974.html 1.【查看是否启动】 启动 SSH 服务 “/etc/init.d/sshd start”。然后用 netstat -antulp | grep ssh 看是否能看到相关信息就可以了。 2.【设置自动启动】 如何设置把 ssh 等一些服务随系统开机自动启动？ 方法一：[root@localhost ~]# vi /etc/rc.local 加入：service sshd start 或 /etc/init.d/sshd start chmod 777 /etc/ssh/ssh_host_ecdsa_key 12345678910111213141516# 免密登录mkdir -p /root/.ssh touch /root/.ssh/config echo &quot;StrictHostKeyChecking no&quot; &gt; /root/.ssh/config sed -i &quot;a UserKnownHostsFile /dev/null&quot; /root/.ssh/config # 开机启动RUN yum install -y openssh-server sudo RUN sed -i &apos;s/UsePAM yes/UsePAM no/g&apos; /etc/ssh/sshd_config # 下面这两句比较特殊，在centos6上必须要有，否则创建出来的容器sshd不能登录RUN ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key RUN ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key ssh服务文章当中的12345678910111213curl http://mirrors.aliyun.com/repo/Centos-6.repo &gt; /etc/yum.repos.d/CentOS-Base-6-aliyun.repomv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bakyum makecacheyum install -y net-tools which openssh-clients openssh-server iproute.x86_64 wgetservice sshd startsed -i 's/UsePAM yes/UsePAM no/g' /etc/ssh/sshd_configsed -ri 's/session required pam_loginuid.so/#session required pam_loginuid.so/g' /etc/pam.d/sshdchkconfig sshd oncd ~;ssh-keygen -t rsa -P '' -f ~/.ssh/id_dsa;cd .ssh;cat id_dsa.pub &gt;&gt; authorized_keys","categories":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"}]},{"title":"","slug":"coudearManager镜像搭建","date":"2018-07-10T14:10:04.881Z","updated":"2018-07-27T04:10:12.850Z","comments":true,"path":"2018/07/10/coudearManager镜像搭建/","link":"","permalink":"http://gangtieguo.cn/2018/07/10/coudearManager镜像搭建/","excerpt":"","text":"docker run -itd –net=br –name cm –hostname cm yaosong5/centosbase:1.0 &amp;&gt; /dev/null 将下载的包进行解压然后进行拷贝 docker cp /Users/yaosong/Yao/cloudera-manager-el6-cm5.9.0_x86_64/cloudera 8a3b1b4b5386:/opt/docker cp /Users/yaosong/Yao/cloudera-manager-el6-cm5.9.0_x86_64/cm-5.9.0 8a3b1b4b5386:/opt/ docker cp /Users/yaosong/Yao/mysql-connector-java-5.1.40-bin.jar 8a3b1b4b5386:/opt/cm-5.9.0/share/cmf/lib/ docker cp /Users/yaosong/Yao/mysql-connector-java.jar 8a3b1b4b5386:/usr/share/java/ docker cp /Users/yaosong/Yao/jdk1.8 8a3b1b4b5386:/usr/local/ 将 parcel 文件放至 /opt/cloudera/parcel-repo docker cp /Users/yaosong/Yao/CDH-5.9.0-1.cdh5.9.0.p0.23-el6.parcel 8a3b1b4b5386:/opt/cloudera/parcel-repodocker cp /Users/yaosong/Yao/CDH-5.9.0-1.cdh5.9.0.p0.23-el6.parcel.sha 8a3b1b4b5386:/opt/cloudera/parcel-repodocker cp /Users/yaosong/Yao/manifest.json 8a3b1b4b5386:/opt/cloudera/parcel-repo vim /etc/profileexport JAVA_HOME=/usr/local/jdk1.8 export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar usr/share/java 并重新命名为 mysql-connector-java.jar 初始化 mysql 库 [root@server1 cm-5.9.0]# /opt/cm-5.9.0/share/cmf/schema/scm_prepare_database.sh mysql cm -hlocalhost -uroot -proot –scm-host localhost scm scm scm 创建用户（所有节点执行） [root@server1 cm-5.9.0]# useradd –system –home=/opt/cm-5.9.0/run/cloudera-scm-server/ –no-create-home –shell=/bin/false –comment “Cloudera SCM User” cloudera-scm Agent 配置 vim /opt/cm-5.9.0/etc/cloudera-scm-agent/config.ini 将 server_host 改为主节点主机名 server_host=cm1 安装mysqlchkconfig mysqld on 5、设置允许远程登录 mysql -u root -p你的密码GRANT ALL PRIVILEGES ON . TO ‘root‘@’%’ IDENTIFIED BY ‘root’ WITH GRANT OPTION;6、创建CM用的数据库 安装集群时按需创建，详见第七章第13步 –hive数据库create database hive DEFAULT CHARSET utf8 COLLATE utf8_general_ci;–oozie数据库create database oozie DEFAULT CHARSET utf8 COLLATE utf8_general_ci;–hue数据库create database hue DEFAULT CHARSET utf8 COLLATE utf8_general_ci; Cloudera推荐设置 在试安装的过程，发现Cloudera给出了一些警告，如下图： 身为一个有洁癖的码农，自然是连黄色的感叹号都要消灭的。因此在安装CM/CDH之前就先全部设置好。 1、设置swap空间 vim /etc/sysctl.conf末尾加上vm.swappiness=10 2、关闭大页面压缩 试过只设置defrag，但貌似个别节点还是会有警告，干脆全部设置 vim /etc/rc.local末尾加上(永久生效)echo never &gt; /sys/kernel/mm/transparent_hugepage/enabledecho never &gt; /sys/kernel/mm/transparent_hugepage/defrag 创建 cdh 所需要的库 create database hive DEFAULT CHARSET utf8 COLLATE utf8_general_ci; create database amon DEFAULT CHARSET utf8 COLLATE utf8_general_ci; create database hue DEFAULT CHARSET utf8 COLLATE utf8_general_ci; create database monitor DEFAULT CHARSET utf8 COLLATE utf8_general_ci; create database oozie DEFAULT CHARSET utf8 COLLATE utf8_general_ci; 89dde192b411:/cdh-rpm docker cp /Users/yaosong/Yao/cloudera-manager-agent-5.9.0-1.cm590.p0.249.el6.x86_64.rpm 89dde192b411:/cdh-rpmdocker cp /Users/yaosong/Yao/cloudera-manager-daemons-5.9.0-1.cm590.p0.249.el6.x86_64.rpm 89dde192b411:/cdh-rpmdocker cp /Users/yaosong/Yao/cloudera-manager-server-5.9.0-1.cm590.p0.249.el6.x86_64.rpm 89dde192b411:/cdh-rpmdocker cp /Users/yaosong/Yao/cloudera-manager-server-db-2-5.9.0-1.cm590.p0.249.el6.x86_64.rpm 89dde192b411:/cdh-rpmdocker cp /Users/yaosong/Yao/enterprise-debuginfo-5.9.0-1.cm590.p0.249.el6.x86_64.rpm 89dde192b411:/cdh-rpmdocker cp /Users/yaosong/Yao/jdk-6u31-linux-amd64.rpm 89dde192b411:/cdh-rpmdocker cp /Users/yaosong/Yao/oracle-j2sdk1.7-1.7.0+update67-1.x86_64.rpm 89dde192b411:/cdh-rpm 启动cloudera manager 服务/opt/cm-5.9.0/etc/init.d/cloudera-scm-server start /opt/cm-5.9.0/etc/init.d/cloudera-scm-agent start 端口 7180 保存为镜像： docker commit -m “cloudera manger image” cm yaosong5/cm59:1.0创建容器： docker run -itd –net=br –name cm1 –hostname cm1 yaosong5/cm59:1.0 &amp;&gt; /dev/null docker run -itd –net=br –name cm2 –hostname cm2 yaosong5/cm59:1.0 &amp;&gt; /dev/null docker run -itd –net=br –name cm3 –hostname cm3 yaosong5/cm59:1.0 &amp;&gt; /dev/null docker stop cm1docker stop cm2docker stop cm3 docker rm cm1docker rm cm2docker rm cm3 调错 .SearchRepositoryManager: No read permission to the server storage directory [/var/lib/cloudera-scm-server]2018-07-11 10:20:39,788 ERROR SearchRepositoryManager-0:com.cloudera.server.web.cmf.search.components.SearchRepositoryManager: No write permission to the server storage directory [/var/lib/cloudera-scm-server] 链接hue连接不上节点的 cm-5.x.0/log/cloudera-scm-server/cloudera-scm-server.log，一般情况下应该会说到 ImportError:libxslt.so.1:cannot open shared object file:No such file ordirectory yum -y install libxml2-python 提示hue测试连接连接不上，安装依赖： yum install libxml2-python mod_ssl install krb5-devel cyrus-sasl-gssapi cyrus-sasl-deve libxml2-devel libxslt-devel mysql mysql-devel openldap-devel python-devel python-simplejson sqlite-devel -y","categories":[],"tags":[]},{"title":"","slug":"ambari搭建","date":"2018-07-09T17:08:44.939Z","updated":"2018-07-27T08:07:46.566Z","comments":true,"path":"2018/07/10/ambari搭建/","link":"","permalink":"http://gangtieguo.cn/2018/07/10/ambari搭建/","excerpt":"","text":"docker run -itd –net=br –name ambari-agent –hostname ambari-agent yaosong5/centosbase:1.0 &amp;&gt; /dev/null 关闭 selinux , 需要重启vim /etc/selinux/config SELINUX=disabled serverwget http://public-repo-1.hortonworks.com/ambari/centos6/2.x/updates/2.0.1/ambari.repocp ambari.repo /etc/yum.repos.dyum install epel-releaseyum repolistyum install ambari-serverambari-server setup会有一连串的提示 安装agent yum install -y ambari-agent chkconfig –add ambari-agent ambari-agent start ambari-server start docker cp /Users/yaosong/Yao/jdk-7u67-linux-x64.tar.gz f2858ae3ecb6:/var/lib/ambari-server/resources/ 会提示安装 jdk，网速好的可以确定，否则可以下载 jdk-6u31-linux-x64.bin，放到 /var/lib/ambari-server/resources/ 下面接着会提示配置用的数据库，可以选择 Oracle 或 postgresql，选择 n 会按默认配置数据库类型：postgresql数据库：ambari用户名：ambari密码：bigdata如果提示 Oracle JDK license，yes等待安装完成 安装 ambari-agent 将 ambari.server 上的 3 个. repo 文件复制到 hadoop 集群的三台服务器上；并完成 yum 源更新的命令。 安装 ambari-agent：在集群的 3 台电脑上执行添加，并添加成开机自启动服务： yum install -y ambari-agent chkconfig –add ambari-agent sudo ambari-agent start http://192.168.1.133:8080用户名密码: admin,admin docker commit -m “bigdata:ambari-server” –author=”yaosong” ambr yaosong5/ambari-server:1.0 docker run -itd –net=br –name ambari-server –hostname ambari-server yaosong5/ambari-server:1.0 &amp;&gt; /dev/null docker run -itd –net=br –name amagent1 –hostname amagent1 yaosong5/centosbase:1.0 &amp;&gt; /dev/nulldocker run -itd –net=br –name amagent2 –hostname amagent2 yaosong5/centosbase:1.0 &amp;&gt; /dev/null 创建容器docker run -itd –net=br –name ambari1 –hostname ambari1 yaosong5/ambari-server:1.0 &amp;&gt; /dev/nulldocker run -itd –net=br –name ambari2 –hostname ambari2 yaosong5/ambari-server:1.0 &amp;&gt; /dev/nulldocker run -itd –net=br –name ambari3 –hostname ambari3 yaosong5/ambari-server:1.0 &amp;&gt; /dev/null docker stop ambari1docker stop ambari2docker stop ambari3 docker rm ambari1docker rm ambari2docker rm ambari3","categories":[],"tags":[]},{"title":"Hue搭建","slug":"hue搭建","date":"2018-07-09T16:37:50.903Z","updated":"2018-08-06T18:17:03.862Z","comments":true,"path":"2018/07/10/hue搭建/","link":"","permalink":"http://gangtieguo.cn/2018/07/10/hue搭建/","excerpt":"[TOC] 本次采用的ant maven来编译hue启动一个基础容器docker run -itd --net=br --name hue --hostname hue yaosong5/centosbase:1.0 &amp;&gt; /dev/null","text":"[TOC] 本次采用的ant maven来编译hue启动一个基础容器docker run -itd --net=br --name hue --hostname hue yaosong5/centosbase:1.0 &amp;&gt; /dev/null 拷贝源包将ant、hue4.0.0、ant、maven等下载到本地结业后，再拷贝到容器（这样更快速） docker cp /Users/yaosong/Yao/ant 4115ea59088e:/ docker cp /Users/yaosong/Yao/maven 4115ea59088e:/ docker cp /Users/yaosong/Yao/hue4 4115ea59088e:/usr/ 配置HOME12345678910vim ~/.bashrc加入MAVEN_HOME=/mavenexport MAVEN_HOMEexport PATH=$&#123;PATH&#125;:$&#123;MAVEN_HOME&#125;/binANT_HOME=/antPATH=$JAVA_HOME/bin:$ANT_HOME/bin:$PATHHUE_HOME=/hue4使其生效source ~/.bashrc 安装依赖，编译hue需要安装一些依赖yum install gmp-devel -y 参考 http://www.aizhuanji.com/a/0Vo0qEMW.html 若解决不了1yum install asciidoc cyrus-sasl-devel cyrus-sasl-gssapi cyrus-sasl-plain gcc gcc-c++ krb5-devel libffi-devel libtidy libxml2-devel libxslt-devel make mysql-devel openldap-devel sqlite-devel openssl-devel gmp-devel -y 参考链接：https://www.jianshu.com/p/417788238e3d \b编译安装hue首先编译 Hue，并在要安装 Hue 的节点上创建 Hue 用户和 hue 组 创建 Hue 用户1234groupadd hueuseradd hue -g huecd $HUE_HOMEchown -R hue:hue * 注：需要注意的是 hue 在编译时有两种方式:1.通过maven、ant编译 2.通过python编译（在centos6.5因为自身python为2.6.6版本和hue编译需要2.7版本会有一点小冲突，故采用1）两种方式都是在hue目录下 make apps，只是第一种方式要先配置maven、ant的环境而已 12cd $HUE_HOMEmake apps 参考 ：https://blog.csdn.net/u012802702/article/details/68071244 如果报错 1/usr/hue4/Makefile.vars:42: *** &quot;Error: must have python development packages for 2.6 or 2.7. Could not find Python.h. Please install python2.6-devel or python2.7-devel&quot;. Stop. 需执行 1234可以先查看一下含 python-devel 的包yum search python | grep python-devel64 位安装 python-devel.x86_64，32 位安装 python-devel.i686，我这里安装:sudo yum install python-devel.x86_64 -y 更改hue的配置文件vim $HUE_HOME/desktop/conf/hue.ini mysql找到位置更改host hive123hive_server_host=masterhive_server_port=10000hive_conf_dir=$HIVE_HOME/conf hadoop-hdfs12345fs_defaultfs=hdfs://master:9000logical_name=masterwebhdfs_url=http://master:50070/webhdfs/v1hadoop_hdfs_home=$HADOOP_HOMEhadoop_conf_dir=$HADOOP_HOME/etc/hadoop hadoop-yarn在 [hadoop].[[yarn_clusters]].[[[default]]] 下 1234resourcemanager_host=masterresourcemanager_port=8032resourcemanager_api_url=http://master:8088proxy_api_url=http://master:8088 hbase在 [hbase] 节点下 123hbase_clusters=(HBASE|master:9090)hbase_conf_dir=$HBASE_HOME/confuse_doas=true 大数据各组件满足hue进行相应配置安装mysql由于需要hue需要存放一些元数据故安装mysql 12345678910111213yum install -y mysql-serverservice mysqld startmysql -u root -pEnter password: //默认密码为空，输入后回车即可set password for root@localhost=password('root'); 密码设置为root默认情况下Mysql只允许本地登录，所以只需配置root@localhost就好set password for root@%=password('root'); 密码设置为root （其实这一步可以不配）set password for root@master=password('root'); 密码设置为root （其实这一步可以不配）select user,host,password from mysql.user; 查看密码是否设置成功GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'root' WITH GRANT OPTION;create database hue; 报错DatabaseError DatabaseError:(1146,”Table ‘hue.desktop_settings’ doesn’t exist”)-初始化mysql 完成以上的这个配置，启动 Hue, 通过浏览器访问，会发生错误，原因是 mysql 数据库没有被初始化DatabaseError: (1146,”Table ‘hue.desktop_settings’ doesn’t exist”)执行以下指令对 hue 数据库进行初始化 123cd $HUE_HOME/build/env/bin/hue syncdbbin/hue migrate 此外需要注意的是如果使用的是：$HUE_HOME/build/env/bin/hue syncdb --noinput 则不会让输入初始的用户名和密码，只有在首次登录时才会让输入，作为超级管理员账户。\b hdfshdfs-site.xml增加一个值开启 hdfs 的 web 交互123456 &lt;!--HUE 增加一个值开启 hdfs 的 web 交互--&gt;&lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; &lt;!--HUE 增加一个值开启 hdfs 的 web 交互--&gt; core-site.xml12345678910&lt;!--《为了让 hue 能够访问 hdfs，需要在 hdfs-site.xml 里面配置一些内容--&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;!--《为了让 hue 能够访问 hdfs，需要在 hdfs-site.xml 里面配置一些内容--&gt; hbasehbase-site.xml 12345678910&lt;!-- hue支持 --&gt;&lt;property&gt; &lt;name&gt;hbase.thrift.support.proxyuser&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.regionserver.thrift.http&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;!-- hue支持 --&gt; hue 访问 hbase 是用的 thriftserver，并且是 thrift1，不是 thrift2，所以要在 master 上面启动 thrif1 1$HBASE_HOME/bin/hbase-daemon.sh start thrift 参考 https://blog.csdn.net/Dante_003/article/details/78889084 读取hbase问题为解决访问Failed to authenticate to HBase Thrift Server, check authentication configurations.需要在hue的配置文件中配置 1use_doas=true 参考http://gethue.com/hbase-browsing-with-doas-impersonation-and-kerberos/ 若以上配置未能解决问题，还需要将core-site.xml拷贝到hbase/conf，并添加以下内容 12345678&lt;property&gt; &lt;name&gt;hadoop.proxyuser.hbase.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.hbase.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt; [参考]https://blog.csdn.net/u012802702/article/details/68071244 hiveHue 与框架 Hive 的集成开启 Hive Remote MetaStorenohup $HIVE_HOME/bin/hive --service metastore &amp; hive 只需启动 hiveserver2，thriftserver 的 10000 端口启动即可123nohup $HIVE_HOME/bin/hiveserver2 &amp;或者nohup HIVE_HOME/bin/hive --service hiveserver2 &amp; 解决 hue ui 界面查询中文乱码问题在 [[[mysql]]]节点下 1options=&#123;\"init_command\":\"SET NAMES'utf8'\"&#125; [参考]https://blog.csdn.net/u012802702/article/details/68071244 ### 依赖的组件启动Mysqlservice mysqld start hadoopstart-all.sh hive然后需要同时启动 hive 的 metastore 和 hiveserve2 12nohup hive --service metastore &amp;nohup hive --service hiveserver2 &amp; hbaseHue 需要读取 HBase 的数据是使用 thrift 的方式，默认 HBase 的 thrift 服务没有开启，所有需要手动额外开启 thrift 服务。 启动 thrift service$HBASE_HOME/bin/hbase-daemon.sh start thrift thrift service 默认使用的是 9090 端口，使用如下命令查看端口是否被占用 netstat -nl|grep 9090 依赖启动的脚本1234567891011#!/bin/bash#启动mysqlservice mysqld start#启动hadoopsh /hadoop-start.sh#启动hivesh /hive-start-servers2.sh#启动 thrift service$HBASE_HOME/bin/hbase-daemon.sh start thrift#启动huenohup $HUE_HOME/build/env/bin/supervisor &amp; hue启动命令&```1234567891011121314151617181920(注：想要后台执行就是 **$HUE_HOME/build/env/bin/supervisor &amp;** )或者`$HUE_HOME/build/env/bin/hue runserver_plus 0.0.0.0:8888`&gt;&gt; 【参考】https://blog.csdn.net/hexinghua0126/article/details/80338779&gt;**hue的\bweb服务端口：8888*## hue停止命令`pkill -U hue`# 报错1、如果修改配置文件后，启动后无法进人 hue 界面 可能是配置文件被锁住了cd $HUE_HOME/desktop/confls –arm –rf hue.ini.swp或者 hadoop、hive 等服务没有启动起来123456789101112132、在 hue\b界面异常，导致 hive 无法使用安装插件：`yum install cyrus-sasl-plain cyrus-sasl-devel cyrus-sasl-gssapi`# 操作镜像## 保存为镜像`docker commit -m &quot;hue&quot; hue yaosong5/hue4:1.0`## 创建容器`docker run -itd --net=br --name gethue --hostname gethue gethue/hue:latest &amp;&gt; /dev/null`\b映射宿主机的\b\bhosts文件及其hue的配置文件方式启动容器 docker run –name=hue -d –net=br -v /etc/hosts/:/etc/hosts -v $PWD/pseudo-distributed.ini:/hue/desktop/conf/pseudo-distributed.ini yaosong5/hue4:1.01234567--net=br为\b了宿主机和容器之前ip自由访问所搭建的网络模式，如有需求\b请参考**其他参考**```bashdocker run --name=hue -d --net=br -v /etc/hosts/:/etc/hosts -v $PWD/pseudo-distributed.ini:/hue/desktop/conf/pseudo-distributed.ini gethue/hue:latest 参考：https://blog.csdn.net/Dante_003/article/details/78889084","categories":[{"name":"部署安装","slug":"部署安装","permalink":"http://gangtieguo.cn/categories/部署安装/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"},{"name":"Hue","slug":"Hue","permalink":"http://gangtieguo.cn/tags/Hue/"}]},{"title":"","slug":"es测试命令","date":"2018-07-09T16:11:03.158Z","updated":"2018-07-09T16:11:04.913Z","comments":true,"path":"2018/07/10/es测试命令/","link":"","permalink":"http://gangtieguo.cn/2018/07/10/es测试命令/","excerpt":"","text":"curl -H “Content-Type: application/json” -XPUT ‘http://localhost:9200/store/books/1&#39; -d ‘{ “title”: “Elasticsearch: The Definitive Guide”, “name” : { “first” : “Zachary”, “last” : “Tong” }, “publish_date”:”2015-02-06”, “price”:”49.99”}’ 在添加一个书的信息curl -H “Content-Type: application/json” -XPUT ‘http://elk1:9200/store/books/2&#39; -d ‘{“title”: “Elasticsearch Blueprints”, “name” : { “first” : “Vineeth”, “last” : “Mohan” },“publish_date”:”2015-06-06”,“price”:”35.99”}’通过ID获得文档信息curl -H “Content-Type: application/json” -XGET ‘http://elk1:9200/store/books/1&#39; curl -H “Content-Type: application/json” -XGET ‘http://elk1:9200/store/books/_search&#39; -d ‘{“query” : { “filtered” : { “query” : { “match_all” : {} }, “filter” : { “term” : { “price” : 35.99 } } } }}’ 在浏览 curl -H “Content-Type: application/json” -XPUT ‘http://elk1:9200/store/books/1&#39; -d ‘{ “title”: “Elasticsearch: The Definitive Guide”, “name” : { “first” : “Zachary”, “last” : “Tong” }, “publish_date”:”2015-02-06”, “price”:”49.99”}’ curl -H “Content-Type: application/json” -XPUT ‘http://127.0.0.1:9200/kc22k2_test’ -d ‘ curl -XPUT elk1:9200/test curl -XGET ‘http://elk1:9200/_cluster/state?pretty&#39;{ “error” : { “root_cause” : [ { “type” : “master_not_discovered_exception”, “reason” : null } ], “type” : “master_not_discovered_exception”, “reason” : null }, “status” : 503}","categories":[],"tags":[]},{"title":"hadoop-spark组合容器的搭建","slug":"hadoop-spark集群搭建","date":"2018-07-08T17:06:20.114Z","updated":"2018-08-06T18:17:55.879Z","comments":true,"path":"2018/07/09/hadoop-spark集群搭建/","link":"","permalink":"http://gangtieguo.cn/2018/07/09/hadoop-spark集群搭建/","excerpt":"[TOC] 配置centos集群 hadoop spark组件启动容器各组件版本对应hbase1.2 hive 版本 2.0.0 hbase1.x ZooKeeper 3.4.x is required as of HBase 1.0.0 新建容器，为减少工作量，引用的是有ssh服务的Docker镜像kinogmt/centos-ssh:6.7，生成容器os为基准。 1docker run -itd --name bigdata --hostname bigdata kinogmt/centos-ssh:6.7 &amp;&gt; /dev/null 注意必须要以-d方式启动，不然sshd服务不会启动，这算是一个小bug","text":"[TOC] 配置centos集群 hadoop spark组件启动容器各组件版本对应hbase1.2 hive 版本 2.0.0 hbase1.x ZooKeeper 3.4.x is required as of HBase 1.0.0 新建容器，为减少工作量，引用的是有ssh服务的Docker镜像kinogmt/centos-ssh:6.7，生成容器os为基准。 1docker run -itd --name bigdata --hostname bigdata kinogmt/centos-ssh:6.7 &amp;&gt; /dev/null 注意必须要以-d方式启动，不然sshd服务不会启动，这算是一个小bug 在容器中下载需要的elk的源包。做解压就不赘述，很多案例教程。 我是采用的下载到宿主机，解压后，用 “docker cp 解压包目录 os:/usr/loca/“来传到容器内，比在容器内下载速度更快 拷贝文件到容器命令格式docker cp 本地文件路径 容器id或者容器名称:将所有组件下载解压并拷贝到容器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&gt; docker cp /Users/yaosong/Downloads/hadoop-2.8.0.tar.gz bigdata:/&gt; docker cp /Users/yaosong/Downloads/spark-2.2.0-bin-without-hadoop.tgz bigdata:/&gt; docker cp /Users/yaosong/Downloads/jdk-8u144-linux-x64.rpm bigdata:/&gt; docker cp /Users/yaosong/Downloads/spark-2.1.0-bin-hadoop2.6.tgz bigdata:/&gt; docker cp /Users/yaosong/Yao/spark源包/hive bigdata:/usr&gt; docker cp /Users/yaosong/Downloads/jdk-8u144-linux-x64.rpm bigdata:/&gt; docker cp /Users/yaosong/Downloads/hadoop-2.8.0.tar.gz bigdata:/&gt; docker cp /Users/yaosong/Downloads/spark-2.2.0-bin-without-hadoop.tgz bigdata:/&gt; docker cp /Users/yaosong/Downloads/spark-2.1.0-bin-hadoop2.6.tgz bigdata:/&gt; docker cp /Users/yaosong/Yao/spark源包/hbase bigdata:/usr&gt; docker cp /Users/yaosong/Yao/spark源包/zk bigdata:/usr&gt; docker cp /Users/yaosong/Yao/ant bigdata:/usr&gt; docker cp /Users/yaosong/Yao/maven bigdata:/usr&gt; docker cp /Users/yaosong/Yao/hue4 bigdata:/usr&gt; \b创建home&gt;&gt; vim /etc/profile&gt;&gt; mac: vim ~/.bashrc&gt;&gt; 添加以下内容&gt;&gt; export JAVA_HOME=/usr/java/jdk&gt; export PATH=$JAVA_HOME:$PATH&gt; export SCALA_HOME=/usr/scala-2.12.3/&gt; export HADOOP_HOME=/usr/hadoop&gt; export HADOOP_CONFIG_HOME=$HADOOP_HOME/etc/hadoop&gt; export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop&gt; export PATH=$PATH:$HADOOP_HOME/bin&gt; export PATH=$PATH:$HADOOP_HOME/sbin&gt; export SPARK_DIST_CLASSPATH=$(hadoop classpath)&gt; SPARK_MASTER_IP=master&gt; SPARK_LOCAL_DIRS=/usr/spark&gt; SPARK_DRIVER_MEMORY=1G&gt; export SPARK_HOME=/usr/spark&gt; export PATH=$SPARK_HOME/bin:$PATH&gt; export PATH=$SPARK_HOME/sbin:$PATH&gt; &gt; MAVEN_HOME=/usr/maven&gt; export MAVEN_HOME&gt; export PATH=$&#123;PATH&#125;:$&#123;MAVEN_HOME&#125;/bin&gt; ANT_HOME=/usr/ant&gt; PATH=$JAVA_HOME/bin:$ANT_HOME/bin:$PATH&gt; export ANT_HOME PATH&gt; HUE_HOME=/usr/hue4&gt; export ZK_HOME=/usr/zk&gt; export HBASE_HOME=/usr/hbase&gt; export PATH=$HBASE_HOME/bin:$PATH&gt; export PATH=$ZK_HOME/bin:$PATH&gt;&gt;&gt;&gt; 安装创建 hadoop 集群所需目录：在以下配置文件中会有以下目录 12345cd $HADOOP_HOME;mkdir tmpmkdir namenodemkdir datanodecd $HADOOP_CONFIG_HOME/ 更改配置文件cd $HADOOP_CONFIG_HOME/ or cd $HADOOP_HOME/etc/hadoop hdfs slavesslave01 slave02 core-site.xml：12345678910111213141516171819202122232425262728293031323334&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/hadoop/tmp&lt;/value&gt; &lt;description&gt;A base for other temporary directories.&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;final&gt;true&lt;/final&gt; &lt;description&gt;The name of the default file system. A URI whose scheme and authority determine the FileSystem implementation. &lt;/description&gt; &lt;/property&gt; &lt;!--hive的配置，参考https://blog.csdn.net/lblblblblzdx/article/details/79760959--&gt; &lt;property&gt; &lt;name&gt;hive.server2.authentication&lt;/name&gt; &lt;value&gt;NONE&lt;/value&gt; &lt;/property&gt; &lt;!--hive的配置hadoop代理用户 root用户提交的任务可以在任意机器上以任意组的所有用户的身份执行。--&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;!--HUE 增加一个值开启 hdfs 的 web 交互--&gt; &lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!--HUE 增加一个值开启 hdfs 的 web 交互--&gt; hdfs-site.xml：12345678910111213141516171819202122232425262728293031&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;final&gt;true&lt;/final&gt; &lt;description&gt;Default block replication. The actual number of replications can be specified when the file is created. The default is used if replication is not specified in create time. &lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/usr/hadoop/namenode&lt;/value&gt; &lt;final&gt;true&lt;/final&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/usr/hadoop/datanode&lt;/value&gt; &lt;final&gt;true&lt;/final&gt;&lt;/property&gt;&lt;!--《为了让 hue 能够访问 hdfs，需要在 hdfs-site.xml 里面配置一些内容--&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;!--《为了让 hue 能够访问 hdfs，需要在 hdfs-site.xml 里面配置一些内容--&gt; mapred-site.xml：12345678&lt;property&gt; &lt;name&gt;mapred.job.tracker&lt;/name&gt; &lt;value&gt;master:9001&lt;/value&gt; &lt;description&gt;The host and port that the MapReduce job tracker runs at. If \"local\", then jobs are run in-process as a single map and reduce task. &lt;/description&gt;&lt;/property&gt; yarn-site.xml：12345678910111213141516171819202122232425&lt;property&gt; &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;description&gt;Whether virtual memory limits will be enforced for containers&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt; &lt;value&gt;256&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;master:8032&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;master:8030&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;master:8031&lt;/value&gt;&lt;/property&gt; 如果是hadoop3以上版本，需要在start-dfs.sh start-yarn.sh中开头空白处分别配置一下内容 12345678910111213vim $HADOOP_HOME/sbin/start-dfs.shHDFS_DATANODE_USER=rootHADOOP_SECURE_DN_USER=hdfsHDFS_NAMENODE_USER=rootHDFS_SECONDARYNAMENODE_USER=rootvim $HADOOP_HOME/sbin/start-yarn.shYARN_RESOURCEMANAGER_USER=rootHADOOP_SECURE_DN_USER=rootYARN_NODEMANAGER_USER=yarnYARN_PROXYSERVER_USER=root 格式化namenode1$HADOOP_HOME/bin/hadoop namenode -format 启动集群$HADOOP_HOME/sbin/start-all.sh 测试 yarn 8088端口 http://yourip:8088 hdfs 50070端口 hdfs3.0为9870 http://yourip:50070 spark只需要在slaves中添加slave01 slave02 **sparkUI端口8080** 测试spark集群启动spark 1$HADOOP_HOME/bin/start-all.sh 官网命令12345678$SPARK_HOME/bin/spark-submit --class org.apache.spark.examples.SparkPi \\--master yarn \\--deploy-mode cluster \\--driver-memory 512m \\--executor-memory 512m \\--executor-cores 1 \\$SPARK_HOME/examples/jars/spark-examples*.jar \\10 执行spark on yarn命令行模式123456789spark-shell --master yarn --deploy-mode client --driver-memory 1g --executor-memory 1g --executor-cores 1spark-shell --master yarn --deploy-mode client --driver-memory 512m --executor-memory 512m --executor-cores 1spark-shell --master yarn --deploy-mode client --driver-memory 475m --executor-memory 475m --executor-cores 1spark-shell --master yarn --deploy-mode client --driver-memory 350m --executor-memory 350m --executor-cores 1spark-shell --master yarn --deploy-mode client --driver-memory 650m --executor-memory 650m --executor-cores 1 创建镜像1docker commit -m \"bigdata基础组件镜像\" bigdata yaosong5/bigdata:2.0 创建容器123docker run -itd --net=br --name master --hostname master yaosong5/bigdata:2.0 &amp;&gt; /dev/nulldocker run -itd --net=br --name slave01 --hostname slave01 yaosong5/bigdata:2.0 &amp;&gt; /dev/nulldocker run -itd --net=br --name slave02 --hostname slave02 yaosong5/bigdata:2.0 &amp;&gt; /dev/null 停止and 删除容器123456docker stop masterdocker stop slave01docker stop slave02docker rm masterdocker rm slave01docker rm slave02","categories":[{"name":"部署安装","slug":"部署安装","permalink":"http://gangtieguo.cn/categories/部署安装/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"},{"name":"Hadoop","slug":"Hadoop","permalink":"http://gangtieguo.cn/tags/Hadoop/"},{"name":"Spark","slug":"Spark","permalink":"http://gangtieguo.cn/tags/Spark/"}]},{"title":"","slug":"hbasezk容器的搭建","date":"2018-07-08T16:01:32.819Z","updated":"2018-07-27T03:54:58.032Z","comments":true,"path":"2018/07/09/hbasezk容器的搭建/","link":"","permalink":"http://gangtieguo.cn/2018/07/09/hbasezk容器的搭建/","excerpt":"","text":"[TOC] 创建hbasezk镜像拷贝源码12345docker cp /Users/yaosong/Yao/hbase 8019587d559b:/usr/docker cp /Users/yaosong/Yao/zk 8019587d559b:/usr/docker cp /Users/yaosong/Yao/hbasezkStart.sh 8019587d559b:/usr/docker cp /Users/yaosong/Yao/hbase-start.sh 8019587d559b:/usr/docker cp /Users/yaosong/Yao/zk-start.sh 8019587d559b:/usr/ 参考https://www.cnblogs.com/netbloomy/p/6677883.html 解压tar -zxvf hbase-1.3.0-bin.tar.gz进入 hbase 的配置目录，在 hbase-env.sh 文件里面加入 java 环境变量. 即： 12vim hbase-env.shexport JAVA_HOME=JAVA_HOME=/usr/java/jdk 关闭 HBase 自带的 Zookeeper, 使用 Zookeeper 集群： 12vim hbase-env.shexport HBASE_MANAGES_ZK=false hbase-site.xml 123456789101112131415161718192021222324&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;hbasezk1,hbasezk2,hbasezk3&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/usr/hbase/tmp/zk/data&lt;/value&gt; &lt;/property&gt; &lt;!-- webui的配置 --&gt; &lt;property&gt; &lt;name&gt;hbase.master.info.port&lt;/name&gt; &lt;value&gt;60010&lt;/value&gt; &lt;/property&gt; &lt;!-- webui新增的配置 --&gt;&lt;/configuration&gt; 创建zk的datadir目录 mkdir -p /usr/hbase/tmp/zk/data 编辑配置目录下面的文件 regionservers. 命令： vim $HBASE_HOME/config/regionservers 加入如下内容： hbasezk1 hbasezk2 hbasezk3 把 Hbase 复制到其他机器scp 开启 hbase 服务。命令如下： 哪台上运行哪台就为hmaster $HBASE_HOME/bin/start-hbase.sh 在 hbasezk1,2,3 中的任意一台机器使用 $HBASE_HOME/bin/hbase shell 进入 hbase 自带的 shell 环境，然后使用命令 version 等，进行查看 hbase 信息及建立表等操作。 zkmkdir -p /usr/zk/data mkdir -p /usr/zk/logs touch /usr/zk/data/myid vim $ZK_HOME/conf/zoo.cfg dataDir=/usr/zk/data dataLogDir=/usr/zk/logs server.1=hbasezk1:2888:3888 server.2=hbasezk2:2888:3888 server.3=hbasezk3:2888:3888 zk问题1、由于 zk 运行一段时间后，会产生大量的日志文件，把磁盘空间占满，导致整个机器进程都不能活动了，所以需要定期清理这些日志文件，方法如下： 1）、写一个脚本文件 cleanup.sh 内容如下： java -cp zookeeper.jar:lib/slf4j-api-1.6.1.jar:lib/slf4j-log4j12-1.6.1.jar:lib/log4j-1.2.15.jar:conf org.apache.zookeeper.server.PurgeTxnLog -n 其中： dataDir：即上面配置的 dataDir 的目录 snapDir：即上面配置的 dataLogDir 的目录 count：保留前几个日志文件，默认为 3 2）、通过 crontab 写定时任务，来完成定时清理日志的需求 crontab -e 0 0 /opt/zookeeper-3.4.10/bin/cleanup.sh HBase Master 高可用（HA）（http://www.cnblogs.com/captainlucky/p/4710642.html）HMaster 没有单点问题，HBase 中可以启动多个 HMaster，通过 Zookeeper 的 Master Election 机制保证总有一个 Master 运行。 所以这里要配置 HBase 高可用的话，只需要启动两个 HMaster，让 Zookeeper 自己去选择一个 Master Acitve。","categories":[],"tags":[]},{"title":"FLINK容器的搭建","slug":"flink容器搭建","date":"2018-07-08T16:00:22.635Z","updated":"2018-08-06T17:26:35.801Z","comments":true,"path":"2018/07/09/flink容器搭建/","link":"","permalink":"http://gangtieguo.cn/2018/07/09/flink容器搭建/","excerpt":"[TOC] 来源容器 flk新建容器，为减少工作量，引用的是有ssh服务的Docker镜像kinogmt/centos-ssh:6.7，生成容器os为基准。 1docker run -itd --name flk --hostname flk kinogmt/centos-ssh:6.7 &amp;&gt; /dev/null 注意必须要以-d方式启动，不然sshd服务不会启动，这算是一个小bug","text":"[TOC] 来源容器 flk新建容器，为减少工作量，引用的是有ssh服务的Docker镜像kinogmt/centos-ssh:6.7，生成容器os为基准。 1docker run -itd --name flk --hostname flk kinogmt/centos-ssh:6.7 &amp;&gt; /dev/null 注意必须要以-d方式启动，不然sshd服务不会启动，这算是一个小bug 在容器中下载需要的elk的源包。做解压就不赘述，很多案例教程。 我是采用的下载到宿主机，解压后，用 “docker cp 解压包目录 os:/usr/loca/“来传到容器内，比在容器内下载速度更快 复制源包123&gt; docker cp /Users/yaosong/Yao/hadoop flk:/usr/&gt; docker cp /Users/yaosong/Yao/flink flk:/usr/&gt; 配置homeexport JAVA_HOME=/usr/java/jdk1.8.0_144/ export PATH=$JAVA_HOME/bin:$PATH export FLINK_HOME=/usr/flink export HADOOP_HOME=/usr/hadoop export HADOOP_CONFIG_HOME=$HADOOP_HOME/etc/hadoop export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop export PATH=$PATH:$HADOOP_HOME/bin export PATH=$PATH:$HADOOP_HOME/sbin export PATH=$PATH:$FLINK_HOME/bin 配置hadoop 参考： []: http://gangtieguo.cn/2018/07/20/Docker%E4%B8%ADhadoop%20spark%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/ “Docker 中 hadoop，spark 镜像搭建” flink.yml 12345678910111213141516 high-availability: zookeeper# The path where metadata for master recovery is persisted. While ZooKeeper stores# the small ground truth for checkpoint and leader election, this location stores# the larger objects, like persisted dataflow graphs.# # Must be a durable file system that is accessible from all nodes# (like HDFS, S3, Ceph, nfs, ...) # high-availability.storageDir: hdfs:///flink/ha/# The list of ZooKeeper quorum peers that coordinate the high-availability# setup. This must be a list of the form:# &quot;host1:clientPort,host2:clientPort,...&quot; (default clientPort: 2181)#high-availability.zookeeper.quorum: zk1:2181,zk2:2181,zk3:2181 Master 1master:8081 slave 12slave01slave02 zoo.cfg 123server.1=zk1:2888:3888server.2=zk2:2888:3888server.3=zk3:2888:3888 需要在yarn-site.xml中配置 12345678&lt;property&gt; &lt;name&gt;yarn.resourcemanager.am.max-attempts&lt;/name&gt; &lt;value&gt;4&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt; &lt;value&gt;8&lt;/value&gt;&lt;/property&gt; 保存镜像1docker commit -m \"bigdata:flink,hadoop\" --author=\"yaosong\" flk yao/flinkonyarn:1.0 获得flk 容器123docker run -itd --net=br --name flk1 --hostname flk1 yao/flinkonyarn:1.0 &amp;&gt; /dev/nulldocker run -itd --net=br --name flk2 --hostname flk2 yao/flinkonyarn:1.0 &amp;&gt; /dev/nulldocker run -itd --net=br --name flk3 --hostname flk3 yao/flinkonyarn:1.0 &amp;&gt; /dev/null 停止/删除flk 容器123456docker stop flk1docker stop flk2docker stop flk3docker rm flk1docker rm flk2docker rm flk3 官方：wordcountflink测试命令由于在本地搭建，机器配置有限，故设置不同参数命令来运行官方wordcount 1234567891011flink run -m yarn-cluster $FLINK_HOME/examples/batch/WordCount.jarflink run -m yarn-cluster -ynd 2 $FLINK_HOME/examples/batch/WordCount.jarflink run -m yarn-cluster -yn 4 $FLINK_HOME/examples/batch/WordCount.jarflink run -m yarn-cluster -yn 6 $FLINK_HOME/examples/batch/WordCount.jarflink run -m yarn-cluster -yn 8 $FLINK_HOME/examples/batch/WordCount.jarflink run -m yarn-cluster -yn 10 $FLINK_HOME/examples/batch/WordCount.jar","categories":[{"name":"FLINK","slug":"FLINK","permalink":"http://gangtieguo.cn/categories/FLINK/"}],"tags":[{"name":"DOCKER","slug":"DOCKER","permalink":"http://gangtieguo.cn/tags/DOCKER/"},{"name":"FLINK","slug":"FLINK","permalink":"http://gangtieguo.cn/tags/FLINK/"}]},{"title":"kafka的启动及命令","slug":"kafka启动脚本","date":"2018-07-08T15:58:00.558Z","updated":"2018-08-06T18:21:34.826Z","comments":true,"path":"2018/07/08/kafka启动脚本/","link":"","permalink":"http://gangtieguo.cn/2018/07/08/kafka启动脚本/","excerpt":"kafka的启动脚本 kafka-startall.sh #!/bin/bash sed -e &apos;1c borker.id=0&apos; $KAFKA_HOME/config/server.properties $KAFKA_HOME/bin/kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties ssh root@slave01 &quot;sed -i &apos;1c borker.id=1 &apos; $KAFKA_HOME/config/server.properties&quot; ssh root@slave01 &quot;sed -i &apos;5c host.name=slave01 &apos; $KAFKA_HOME/config/server.properties&quot; ssh root@slave01 &quot;sed -i &apos;6c advertised.host.name=slave01 &apos; $KAFKA_HOME/config/server.properties&quot; ssh root@slave01 &quot;$KAFKA_HOME/bin/kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties&quot; ssh root@slave02 &quot;sed -i &apos;1c borker.id=2 &apos; $KAFKA_HOME/config/server.properties&quot; ssh root@slave02 &quot;sed -i &apos;5c host.name=slave02 &apos; $KAFKA_HOME/config/server.properties&quot; ssh root@slave02 &quot;sed -i &apos;6c advertised.host.name=slave02 &apos; $KAFKA_HOME/config/server.properties&quot; ssh root@slave02 &quot;$KAFKA_HOME/bin/kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties&quot;","text":"kafka的启动脚本 kafka-startall.sh #!/bin/bash sed -e &apos;1c borker.id=0&apos; $KAFKA_HOME/config/server.properties $KAFKA_HOME/bin/kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties ssh root@slave01 &quot;sed -i &apos;1c borker.id=1 &apos; $KAFKA_HOME/config/server.properties&quot; ssh root@slave01 &quot;sed -i &apos;5c host.name=slave01 &apos; $KAFKA_HOME/config/server.properties&quot; ssh root@slave01 &quot;sed -i &apos;6c advertised.host.name=slave01 &apos; $KAFKA_HOME/config/server.properties&quot; ssh root@slave01 &quot;$KAFKA_HOME/bin/kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties&quot; ssh root@slave02 &quot;sed -i &apos;1c borker.id=2 &apos; $KAFKA_HOME/config/server.properties&quot; ssh root@slave02 &quot;sed -i &apos;5c host.name=slave02 &apos; $KAFKA_HOME/config/server.properties&quot; ssh root@slave02 &quot;sed -i &apos;6c advertised.host.name=slave02 &apos; $KAFKA_HOME/config/server.properties&quot; ssh root@slave02 &quot;$KAFKA_HOME/bin/kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties&quot; kafka的shell命令 /usr/kafka/bin/kafka-topics.sh --create --zookeeper hbasezk1:2181 --replication-factor 2 --partitions 1 --topic shuaige /usr/kafka/bin/kafka-console-producer.sh --broker-list master:9092 --topic shuaige &apos;&apos;&apos;在一台服务器上创建一个订阅者&apos;&apos;&apos; /usr/kafka/bin/kafka-console-consumer.sh --zookeeper hbasezk1:2181 --topic shuaige --from-beginning /kafka-topics.sh --list --zookeeper localhost:12181","categories":[{"name":"大数据","slug":"大数据","permalink":"http://gangtieguo.cn/categories/大数据/"}],"tags":[{"name":"Kakfa","slug":"Kakfa","permalink":"http://gangtieguo.cn/tags/Kakfa/"}]},{"title":"ELK容器的搭建","slug":"elk容器的搭建","date":"2018-07-08T15:43:05.950Z","updated":"2018-08-06T17:26:45.308Z","comments":true,"path":"2018/07/08/elk容器的搭建/","link":"","permalink":"http://gangtieguo.cn/2018/07/08/elk容器的搭建/","excerpt":"[TOC] 来源容器 elk新建容器，为减少工作量，引用的是有ssh服务的Docker镜像kinogmt/centos-ssh:6.7，生成容器os为基准。 1docker run -itd --name elk --hostname elk kinogmt/centos-ssh:6.7 &amp;&gt; /dev/null 注意必须要以-d方式启动，不然sshd服务不会启动，这算是一个小bug","text":"[TOC] 来源容器 elk新建容器，为减少工作量，引用的是有ssh服务的Docker镜像kinogmt/centos-ssh:6.7，生成容器os为基准。 1docker run -itd --name elk --hostname elk kinogmt/centos-ssh:6.7 &amp;&gt; /dev/null 注意必须要以-d方式启动，不然sshd服务不会启动，这算是一个小bug 在容器中下载需要的elk的源包。做解压就不赘述，很多案例教程。 我是采用的下载到宿主机，解压后，用 “docker cp 解压包目录 os:/usr/loca/“来传到容器内，比在容器内下载速度更快 设置Home vim ~/bashrc 123456789export ES_HOME=/usr/esexport PATH=$ES_HOME/bin:$PATHexport KIBANA_HOME=/usr/kibanaexport PATH=$KIBANA_HOME/bin:$PATHexport LOGSTASH_HOME=/usr/logstashexport PATH=$LOGSTASH_HOME/bin:$PATHexport NODE_HOME=/usr/nodeexport PATH=$NODE_HOME/bin:$PATHexport NODE_PATH=$NODE_HOME/lib/node_modules source ~/.bashrc 安装插件header安装nodejs一般预装的版本不对 123yum erase nodejs npm -y # 卸载旧版本的nodejsrpm -qa &apos;node|npm&apos; | grep -v nodesource # 确认nodejs是否卸载干净yum install nodejs -y # 安装npm 安装的版本会有不对 下载合适版本 1234cd /usrwget https://npm.taobao.org/mirrors/node/latest-v4.x/node-v4.4.7-llinux-x64.tar.gztar -zxvf node-v4.4.7-linux-x64.tar.gzmv node-v8.9.1-linux-x64 node 直接将node目录配置到home即可 12export NODE_HOME=/usr/nodeexport PATH=$NODE_HOME/bin:$PATH 下载 header，安装grunt（所有命令在hear的所在目录执行） wget https://github.com/mobz/elasticsearch-head/archive/master.zip unzip master.zip 看当前 head 插件目录下有无 node_modules/grunt 目录：没有：执行命令创建： 1npm install grunt --save 安装 grunt：grunt 是基于 Node.js 的项目构建工具，可以进行打包压缩、测试、执行等等的工作，head 插件就是通过 grunt 启动 1npm install -g grunt-cli 参考https://blog.csdn.net/ggwxk1990/article/details/78698648 npm install 安装所下载的header包 1npm install header启动在 elasticsearch-head-master 目录下 1grunt server 或者 npm run start els不能通过root启动，创建用户useradd elk groupadd elk usermod -a -G elk elk echo elk | passwd --stdin elk 将elk添加到sudoers echo &quot;elk ALL = (root) NOPASSWD:ALL&quot; | tee /etc/sudoers.d/elk chmod 0440 /etc/sudoers.d/elk 解决sudo: sorry, you must have a tty to run sudo问题，在/etc/sudoer注释掉 Default requiretty 一行 sudo sed -i ‘s/Defaults requiretty/Defaults:elk !requiretty/‘ /etc/sudoers 修改文件所有者chown -R elk:elk /usr/es/ 设置资源参数 1sudo vim /etc/security/limits.d/90-nproc.conf 添加 elk soft nproc 4096 12docker-machine sshsysctl -w vm.max_map_count=655360 es启动脚本单机 su elk -c &quot;$ES_HOME/bin/elasticsearch -d&quot; ssh elk@elk1 &quot; $ES_HOME/bin/elasticsearch -d&quot; ssh root@elk1 &quot; su elk -c $ES_HOME/bin/elasticsearch &quot; 集群elasticSearch脚本 vim es-start.sh 12345678#!/bin/bashsed -i '6c node.name: es1 '$ES_HOME/config/elasticsearch.ymlsu - elk -c \"$ES_HOME/bin/elasticsearch -d\"ssh root@elk2 \"sed -i '6c node.name: es2 ' $ES_HOME/config/elasticsearch.yml\"ssh root@elk2 ' su - elk -c \"$ES_HOME/bin/elasticsearch -d\" 'ssh root@elk3 \"sed -i '6c node.name: es3 ' $ES_HOME/config/elasticsearch.yml\"ssh root@elk3 ' su - elk -c \"$ES_HOME/bin/elasticsearch -d\" ' kibana启动单机（只需要启动单机） bin/kibana12345678#!/bin/bashsed -i '3c http://elk1:9200 '$KIBANA_HOME/config/kibana.ymlnohup $KIBANA_HOME/bin/kibana &amp;ssh root@elk2 \"sed -i '3c http://elk2:9200 ' $KIBANA_HOME/config/kibana.yml\"ssh root@elk2 \"nohup $KIBANA_HOME/bin/kibana &amp; \"ssh root@elk3 \"sed -i '3c http://elk3:9200 ' $KIBANA_HOME/config/kibana.yml\"ssh root@elk3 \"nohup $KIBANA_HOME/bin/kibana &amp; \" logstash单机启动 $LOGSTASH_HOME/bin/logstash -f logstash.conf $LOGSTASH_HOME/bin/logstash -f 配置文件的目录\b 集群启动脚本 logstash-start.sh1234#!/bin/bashnohup $LOGSTASH_HOME/bin/logstash -f $LOGSTASH_HOME/conf/$1 &amp;ssh root@elk2 \"nohup $LOGSTASH_HOME/bin/logstash -f $LOGSTASH_HOME/conf/$1 &amp; \"ssh root@elk3 \"nohup $LOGSTASH_HOME/bin/logstash -f $LOGSTASH_HOME/conf/$1 &amp; \" 保存容器为镜像1docker commit -m \"elk镜像\" --author=\"yaosong\" os yaosong5/elk:1.0 生成elk 容器123docker run -itd --net=br --name elk1 --hostname elk1 yaosong5/elk:1.0 &amp;&gt; /dev/nulldocker run -itd --net=br --name elk2 --hostname elk2 yaosong5/elk:1.0 &amp;&gt; /dev/nulldocker run -itd --net=br --name elk3 --hostname elk3 yaosong5/elk:1.0 &amp;&gt; /dev/null 停止/删除elk 容器1234567docker stop elk1docker stop elk2docker stop elk3docker rm elk1docker rm elk2docker rm elk3 参考elk 操作命令es操作命令http://www.yfshare.vip/2017/11/04/%E9%83%A8%E7%BD%B2FileBeat-logstash-elasticsearch%E9%9B%86%E7%BE%A4-kibana/#%E9%85%8D%E7%BD%AE-filebeart 其他yum erase nodejs npm -y # 卸载旧版本的nodejsrpm -qa ‘node|npm’ | grep -v nodesource # 确认nodejs是否卸载干净yum install nodejs -y","categories":[{"name":"ELK","slug":"ELK","permalink":"http://gangtieguo.cn/categories/ELK/"}],"tags":[{"name":"Dokcer","slug":"Dokcer","permalink":"http://gangtieguo.cn/tags/Dokcer/"},{"name":"ELK","slug":"ELK","permalink":"http://gangtieguo.cn/tags/ELK/"}]},{"title":"Docker常用命令汇集","slug":"Docker命令汇集","date":"2018-06-26T02:33:37.714Z","updated":"2018-08-06T17:33:16.880Z","comments":true,"path":"2018/06/26/Docker命令汇集/","link":"","permalink":"http://gangtieguo.cn/2018/06/26/Docker命令汇集/","excerpt":"","text":"[TOC] Docker源配置 安装过程中需要重国外 docker 仓库下载文件，速度太慢，建议配置 docker 国内镜像仓库： vi /etc/docker/daemon.json {“registry-mirrors”:[“http://c1f0a193.m.daocloud.io&quot;] } 启动容器 docker run -itd --net=br --name slave02 --hostname slave02 centos:hadoop-spark &amp;&gt; /dev/null 如果以 /bin/bash启动的话，sshd服务不会启动(docker未知bug) 创建容器--name --hostname (同-h) --net= -d表示后台启动 此命令不会打印出容器id docker run -itd --net=br --name hm --hostname hadoop-master kiwenlau/hadoop:1.0 &amp;&gt; /dev/null （hadoop镜像） 设置静态固定ip docker run -d --net=br --name=c6 --ip=192.168.33.6 nginx 自动分配Ip docker run -d --net=br --name=c1 nginx 设置docker默认ip段命令 docker run -itd -P -p 50070:50070 -p 8088:8088 -p 8080:8080 --name master -h master --add-host slave01:172.17.0.3 --add-host slave02:172.17.0.4 centos:ssh-spark-hadoop 容器挂载目录compose文件：12volumes: - /Users/yaosong/Yao/dev/hadoop/dfs/name:/root/hadoop/dfs/name shell命令： 12-v : docker run -it -v /test:/soft centos /bin/bash “:”前目录为宿主机目录，后目录为容器目录 删除所有未用的 Data volumes1docker volume prune run 命令解释-d 是后台启动 docker run -itd --net=br --name spark --hostname spark yaosong/spark:2.1.0 &amp;&gt; /dev/null sudo docker exec -it hm bash（进入后台启动的容器） 和下面一样（直接进入） docker run -it --net=br --name spark --hostname spark yaosong/spark:2.1.0 bash exec 进入后台容器docker exec -it spark bash docker exec -it 容器名 bash 执行命令 docker exec -it 容器名 ip addr 可以拿到 a0 容器的 ip logs查看容器启动日志logs -f -t --tail 100 kanbigdata_namenode_1```12## 查看容器信息 docker inspect hm执行命令 docker exec -it 容器名 ip addr 可以拿到 a0 容器的 ip12345678910## 启动 关闭 删除容器 docker start docker stop 容器名 docker rm 容器名## cp容器宿主互拷文件 docker cp /Users/yaosong/Yao/etc.tar f7e795c0fddd:/后为容器id:/目录12345678910## 删除镜像 （根据镜像id删除） docker rmi 00de07ebadff 用docker images -a 查看image id， 也可docker rmi 镜像名:版本号## 保存镜像 docker commit -m “centos-6.9 with spark 2.2.0 and hadoop 2.8.0” os centos:hadoop-spark docker commit -m “bigdata:spark,hadoop,hive,mysql and shell foundation” –author=”yaosong” master yao/os/bigdata:2.1123456789## Docker用DockerFile创建镜像 docker build -t hadoop:v1- &lt;Dockerfile docker build -t=&quot;hadoop:v1&quot; . （.表示是当前文件夹，也就是dockerfile所在文件夹） docker build -f Dockerfile -t hadoop:v1 . 此命令也可## 一键启动docker-compose.yml编排的所有服务 docker-compose -f docker-compose.yml up d12345678## Docker改变标签docker tag IMAGEID(镜像id) REPOSITORY:TAG（仓库：标签）`docker tag b7a66cb0e8ba yaosong5/bigdata:1.0`## 搜索docker镜像 docker search yaosong51234567891011121314151617181920212223242526272829303132## 登录docker账户`docker login` 登录docker hub中注册的账户## 上传仓库`docker push yaosong5/elk:1.0`## 容器保存为镜像，加载本地镜像 引用 docker save imageID &gt; filename docker load &lt;filename 如： docker save 4f9e92e56941&gt; /Users/yaosong/centosSparkHadoop.tar docker load &lt;/Users/yaosong/centosSparkHadoop.tar 通过 image 保存的镜像会保存操作历史，可以回滚到历史版本。## 保存，加载容器命令： docker export containID &gt; filename docker import filename [newname]通过容器保存的镜像不会保存操作历史，所以文件小一点。如果要运行通过容器加载的镜像， 需要在运行的时候加上相关命令。# Docker-machine命令## 列出docker-machine docker-machine ls12## 开启虚拟机 docker-machine start default12## 关闭虚拟机 docker-machine stop default12## 重启虚拟机 docker-machine restart default12## 删除虚拟机 docker-machine rm default12## 设置环境变量docker-machine eval $(docker-machine env default) # Setup the environment`","categories":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/categories/Docker/"}],"tags":[{"name":"Dokcer","slug":"Dokcer","permalink":"http://gangtieguo.cn/tags/Dokcer/"}]},{"title":"各种快捷键","slug":"各种快捷键","date":"2018-06-21T15:40:13.306Z","updated":"2018-07-19T18:33:25.160Z","comments":true,"path":"2018/06/21/各种快捷键/","link":"","permalink":"http://gangtieguo.cn/2018/06/21/各种快捷键/","excerpt":"","text":"|iterm|Command + Shift + h iterms2复制历史 分屏 command + option + 方向键 command + [ 或 command + ] 分屏切换屏幕 Control + a 到行首 Control + u 清除当前行 Control + e 到行尾 Control + p / !! 上一条命令 Control + k 从光标处删至命令行尾 (本来 Control + u 是删至命令行首，但iterm中是删掉整行) Control + w A + d 从光标处删至字首/尾 Control + k 删除到文本末尾 Control + h 删掉光标前的自负 Control + d 删掉光标后的自负 Control + r 搜索命令历史，这个较常用 |Alfred|Command + Option + C afrend剪切板历史 Command + Option + / afrend路径历史 Command + Option + \\ afrend对搜索的路径进行操作 如复制等等 |sublime|Command + Shift + d 复制一行 Command + Option + f 查找并替换 CTRL + - 上个打开的文件 |idea|Command + Shift + F12 编栏全屏 其实就是 Hide All Tool Windows (隐藏所有工具窗口) 这个操作的快捷键。 Command + Option + Space 类名或接口名提示 Control + ; 是什么 代替鼠标 Command + l 跳到指定行 Command + w 关闭标签页 Option + 上 和windows的ctrl+w相同 递进选中代码块 Alt + Insert Command + N 代码自动生成，如生成对象的 set / get 方法，构造函数，toString() 等 Alt + 前方向键 Control + 前方向键 当前光标跳转到当前文件的前一个方法名位置 Ctrl + Alt + Enter Command + Option + Enter 光标所在行上空出一行，光标定位到新行 Ctrl + Alt + 左方向键 Command + Option + 左方向键 退回到上一个操作的地方 Ctrl + Alt + 右方向键 Command + Option + 右方向键 前进到上一个操作的地方 Command + Option + T 包围代码 Command + Shift +v 历史 Find usage 查看变量方法的类的直接使用情况 Shift + Enter 开始新的一行 Command + P 方法参数提示 Command + U 前往父类 Command + +/- 展开/折叠代码 Alt + 1,2,3...9 Command + 1,2,3...9 显示对应数值的选项卡，其中 1 是 Project 用得最多 Control + Option + O 优化导入的类，可以对当前文件和整个包目录使用 Ctrl + Alt + T 对选中的代码弹出环绕选项弹出层 Control + Option + H 继承关系 Control + H 接口到实现类 Control + Shift + J 智能的将代码拼接成一行 Command+Alt+V 引入变量，自动导入变量 Option + F7 查询所选对象/变量被引用 4、类、方法、文件定位 查找类 ctr + N 查找文件 Ctrl + Shift + N 符号定位 Ctrl + Alt + Shift + N 查看文件结构 ctrl + F12 最近打开的文件 ctr + E 定位下一个方法 alt + down 定位上一个方法 alt + up 查看方法参数信息 ctr + p 查看方法、类的 doc ctr + Q 行数 Command + l 5、类、方法的结构查看、定位 跳到类或方法的声明 ctr + B 定位到类的父类、接口 ctr + U 画图 ommand+Option+u 查看类的继承结构 ctr + H 查看方法的继承结构 ctr + Shift + H 查看类或方法被调用情况 ctr + alt +H 原地参看类、方法的声明 Ctrl + Shift + I Control + H 显示当前类的层次结构 继承 Command + Shift + H 显示方法层次结构 Control + Option + H 显示调用层次结构 Command + L 在当前文件跳转到某一行的指定处 Command + B / Command + 鼠标点击 进入光标所在的方法/变量的接口或是定义处 Command + Option + B 跳转到实现处 Command + G 查找模式下，向下查找 Command + Shift + U 大小写切换 |Mac|Shift+Command+G 跳转打开文件夹 Command + Shift + . 显示隐藏文件 Command + Control + 空格 emoji表情 Shift + Option）+ K Apple logo 「 」 Command+i 简介 Shift+Control+d 搜狗表情包 Shift + Command + 空格 历史文件 Control + Command +F 全屏模式 Command + z 打开safari下最近关闭tab页面 Command + Option + Shift + Esc 强制退出活跃的 Command + Option + Esc 强制退出 Command + ` 切换同一应用的窗口 Shift + Command + d alt + cmd + space 快速打开finder cmd + Option + Shift + v 去格式粘贴（亲测大部分软件都可以） Command + Tab 切换应用的时候，可以松开Tab，然后按Q退出选中的应用。 三指点击网页链接，可以预览链接网页。 按住右上角的新建选项卡按钮能快速浏览并选择最近关闭的窗口 |finder|Command + 1，2，3 图标，列表，分栏显示文件夹 Command + Control + P 复制路径 自己配置 Command + Option + B 快捷键标记 自己配置 Command + O 打开文件夹 Command + 下 进入文件夹 Command + 上 返回文件夹 Command ＋［ 返回 Command ＋ ］ 前进 | mac命令|根据 asker 提示 作补充： command + fn + 左/右，可以调整到文件开头 / 结尾。 fn + 左/右相当于home/end在 网页和多数文档中适用。 defaults write com.apple.finder QuitMenuItem -bool YES 设置finder可以关闭 open -n /Applications/WizNote.app 多次打开一个应用 mac 没有声音 sudo kill -9 `ps ax|grep &apos;coreaudio[a-z]&apos; |awk &apos;{print $1}&apos;` sudo killall coreaudiod 使用后的效果，可以说是非常明显了，再也不会有在「挤牙膏」的感觉。让它回到最开始的状态： defaults delete com.apple.dock; killall Dock defaults write com.apple.Dock autohide-delay -float 0 &amp;&amp; killall Dock 打开开机声音 sudo nvram -d SystemAudioVolume 双屏分任务工作！只要按住窗口左上角的绿色＋即可 去掉资源库文件夹的隐藏属性 chflags nohidden ~/Library/ 打开隐藏属性 chflags hidden ~/Library/ 调节音量的同时按住 Option + Shift键 显示“隐藏文件” Command + Shift + . defaults write com.apple.finder AppleShowAllFiles -bool true;killall Finder 隐藏 defaults write com.apple.finder AppleShowAllFiles -bool true;killall Finder 关闭开机声音 sudo nvram SystemAudioVolume=%80， 省略号 1、依次按 ⌃ ⌘ 空格 2、⇧ 数字6 Option 点击 Dock 图标，按住 Option 点击 Dock 中的图标，则会在桌面显示该应用所有窗口 Option + 左：向左移动一个单词 Option + 右：向右移动一个单词 Option + Delete：删除左边一个单词 Option + Fn + Delete：删除右边一个单词 设置 dock 显示时间命令 打开终端输入以下命令 #先修改停留时间（后面数字为停留时间）如： defaults write com.apple.dock autohide-delay -int 0 ##（时间设为最短） defaults write com.apple.dock autohide-delay -int 0.5 ##（时间设为 0.5s） defaults write com.apple.dock autohide-delay -int 10 ##（时间设为 10s） #使设置生效 killall Dock |推荐|再推荐个人 池健强 《人生元编程》作者 他的博客和微信上有很多干货","categories":[{"name":"快捷键","slug":"快捷键","permalink":"http://gangtieguo.cn/categories/快捷键/"}],"tags":[{"name":"快捷键","slug":"快捷键","permalink":"http://gangtieguo.cn/tags/快捷键/"},{"name":"Mac","slug":"Mac","permalink":"http://gangtieguo.cn/tags/Mac/"},{"name":"Idea","slug":"Idea","permalink":"http://gangtieguo.cn/tags/Idea/"},{"name":"Finder","slug":"Finder","permalink":"http://gangtieguo.cn/tags/Finder/"}]},{"title":"Centos7上搭建Jenkins","slug":"Centos7上搭建Jenkins","date":"2018-06-21T14:11:28.272Z","updated":"2018-08-06T16:56:00.707Z","comments":true,"path":"2018/06/21/Centos7上搭建Jenkins/","link":"","permalink":"http://gangtieguo.cn/2018/06/21/Centos7上搭建Jenkins/","excerpt":"之前用yum模式安装，总是启动报错，解决了一番，未找到解决方案，后直接下载war包进行安装部署 默认安装了Java","text":"之前用yum模式安装，总是启动报错，解决了一番，未找到解决方案，后直接下载war包进行安装部署 默认安装了Java 1. 安装 jenkins 123456cd /optmkdir /jenkinscd jenkinsmkdir jenkins_homemkdir jenkins_nodewget http://mirrors.jenkins-ci.org/war/latest/jenkins.war 2. 编写可执行文件 vim start_jenkins.sh1234#!/bin/bashJENKINS_ROOT=/opt/jenkinsexport JENKINS_HOME=$JENKINS_ROOT/jenkins_homejava -jar $JENKINS_ROOT/jenkins.war --httpPort=8000 修改文件的权限： chmod a+x start_jenkins.sh 启动 jenkins: nohup ./start_jenkins.sh &gt; jenkins.log 2&gt;&amp; 1&amp; 3 访问 jenkins 输入 http:// 服务器地址: 8000 注意：在启动日志中会出现初始密码，这个用来首次登陆Jenkins使用 参考在 Centos7 上搭建 jenkins","categories":[{"name":"部署安装","slug":"部署安装","permalink":"http://gangtieguo.cn/categories/部署安装/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://gangtieguo.cn/tags/Jenkins/"}]},{"title":"Docker安装Hadoop集群","slug":"Docker安装Hadoop集群","date":"2018-06-03T06:36:21.404Z","updated":"2018-06-21T11:37:36.360Z","comments":true,"path":"2018/06/03/Docker安装Hadoop集群/","link":"","permalink":"http://gangtieguo.cn/2018/06/03/Docker安装Hadoop集群/","excerpt":"Docker配置Hadoop集群环境 在网上找到一个网友自制的镜像，拉取配置都是参考的，记录一下。","text":"Docker配置Hadoop集群环境 在网上找到一个网友自制的镜像，拉取配置都是参考的，记录一下。 拉取镜像 sudo docker pull kiwenlau/hadoop-master:0.1.0sudo docker pull kiwenlau/hadoop-slave:0.1.0sudo docker pull kiwenlau/hadoop-base:0.1.0sudo docker pull kiwenlau/serf-dnsmasq:0.1.0 查看下载的镜像 sudo docker images 在github中拉取源代码(或者在oschina中拉取)git clone https://github.com/kiwenlau/hadoop-cluster-docker开源中国git clone http://git.oschina.net/kiwenlau/hadoop-cluster-docker 运行容器拉取镜像后，打开源代码文件夹，并且运行脚本 cd hadoop-cluster-docker 注意：运行脚本时,需要先启动docker服务 ./start-container.sh 一共开启了 3 个容器，1 个 master, 2 个 slave。开启容器后就进入了 master 容器 root 用户的根目录（/root） 查看root目录下文件 测试容器是否正常运行serf members 参考：基于 Docker 快速搭建多节点 Hadoop 集群","categories":[{"name":"环境配置","slug":"环境配置","permalink":"http://gangtieguo.cn/categories/环境配置/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"},{"name":"Hadooop","slug":"Hadooop","permalink":"http://gangtieguo.cn/tags/Hadooop/"}]},{"title":"命令积累","slug":"大数据命令积累","date":"2018-05-31T06:10:40.710Z","updated":"2018-08-06T18:20:09.751Z","comments":true,"path":"2018/05/31/大数据命令积累/","link":"","permalink":"http://gangtieguo.cn/2018/05/31/大数据命令积累/","excerpt":"bin /h dfs oev -i edits -o edits.xml 查看元数据","text":"bin /h dfs oev -i edits -o edits.xml 查看元数据","categories":[{"name":"碎片知识","slug":"碎片知识","permalink":"http://gangtieguo.cn/categories/碎片知识/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://gangtieguo.cn/tags/大数据/"},{"name":"命令","slug":"命令","permalink":"http://gangtieguo.cn/tags/命令/"}]},{"title":"","slug":"json-tool使用","date":"2018-05-30T01:36:02.864Z","updated":"2018-08-06T16:34:42.126Z","comments":true,"path":"2018/05/30/json-tool使用/","link":"","permalink":"http://gangtieguo.cn/2018/05/30/json-tool使用/","excerpt":"","text":"title: jsontool使用date: 2018年06月21日 22时15分52秒tags: []categories: toc: truejson-tool使用：java -jar json-tool.jar &quot;json文件目录&quot; &quot;jsonPath路径&quot;示例： 1java -jar /Users/yaosong/Documents/json-tool.jar &quot;/Users/yaosong/tmp/access_report_data_by_token.json&quot; &quot;$.report_data.behavior_check[?(@.check_point_cn == &apos;朋友圈在哪里&apos;)].evidence&quot;","categories":[],"tags":[]},{"title":"源文件提交到仓库","slug":"博客源文件提交到仓库","date":"2018-05-21T17:43:07.025Z","updated":"2018-05-21T17:44:03.947Z","comments":true,"path":"2018/05/22/博客源文件提交到仓库/","link":"","permalink":"http://gangtieguo.cn/2018/05/22/博客源文件提交到仓库/","excerpt":"将博客源文件加入到仓库 git add .git commit -m “ “git push origin mastergit push origin master -f","text":"将博客源文件加入到仓库 git add .git commit -m “ “git push origin mastergit push origin master -f","categories":[{"name":"博客","slug":"博客","permalink":"http://gangtieguo.cn/categories/博客/"}],"tags":[{"name":"git","slug":"git","permalink":"http://gangtieguo.cn/tags/git/"},{"name":"Hexo","slug":"Hexo","permalink":"http://gangtieguo.cn/tags/Hexo/"}]},{"title":"git命令总结","slug":"git命令总结","date":"2018-05-21T17:43:07.025Z","updated":"2018-07-26T06:08:36.732Z","comments":true,"path":"2018/05/22/git命令总结/","link":"","permalink":"http://gangtieguo.cn/2018/05/22/git命令总结/","excerpt":"提交 git add .git commit -m “ “git push origin mastergit push origin master -f 拉取git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;如拉取远程的 master 分支到本地 wy 分支：git pull origin master:wy 分支切换","text":"提交 git add .git commit -m “ “git push origin mastergit push origin master -f 拉取git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;如拉取远程的 master 分支到本地 wy 分支：git pull origin master:wy 分支切换 查看分支：git branch创建分支：git branch 切换分支：git checkout 创建 + 切换分支：git checkout -b 合并某分支到当前分支：git merge 删除分支：git branch -d","categories":[],"tags":[{"name":"git","slug":"git","permalink":"http://gangtieguo.cn/tags/git/"}]},{"title":"部署博客到云服务器","slug":"转移Github博客到云服务器","date":"2018-05-20T16:56:17.069Z","updated":"2018-05-21T16:55:37.674Z","comments":true,"path":"2018/05/21/转移Github博客到云服务器/","link":"","permalink":"http://gangtieguo.cn/2018/05/21/转移Github博客到云服务器/","excerpt":"简单记录转移到博客到云服务器","text":"简单记录转移到博客到云服务器 原理及准备 我们在自己的电脑上写好博客, 使用 git 发布到代码仓库进行备份, git 仓库接收到 push 请求后, 使用 webhook 配合 nodejs 自动进行服务器端页面的更新. 准备安装Git和NodeJS (CentOS 环境) 1yum install git 安装NodeJS 1curl --silent --location https://rpm.nodesource.com/setup_5.x | bash - 服务器构建webhook方式服务器端的” 钩子”我们借助一个 node 插件 github-webhook-handler 来快速完成配合 github webhook 的操作, 其他 git 平台也有相应的插件, 如配合 coding 的 coding-webhook-handler. 监听脚本 我们借助一个 node 插件 github webhook-handler来快速完成配合 github webhook 的操作, 其他 git 平台也有相应的插件, 如配合 coding 的 coding-webhook-handler. 使用 npm install -g github-webhook-handler 命令来安装到服务器端.conding则为npm install -g coding-webhook-handler 切换到服务器站点目录，如我的是 /root/blog,新建一个public目录，将你的github仓库中的master分支pull到该目录中，这个目录作为这个博客的根目录了 123456cd /root/blogmkdir public cd public git initgit remote add origin https://github.com/yaosong5/yaosong5.github.iogit pull origin master 然后我们创建一个webhooks.js文件，将以下的内容粘贴，这相当于Node.js 服务器的代码构建 123456789101112131415161718192021222324252627282930var http = require('http')var createHandler = require('github-webhook-handler')var handler = createHandler(&#123; path: '/', secret: 'yao' &#125;)function run_cmd(cmd, args, callback) &#123; var spawn = require('child_process').spawn; var child = spawn(cmd, args); var resp = \"\"; child.stdout.on('data', function(buffer) &#123; resp += buffer.toString(); &#125;); child.stdout.on('end', function() &#123; callback (resp) &#125;);&#125;http.createServer(function (req, res) &#123; handler(req, res, function (err) &#123; res.statusCode = 404 res.end('no such location') &#125;)&#125;).listen(7777)handler.on('error', function (err) &#123; console.error('Error:', err.message)&#125;)handler.on('push', function (event) &#123; console.log('Received a push event for %s to %s', event.payload.repository.name, event.payload.ref); run_cmd('sh', ['./deploy.sh',event.payload.repository.name], function(text)&#123; console.log(text) &#125;);&#125;) 注意上段代码中第 3 行 { path: ‘/‘, secret: ‘改为你的secret’ } 中 secret 可以改为你喜欢的口令, 这口令将在下面的步骤中起到作用 ,配置github webhooks的时候填入的口令, 请留意. 第 19 行 listen(7777) 中 7777 为监听程序需要使用的端口. 执行脚本上面的 javascript 代码是用来捕捉 github 发来的信号并发起一个执行 ./deploy.sh 的脚本, 接下来我们还需要写 deploy.sh 的内容. 123456789101112#!/bin/bashWEB_PATH='/root/blog/public'echo \"Start deployment\"cd $WEB_PATHecho \"pulling source code...\"git reset --hard origin/mastergit clean -fgit pullgit checkout masterecho \"Finished.\" 将以上代码的第 3 行改为你服务器中的实际目录. 接下来只需要开启监听就可以了. tips: 在此之前你可以使用 node webhook.js 来测试一下监听程序是否能够正常运行.我在这里碰到了一个 node 环境变量的问题, 读取不到 github-webhook-handler 这个模块, 找了很多办法也没有解决, 后来我直接在项目根目录的上级目录安装了这个模块, 问题就解决了. cd /root/blognpm install github-webhook-handlernpm 会从当前目录依次向上寻找含有 node_modules 目录并访问该模块. 普通方式运行 webhook.js利用 Linux 提供的 nohup 命令，让 webhooks.js 运行在后台 1nohup node webhook.js &gt; deploy.log &amp; Forever方式运行webhook.js 我在实际使用的时候发现，我的 Node 服务器时不时会自动停掉，具体原因我暂时还没有弄清楚。不过似乎很多人都遇到了这样的困扰，要解决这个问题，forever 是个不错的选择。借助 forever 这个库，它可以保证 Node 持续运行下去，一旦服务器挂了，它都会重启服务器。 安装 forever：npm install -g forever运行：12cd &#123; 部署服务器的根目录 &#125; nohup forever start webhook.js &gt; deploy.log &amp; Ubuntu 中原本就有一个叫 node 的包。为了避免冲突，在 Ubuntu 上安装或使用 Node 得用 nodejs 这个名字。而 forever 默认是使用 node 作为执行脚本的程序名。所以为了处理 Ubuntu 存在的这种特殊情况，在启动 forever 时得另外添加一个参数：(其它则忽略) forever start webhook.js -c nodejs Github配置webhooks配置好 Webhook 后，Github 会发送一个 ping 来测试这个地址。如果成功了，那么这个 Webhook 前就会加上一个绿色的勾；如果你得到的是一个红色的叉，那就好好检查一下哪儿出问题了吧！ git-hook方式可采用一种更为简单的部署方式 这种方式和webhook可二选一 服务器上建立git裸库创建一个裸仓库，裸仓库就是只保存git信息的Repository, 首先切换到git用户确保git用户拥有仓库所有权一定要加 –bare，这样才是一个裸库。 12cd git init --bare blog.git 使用 git-hooks 同步网站根目录在这里我们使用的是 post-receive这个钩子，当git有收发的时候就会调用这个钩子。 在 ~/blog.git 裸库的 hooks文件夹中，新建post-receive文件。 vim ~/blog.git/hooks/post-receive 填入以下内容 12#!/bin/shgit --work-tree=/root/blog/public --git-dir=/root/blog.git checkout -f work-tree=/root/blog/public这个目录是网站的网页文件目录，–git-dir=/root/blog.git目录为裸库地址，裸库监听git提交会将文件提交到网页目录保存后，要赋予这个文件可执行权限chmod +x post-receive 配置博客根目录_config.yml完成自动化部署打开 _config.yml, 找到 deploy12345deploy: type: git repo: 用户名@SERVER名:/home/git/blog.git（裸库地址） //&lt;repository url&gt; branch: master //这里填写分支 [branch] message: 提交的信息 //自定义提交信息 (默认为 Site updated: &#123;&#123; now(&apos;YYYY-MM-DD HH:mm:ss&apos;) &#125;&#125;) Nginx服务npm 安装nginx启动nginx 1service nginx start nginx -t 查看nginx配置文件若nginx服务启动，访问报403错误 则将首行 user nginx 改为user root 123456789vim /etc/nginx/nginx.confserver &#123; listen 80; # 监听端口 server_name 47.98.141.252:80 gangtieguo.cn wwww.gangtieguo.cn; # 你的域名 location / &#123; root /root/blog/public; index index.html; &#125;&#125; 重载 nginx，使配置生效 nginx -s reload 参考Hexo 静态博客搭建并实现自动部署到远程 vps将 Hexo 博客发布到自己的服务器上利用 Github 的 Webhook 功能和 Node.js 完成项目的自动部署Webhook 实践 —— 自动部署Hexo 快速搭建静态博客并实现远程 VPS 自动部署阿里云 VPS 搭建自己的的 Hexo 博客","categories":[{"name":"博客","slug":"博客","permalink":"http://gangtieguo.cn/categories/博客/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://gangtieguo.cn/tags/Hexo/"}]},{"title":"MyBatis相关注解","slug":"MyBatis注解","date":"2018-05-17T12:09:55.000Z","updated":"2018-08-06T18:18:59.332Z","comments":true,"path":"2018/05/17/MyBatis注解/","link":"","permalink":"http://gangtieguo.cn/2018/05/17/MyBatis注解/","excerpt":"现接触MyBatic记录一些注解","text":"现接触MyBatic记录一些注解自动生成主键 可以使用 @Options 注解的 userGeneratedKeys 和 keyProperty 属性让数据库产生 auto_increment（自增长）列的值，然后将生成的值设置到输入参数对象的属性中。123@Insert(\"insert into students(name,sex,age) values(#&#123;name&#125;,#&#123;sex&#125;,#&#123;age&#125;\") @Options(useGeneratedKeys = true, keyProperty =\"userId\") int insertUser(User user); 将自增的Id存入到userId属性中","categories":[{"name":"框架","slug":"框架","permalink":"http://gangtieguo.cn/categories/框架/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://gangtieguo.cn/tags/Java/"},{"name":"SSH","slug":"SSH","permalink":"http://gangtieguo.cn/tags/SSH/"}]},{"title":"linux命令积累","slug":"Linux命令积累","date":"2018-05-10T07:37:28.983Z","updated":"2018-08-06T17:47:25.486Z","comments":true,"path":"2018/05/10/Linux命令积累/","link":"","permalink":"http://gangtieguo.cn/2018/05/10/Linux命令积累/","excerpt":"简单linux命令","text":"简单linux命令nohup &amp;后台运行 文件查找find / -type f -size +10G在Linux下如何让文件让按大小单位为M,G等易读格式，S size大小排序。 ls -lhSdu -h * | sort -n当然您也可以结合管道文件夹内最大的几个文件 du -h * | sort -n|head动态显示机器各端口的链接情况while :; do netstat -apn | grep &quot;:80&quot; | wc -l; sleep 1; done sed更改第一行 sed -i &#39;1s/.*//&#39; sed -i ‘1s/.*/想更改的内容/‘删除第一行sed -i &#39;1d&#39; sed -i ‘1d’ 文件名插入第一行 sed -i &#39;1i\\&#39; sed -i ‘1i\\内容‘ 文件名 cpucat /proc/cpuinfo | grep processor | wc -llscpu sz rz与服务器交互上传下载文件sudo yum install lrzsz -y 挂载 sshfs root@192.168.73.12:/home/ /csdn/win10/ 即：sshfs 用户名@远程主机IP:远程主机路径 本地挂载点sshfs root@master:/usr/hadoop /usr/hive/hadoop 查看端口是否被监听netstat -nl|grep 10000","categories":[{"name":"Linux","slug":"Linux","permalink":"http://gangtieguo.cn/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://gangtieguo.cn/tags/linux/"},{"name":"开发","slug":"开发","permalink":"http://gangtieguo.cn/tags/开发/"}]},{"title":"博客备份.md","slug":"博客修改备份","date":"2018-05-08T10:34:55.000Z","updated":"2018-05-17T16:18:46.428Z","comments":true,"path":"2018/05/08/博客修改备份/","link":"","permalink":"http://gangtieguo.cn/2018/05/08/博客修改备份/","excerpt":"","text":"1234567891011121314151617&lt;% if (!is_post()) &#123; %&gt; &lt;% if (site.tags.length)&#123; %&gt; &lt;div class=&quot;widget tag&quot;&gt; &lt;h3 class=&quot;title&quot;&gt;&lt;%= __(&apos;标签 :&apos;) %&gt;&lt;/h3&gt; &lt;%- list_categories(site.tags) %&gt; &lt;/div&gt; &lt;% &#125; %&gt; &lt;% &#125; %&gt; &lt;% if (!is_post()) &#123; %&gt; &lt;% if (site.categories.length)&#123; %&gt; &lt;div class=&quot;widget tag&quot;&gt; &lt;h2 class=&quot;title&quot;&gt;&lt;%= __(&apos;分类 :&apos;) %&gt;&lt;/h2&gt; &lt;h4&gt; &lt;%- list_categories(site.categories) %&gt;&lt;/h4&gt; &lt;/div&gt; &lt;% &#125; %&gt; &lt;% &#125; %&gt; 123456&lt;% if (!index &amp;&amp; post.toc) &#123; %&gt; &lt;div id=&quot;toc&quot; class=&quot;toc-article&quot;&gt; &lt;strong class=&quot;toc-title&quot;&gt;&lt;%= __(&apos;&apos;) %&gt;&lt;/strong&gt; &lt;%- toc(post.content) %&gt; &lt;/div&gt; &lt;% &#125; %&gt;","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://gangtieguo.cn/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://gangtieguo.cn/tags/Hexo/"},{"name":"Other","slug":"Other","permalink":"http://gangtieguo.cn/tags/Other/"}]},{"title":"spring集成权限校验","slug":"spring集成权限校验","date":"2018-05-08T10:34:55.000Z","updated":"2018-05-17T12:21:22.941Z","comments":true,"path":"2018/05/08/spring集成权限校验/","link":"","permalink":"http://gangtieguo.cn/2018/05/08/spring集成权限校验/","excerpt":"shiro简介shiro是权限控制的一个框架是一个强大易用的Java安全框架，提供了认证、授权、加密和会话管理功能，可为任何应用提供安全保障 - 从命令行应用、移动应用到大型网络及企业应用。","text":"shiro简介shiro是权限控制的一个框架是一个强大易用的Java安全框架，提供了认证、授权、加密和会话管理功能，可为任何应用提供安全保障 - 从命令行应用、移动应用到大型网络及企业应用。 权限控制的方式权限有四种实现方式注解(基于代理),url拦截(基于过滤器),shiro标签库(基于标签),编写代码(及其不推荐)不论哪种方式:都需要引入spring用于整合shiro的过滤器 web.xml中:DelegatingFilterProxy=&gt;spring整合shiro配置spring提供的用于整合shiro框架的过滤器123456789101112131415 &lt;filter&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy &lt;/fileter&gt;``` filet-name需要和**spring配置文件**中的一个BEAN对象的id保持一致**非常重要** ### 配置 I. 注解方式,注解是利用生成的代理对象来完成权限校验: spring框架会为当前action对象(加注解的action)创建一个代理对象,如果有权限,就执行这个方法,不然就会报**异常**(将spring,Strust配置文件丰富:添加权限的注解,struts添加捕获异常,跳转页面) 1. 需要在spring配置文件中进行配置开启注解**DefaultAdvisorAutoProxyCreator**, 并配置成cjlib方式的注解 ```xml&lt;property name=\"proxyTargetClass\" value=\"true\"&gt;\\&lt;/property&gt; 注解实现权限当为jdk模式的时候方法注解实现权限过滤抛异常的原因:因为如果是jdk方式的话,实现的接口modelDriven只有一个getModel方法所以不能进行对除该方法外其他方法进行注解 定义切面类AuthorizationAttributeSourceAdvisor 1&lt;bean id=\"authorizationAttributeSourceAdvisor\" class=\"org.apache.shiro.spring.security.interceptor.AuthorizationAttributeSourceAdvisor\"&gt;&lt;/bean&gt; 在需要权限才能访问的方法上添加注解 1234567891011121314151617181920212223242526272829 @RequiresPermissions(\"relo_delete这是权限名称\") ``` II. url拦截(springxml) 基于过滤器或者拦截器实现 ```xml&lt;bean id=\"shiroFilter\" class=\"org.apache.shiro.spring.web.ShiroFilterFactoryBean\"&gt; &lt;property name=\"securityManager\" ref=\"securityManager\"/&gt; &lt;property name=\"loginUrl\" value=\"/login.jsp\"/&gt; &lt;property name=\"unauthorizedUrl\" value=\"/unauthorized.jsp\"/&gt; &lt;property name=\"filterChainDefinitions\"&gt; &lt;value&gt; /css/** = anon /js/** = anon /images/** = anon /validatecode.jsp* = anon /login.jsp* = anon /userAction_login.action = anon /page_base_staff.action = perms[\"staff\"] /** = authc &lt;!--/** = authc--&gt; &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!--开启自动代理,并且将代理代理模式设置为cjlib--&gt; &lt;bean id=\"defaultAdvisorAutoProxyCreator\" class=\"org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator\"&gt; &lt;!--设置成cglib方式--&gt; &lt;property name=\"proxyTargetClass\" value=\"true\"&gt;&lt;/property&gt; &lt;/bean&gt; shiro的使用 在web.xml中引入用于创建shiro框架的过滤器web.xml中:DelegatingFilterProxy=&gt;spring整合shiro注意引入的位置:要在struts核心过滤器的前面,StrutsPrepareAndExcutFilter,不然,所有请求会通过struts过滤器获直接访问得到,shiro的过滤器将不会起到作用 在Spring中整合shiro2.1). shiro框架过滤器:ShiroFilterFactoryBean 需要声明那些过滤器,那些资源需要匹配那些过滤器,采用url拦截方式进行的路径对应的拦截器2.2). 配置安全管理器:DefaultWebSecurityManager 需要注入 自定义的Realm bean对象 1234567891011121314151617181920212223242526272829303132333435363738 &lt;!--配置一个shiro框架的过滤器工厂bean,用于创建shiro框架的过滤器--&gt; &lt;bean id=\"shiroFilter\" class=\"org.apache.shiro.spring.web.ShiroFilterFactoryBean\"&gt; &lt;property name=\"securityManager\" ref=\"securityManager\"/&gt; &lt;property name=\"loginUrl\" value=\"/login.jsp\"/&gt; &lt;property name=\"unauthorizedUrl\" value=\"/unauthorized.jsp\"/&gt; &lt;property name=\"filterChainDefinitions\"&gt; &lt;value&gt; /css/** = anon /js/** = anon /images/** = anon /validatecode.jsp* = anon /login.jsp* = anon /userAction_login.action = anon /page_base_staff.action = perms[\"staff\"] /** = authc &lt;!--/** 表示所有/下所有路径,包括下面的所有路径--&gt; &lt;!--/validatecode.jsp* 表示所有除了validatecode.jsp,还包括jsp后追加其他内容的.如validatecode.jsp?'+Math.random();防止验证码读取缓存 &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!--开启自动代理,并且将代理代理模式设置为cjlib 动态代理分为两类 基于jdk 创建的类必须要实现一个接口,这是面向接口的动态代理 基于cjlib 创建的类不能用final修饰--&gt; &lt;bean id=\"defaultAdvisorAutoProxyCreator\" class=\"org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator\"&gt; &lt;!--设置成cglib方式--&gt; &lt;property name=\"proxyTargetClass\" value=\"true\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--定义aop通知+切入点--&gt; &lt;bean id=\"authorizationAttributeSourceAdvisor\" class=\"org.apache.shiro.spring.security.interceptor.AuthorizationAttributeSourceAdvisor\"&gt;&lt;/bean&gt; &lt;!--注入安全管理器--&gt; &lt;bean id=\"securityManager\" class=\"org.apache.shiro.web.mgt.DefaultWebSecurityManager\"&gt; &lt;property name=\"realm\" ref=\"bosRealm\"&gt;&lt;/property&gt; &lt;property name=\"cacheManager\" ref=\"ehCacheManager\"&gt;&lt;/property&gt; &lt;/bean&gt; 在登陆认证的方法中加入subject controller中的login方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344public String login()&#123;Subject subject = SecurityUtils.getSubject(); //创建一个用户名密码令牌 AuthenticationToken token = new UsernamePasswordToken(getModel().getUsername(), MD5Utils.md5( getModel().getPassword())); try &#123; //认证 subject.login(token); &#125; catch (Exception e) &#123; this.addActionError(\"用户名或者密码错误\"); return LOGIN; &#125; /*当通过认证,跳入主页*/ User user = (User) subject.getPrincipal(); /*将用户信息存入session*/ ServletActionContext.getRequest().getSession().setAttribute(\"currentUser\", user); /*返回主页*/ return \"\";&#125;``` 4. 自定义Realm(用于权限的具体实施,即认证和授权)一般实现Realm接口的 **AuthorizingRealm** 实例 4.1实现认证 重写doGetAuthenticationInfo方法必须继承*AuthorizingRealm* 在需要交付给spring生成,并需要在安全注册管理器中注入属性Realm```javaprotected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123;UsernamePasswordToken mytoken = (UsernamePasswordToken) token; String username = mytoken.getUsername(); DetachedCriteria dc = DetachedCriteria.forClass(User.class); dc.add(Restrictions.eq(\"username\",username)); List&lt;User&gt; list = userDao.findByCriteria(dc); if(list != null &amp;&amp; list.size() &gt;0)&#123; User user = list.get(0); String dbPassword = user.getPassword(); AuthenticationInfo info = new SimpleAuthenticationInfo(user,dbPassword,this.getName()); return info; &#125;else&#123; return null; &#125; &#125; 4.2实现授权 重写doGetAuthorizationInfo方法 12345678910111213141516171819202122232425262728293031323334353637383940protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123;/*获的简单授权对象,用于授权的*/ SimpleAuthorizationInfo info = new SimpleAuthorizationInfo(); /*授权staff权限*/ //info.addStringPermission(\"staff\"); //步骤获得授权对象,获得当前用户,获得当前用户的权限(若为admin即授予所有权限),当前用户授权 //获得对象 User user = (User)principals.getPrimaryPrincipal(); List&lt;Function&gt; fList = null; //获得权限 if(user.getUsername().equals(\"admin\"))&#123; fList = functionDao.findAll(); &#125;else&#123; fList = functionDao.findFunctionByUserId(user.getId()); &#125; //授予权限 for(Function f : fList)&#123; info.addStringPermission(f.getCode());&#125;``` ## 关于Shiro中使用 **encache** 1.引入包 `在spring配置文件中配置以下` 2.配置文件ehcache.xml ```xml&lt;ehcache xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:noNamespaceSchemaLocation=\"../config/ehcache.xsd\"&gt; &lt;defaultCache maxElementsInMemory=\"10000\" eternal=\"false\" timeToIdleSeconds=\"120\" timeToLiveSeconds=\"120\" overflowToDisk=\"true\" maxElementsOnDisk=\"10000000\" diskPersistent=\"false\" diskExpiryThreadIntervalSeconds=\"120\" memoryStoreEvictionPolicy=\"LRU\" /&gt;&lt;/ehcache&gt; &lt;!--eternal是否永久有效--&gt; 3.引入缓存管理器EhCacheManager(shiro包中的),并设置配置文件;4.将缓存管理器注入安全管理器DefaultWebSecurityManager12345678910&lt;!--注册安全管理器--&gt;&lt;bean id=\"securityManager\" class=\"org.apache.shiro.web.mgt.DefaultWebSecurityManager\"&gt; &lt;property name=\"realm\" ref=\"bosRealm\"&gt;&lt;/property&gt; &lt;property name=\"cacheManager\" ref=\"ehCacheManager\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"bosRealm\" class=\"org.yao.bos.web.action.realm.BOSRealm\"&gt;&lt;/bean&gt; &lt;!--注入缓存管理器--&gt; &lt;bean id=\"ehCacheManager\" class=\"org.apache.shiro.cache.ehcache.EhCacheManager\"&gt; &lt;property name=\"cacheManagerConfigFile\" value=\"classpath:ehcache.xml\"&gt;&lt;/property&gt; &lt;/bean&gt;","categories":[{"name":"Spring","slug":"Spring","permalink":"http://gangtieguo.cn/categories/Spring/"}],"tags":[{"name":"开发","slug":"开发","permalink":"http://gangtieguo.cn/tags/开发/"},{"name":"Java","slug":"Java","permalink":"http://gangtieguo.cn/tags/Java/"},{"name":"技术","slug":"技术","permalink":"http://gangtieguo.cn/tags/技术/"}]}]}