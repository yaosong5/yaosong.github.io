{"meta":{"title":"钢铁锅","subtitle":"应尽便须尽，无复独多虑","description":"纵浪大化中，不喜亦不悲","author":"GTG","url":"http://gangtieguo.cn"},"pages":[{"title":"","date":"2018-05-18T06:50:40.022Z","updated":"2018-05-17T02:15:40.515Z","comments":true,"path":"google00655d7c846aab3a.html","permalink":"http://gangtieguo.cn/google00655d7c846aab3a.html","excerpt":"","text":"google-site-verification: google00655d7c846aab3a.html"},{"title":"","date":"2018-05-18T06:50:40.014Z","updated":"2018-05-17T01:53:01.988Z","comments":true,"path":"baidu_verify_WHXmBFaAkY.html","permalink":"http://gangtieguo.cn/baidu_verify_WHXmBFaAkY.html","excerpt":"","text":"WHXmBFaAkY"},{"title":"关于","date":"2018-05-08T07:52:07.000Z","updated":"2018-08-07T07:27:50.398Z","comments":true,"path":"about/index.html","permalink":"http://gangtieguo.cn/about/index.html","excerpt":"","text":"Nothing"},{"title":"404 Not Found：该页无法显示","date":"2018-05-18T06:50:42.172Z","updated":"2018-05-08T10:00:51.508Z","comments":false,"path":"/404.html","permalink":"http://gangtieguo.cn//404.html","excerpt":"","text":""},{"title":"分类","date":"2018-08-07T07:28:04.845Z","updated":"2018-08-07T07:28:04.841Z","comments":true,"path":"categories/index.html","permalink":"http://gangtieguo.cn/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-08-07T07:27:29.140Z","updated":"2018-08-07T07:27:29.135Z","comments":true,"path":"tags/index.html","permalink":"http://gangtieguo.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Json与Scala类型的相互转换处理","slug":"Json与Scala类型的一些互相转换处理","date":"2018-08-10T17:19:05.443Z","updated":"2018-08-10T17:26:04.793Z","comments":true,"path":"2018/08/11/Json与Scala类型的一些互相转换处理/","link":"","permalink":"http://gangtieguo.cn/2018/08/11/Json与Scala类型的一些互相转换处理/","excerpt":"[TOC] 在开发过程中时常会有对json数据的一些处理，现做一些记录","text":"[TOC] 在开发过程中时常会有对json数据的一些处理，现做一些记录 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import com.alibaba.fastjson.&#123;JSON, JSONArray, JSONObject&#125;import com.fasterxml.jackson.databind.ObjectMapperimport com.fasterxml.jackson.module.scala.DefaultScalaModuleimport net.minidev.json.parser.JSONParserimport scala.collection.JavaConversions.mapAsScalaMapimport scala.collection.mutableimport java.util/** * json utils */object JsonUtils &#123; val mapper: ObjectMapper = new ObjectMapper() def toJsonString(T: Object): String = &#123; mapper.registerModule(DefaultScalaModule) mapper.writeValueAsString(T) &#125; def getArrayFromJson(jsonStr: String) = &#123; JSON.parseArray(jsonStr) &#125; def getObjectFromJson(jsonStr: String): JSONObject = &#123; JSON.parseObject(jsonStr) &#125; /** * 配合getObjectFromJson 使用把 JSONObject 变为 map * @param jsonObj * @return */ def jsonObj2Map(jsonObj:JSONObject): mutable.Map[String, String] = &#123; var map = mutable.Map[String, String]() val itr: util.Iterator[String] = jsonObj.keySet().iterator() while (itr.hasNext) &#123; val key = itr.next() map += ((key, jsonObj.getString(key))) &#125; map &#125; /** * json 字符串转成 Map * #############有些情况下转换会有问题############### * @param json * @return */ def json2Map(json: String): mutable.HashMap[String,String] =&#123; val map : mutable.HashMap[String,String]= mutable.HashMap() val jsonParser =new JSONParser() //将string转化为jsonObject val jsonObj: JSONObject = jsonParser.parse(json).asInstanceOf[JSONObject] //获取所有键 val jsonKey = jsonObj.keySet() val iter = jsonKey.iterator() while (iter.hasNext)&#123; val field = iter.next() val value = jsonObj.get(field).toString if(value.startsWith(\"&#123;\")&amp;&amp;value.endsWith(\"&#125;\"))&#123; val value = mapAsScalaMap(jsonObj.get(field).asInstanceOf[util.HashMap[String, String]]) map.put(field,value.toString()) &#125;else&#123; map.put(field,value) &#125; &#125; map &#125; /** * map 转换成 json 字符串 * @param map * @return */ def map2Json(map : mutable.Map[String,String]): String = &#123; import net.minidev.json.&#123;JSONObject&#125; import scala.collection.JavaConversions.mutableMapAsJavaMap val jsonString = JSONObject.toJSONString(map) jsonString &#125;&#125; 测试实例123456789101112131415161718def main(args: Array[String]) &#123; val json = \"[&#123;\\\"batchid\\\":305322456,\\\"amount\\\":20.0,\\\"count\\\":20&#125;,&#123;\\\"batchid\\\":305322488,\\\"amount\\\":\\\"10.0\\\",\\\"count\\\":\\\"10\\\"&#125;]\" val array: JSONArray = JsonUtils.getArrayFromJson(json) println(array) array.toArray().foreach(json=&gt;&#123; println(json) val jobj = json.asInstanceOf[JSONObject] println(jobj.get(\"batchid\")) &#125;) val jsonStr = \"&#123;\\\"batchid\\\":119,\\\"amount\\\":200.0,\\\"count\\\":200&#125;\" val jsonObj: JSONObject = JsonUtils.getObjectFromJson(jsonStr) println(jsonObj) val jsonObj2: JSONObject = JsonUtils.getObjectFromJson(\"&#123;'name':'Wang','age':18,'tag1':[&#123;'tn1':'100','tn2':'101','ts':'ts01'&#125;,&#123;'tn1':'100','tn2':'101','ts':'ts02'&#125;,&#123;'tn1':'100','tn2':'101','ts':'ts03'&#125;]&#125;\") println(jsonObj2)&#125;","categories":[{"name":"大数据","slug":"大数据","permalink":"http://gangtieguo.cn/categories/大数据/"}],"tags":[{"name":"Json","slug":"Json","permalink":"http://gangtieguo.cn/tags/Json/"},{"name":"Scala","slug":"Scala","permalink":"http://gangtieguo.cn/tags/Scala/"}]},{"title":"Spark读取HBase","slug":"Spark读取Hbase","date":"2018-08-10T16:18:11.706Z","updated":"2018-08-10T17:56:47.563Z","comments":true,"path":"2018/08/11/Spark读取Hbase/","link":"","permalink":"http://gangtieguo.cn/2018/08/11/Spark读取Hbase/","excerpt":"[TOC] Spark读取Hbase","text":"[TOC] Spark读取Hbase spark配置首先spark的配置 12345678910111213141516171819202122val array = Array( (\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\"), (\"spark.storage.memoryFraction\", \"0.3\"), (\"spark.memory.useLegacyMode\", \"true\"), (\"spark.shuffle.memoryFraction\", \"0.6\"), (\"spark.shuffle.file.buffer\", \"128k\"), (\"spark.reducer.maxSizeInFlight\", \"96m\"), (\"spark.sql.shuffle.partitions\", \"500\"), (\"spark.default.parallelism\", \"180\"), (\"spark.dynamicAllocation.enabled\", \"false\") ) val conf = new SparkConf().setAll(array) .setJars(Array(\"your.jar\")) val sparkSession: SparkSession = SparkSession .builder .appName(applicationName) .enableHiveSupport() .master(\"spark://master:7077\") .config(conf) .getOrCreate() val sqlContext = sparkSession.sqlContext val sparkContext: SparkContext = sparkSession.sparkContext Hbase配置1234567891011121314151617181920212223242526272829303132333435363738394041424344val hBaseConf = HBaseConfiguration.create()var scan = new Scan();scan.addFamily(Bytes.toBytes(\"cf\"));var proto = ProtobufUtil.toScan(scan)var scanToString = Base64.encodeBytes(proto.toByteArray())//以为全局扫描的方式hBaseConf.set(TableInputFormat.SCAN,scanToString)//如需要设置起止行的话//scan.setStartRow(Bytes.toBytes(\"1111111111111\"))//scan.setStopRow(Bytes.toBytes(\"999999999999999\"))hBaseConf.set(\"hbase.zookeeper.quorum\",\"zk1,zk2,zk3\")hBaseConf.set(\"phoenix.query.timeoutMs\",\"1800000\")hBaseConf.set(\"hbase.regionserver.lease.period\",\"1200000\")hBaseConf.set(\"hbase.rpc.timeout\",\"1200000\")hBaseConf.set(\"hbase.client.scanner.caching\",\"1000\")hBaseConf.set(\"hbase.client.scanner.timeout.period\",\"1200000\")//表名配置hBaseConf.set(TableInputFormat.INPUT_TABLE,\"beehive:a_up_rawdata\")// 从数据源获取数据val hbaseRDD = sparkContext.newAPIHadoopRDD(hBaseConf,classOf[TableInputFormat],classOf[org.apache.hadoop.hbase.io.ImmutableBytesWritable],classOf[org.apache.hadoop.hbase.client.Result])//即可得到读取Hbase查询的RDD val hbaseJsonRdd: RDD[String] = hbaseRDD.filter(t =&gt; broadCast.value.contains(Bytes.toString(t._2.getRow)) //********************************操作每个分区的数据******************************** ).mapPartitions( it=&gt;&#123; it.map(x=&gt;x._2).map(hbaseValue =&gt; &#123; var listBuffer = new ListBuffer[String]() //对应的值 val rowkey = Bytes.toString(hbaseValue.getRow) val value: String = Bytes.toString(hbaseValue.getValue(Bytes.toBytes(\"cf\"), Bytes.toBytes(\"填写获取哪一列\"))) if (null != value ) &#123; //如果value不为空则再进行操作 &#125; listBuffer &#125;) &#125;).flatMap(r =&gt; r)//注意map操作是需要函数内部有返回值的，如果只是打印的话，换成foreach算子 println(s\"hbaseJsonRdd.size为：$&#123;hbaseJsonRdd.count()&#125;\") sparkContext.stop() sparkSession.close() println(\"ALL 已经关闭，程序终止\")","categories":[{"name":"大数据","slug":"大数据","permalink":"http://gangtieguo.cn/categories/大数据/"}],"tags":[{"name":"HBase","slug":"HBase","permalink":"http://gangtieguo.cn/tags/HBase/"},{"name":"Spark","slug":"Spark","permalink":"http://gangtieguo.cn/tags/Spark/"}]},{"title":"Spark读取HBase解析json创建临时表录入到Hive表","slug":"Spark读取HBase解析json创建临时表录入到Hive表","date":"2018-08-10T16:09:46.585Z","updated":"2018-08-10T18:21:36.344Z","comments":true,"path":"2018/08/11/Spark读取HBase解析json创建临时表录入到Hive表/","link":"","permalink":"http://gangtieguo.cn/2018/08/11/Spark读取HBase解析json创建临时表录入到Hive表/","excerpt":"[TOC] 介绍：主要是读取通过mysql查到关联关系然后读取HBASE里面存放的Json，通过解析json将json数组对象里的元素拆分成单条json,再将json映射成临时表，查询临时表将数据落入到hive表中 注意：查询HBASE的时候，HBase集群的HMaster，HRegionServer需要是正常运行 主要将内容拆分成几块，spark读取HBase，spark解析json将json数组中每个元素拆成一条（比如json数组有10个元素，需要解析平铺成19个json，那么对应临时表中就是19条记录，对应查询插入到hive也就是19条记录） spark读取本地HBase","text":"[TOC] 介绍：主要是读取通过mysql查到关联关系然后读取HBASE里面存放的Json，通过解析json将json数组对象里的元素拆分成单条json,再将json映射成临时表，查询临时表将数据落入到hive表中 注意：查询HBASE的时候，HBase集群的HMaster，HRegionServer需要是正常运行 主要将内容拆分成几块，spark读取HBase，spark解析json将json数组中每个元素拆成一条（比如json数组有10个元素，需要解析平铺成19个json，那么对应临时表中就是19条记录，对应查询插入到hive也就是19条记录） spark读取本地HBase 参考 Spark读取HBase json样例 读取hbasehbase里面存放的是身份id作为rowkey来存放的数据 JSON、JSONObject类包是引用的com.alibaba.fastjson包下的 123456789101112131415161718192021222324252627282930313233343536val hbaseJsonRdd: RDD[String] = hbaseRDD.mapPartitions( it=&gt;&#123; it.map(x=&gt;x._2).map(hbaseValue =&gt; &#123; var listBuffer = new ListBuffer[String]() //对应的值 //获取key,也就是身份证号，通过身份证号在广播map中的值 也就是risk_request_id val idNum = Bytes.toString(hbaseValue.getRow) val json: String = Bytes.toString(hbaseValue.getValue(Bytes.toBytes(\"cf\"), Bytes.toBytes(s\"273468436_data\"))) if (null != json ) &#123; //********************************获取到json之后进行解析******************************** try &#123; val jSONObject: JSONObject = JSON.parseObject(json) if (jSONObject != null) &#123; val contactRegion = repostData.getJSONArray(\"contact_region\") if (contactRegion != null) &#123; contactRegion.toArray().foreach(v =&gt; &#123; val arrays = JSON.parseObject(v.toString) //val map = JSON.toJavaObject(arrays,classOf[util.Map[String,String]]) val map: mutable.Map[String, String] = JsonUtils.jsonObj2Map(arrays) //将json 转为Map //将******************************** 日期和requestId request_id封装到 map里面********************************，再将map转为json map.put(\"region_id\", \"2\") map.put(\"request_id\", \"1\") map.put(\"region_create_at\", \"0000\") map.put(\"region_update_at\", \"0000\") listBuffer += (JsonUtils.map2Json(map)) &#125;) &#125; &#125; &#125; &#125;catch &#123; case e: Exception =&gt; e.printStackTrace() &#125; &#125; listBuffer &#125;) &#125;).flatMap(r =&gt; r) 代码中的 jsonObj2Map,map2Json 方法参照 Json与Scala类型的相互转换处理 这里拆分json数组每一个元素为一个json，存放在ListBuffer里面，通过flatMap压平rdd里面的内容。 映射临时表最后将得到的json通过sparkSql创建成临时表 1234567 val dataFrame: DataFrame = sqlContext.read.json(hbaseJsonRdd)dataFrame.createOrReplaceTempView(\"tmp_hbase\")//// 测试println(\"++++++++++++++++++++++++++++++hbaseJsonRdd.....创建临时表 测试查询数据 ......++++++++++++++++++++++++++++++\")val df = sqlContext.sql(\"select * from tmp_hbase limit 1\")df.show(1) 插入Hive1234567sqlContext.sql(\"insert into ods.ods_r_juxinli_region_n partition(dt='20180101') select region_id as juxinli_region_id,request_id as juxinli_request_id,\" + \"region_loc as juxinli_rejion_loc ,region_uniq_num_cnt as juxinli_region_uniq_num_cnt ,\" + \"region_call_out_time as juxinli_region_call_out_time,region_call_in_time as juxinli_region_call_in_time,region_call_out_cnt as juxinli_region_call_out_cnt,\" + \"region_call_in_cnt as juxinli_region_call_in_cnt,region_avg_call_in_time as juxinli_region_avg_call_in_time,region_avg_call_out_time as juxinli_region_avg_call_out_time,\" + \"region_call_in_time_pct as juxinli_region_call_in_time_pct,region_call_out_time_pct as juxinli_region_call_out_time_pct ,region_call_in_cnt_pct as juxinli_region_call_in_cnt_pct,\" + \"region_call_out_cnt_pct as juxinli_region_call_out_cnt_pct,region_create_at as juxinli_region_create_at,region_update_at as juxinli_region_update_at from tmp_hbase\") &#125; 关闭资源 12sparkContext.stop()sparkSession.close()","categories":[{"name":"大数据","slug":"大数据","permalink":"http://gangtieguo.cn/categories/大数据/"}],"tags":[{"name":"Spark","slug":"Spark","permalink":"http://gangtieguo.cn/tags/Spark/"},{"name":"SparkSOL","slug":"SparkSOL","permalink":"http://gangtieguo.cn/tags/SparkSOL/"}]},{"title":"HBase拷贝生产环境数据到本地运行调试","slug":"HBase拷贝生产环境数据到本地运行调试","date":"2018-08-10T10:19:15.453Z","updated":"2018-08-10T16:02:52.859Z","comments":true,"path":"2018/08/10/HBase拷贝生产环境数据到本地运行调试/","link":"","permalink":"http://gangtieguo.cn/2018/08/10/HBase拷贝生产环境数据到本地运行调试/","excerpt":"[TOC] 由于线上环境要经过跳板机跳转，并且打包测试，上传jar包步骤多，不然的话，要进行各种端口转发，且有权限控制，不易在本地idea编辑器上进行程序运行及调试 现在想法是，将线上测试环境的数据拷贝小部分到本地自己搭建的集群，进行程序的逻辑和初期调试 此贴就是记录一些操作 这都是要基于本地有HBASE及其依赖组件的。 主要思路是，拷贝线上查询的结果到文件hbaseout1.txt，将hbaseout1.txt文件sz导入本地 再在本地集群上将数据插入到hbase","text":"[TOC] 由于线上环境要经过跳板机跳转，并且打包测试，上传jar包步骤多，不然的话，要进行各种端口转发，且有权限控制，不易在本地idea编辑器上进行程序运行及调试 现在想法是，将线上测试环境的数据拷贝小部分到本地自己搭建的集群，进行程序的逻辑和初期调试 此贴就是记录一些操作 这都是要基于本地有HBASE及其依赖组件的。 主要思路是，拷贝线上查询的结果到文件hbaseout1.txt，将hbaseout1.txt文件sz导入本地 再在本地集群上将数据插入到hbase 1、创建和线上同名通结构的表在线上执行 describe &#39;beehive:a_up_rawdata&#39; 得到 在本地执行 1234hbase shellcreate_namespace &apos;beehive&apos;create &apos;beehive:a_up_rawdata&apos;,&#123;NAME =&gt; &apos;cf&apos;, BLOOMFILTER =&gt; &apos;ROW&apos;, VERSIONS =&gt; &apos;1&apos;, IN_MEMORY =&gt; &apos;false&apos;, KEEP_DELETED_CELLS =&gt; &apos;FALSE&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, COMPRESSION =&gt; &apos;NONE&apos;, TTL =&gt; &apos;FOREVER&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, BLOCKCACHE =&gt; &apos;true&apos;, BLOCKSIZE =&gt; &apos;65536&apos;, REPLICATION_SCOPE =&gt; &apos;1&apos;&#125; 2、拷贝线上hbase数据查询结果导入文件在线上机器任意目录执行 1echo \"get 'beehive:a_up_rawdata','530111199211287371',&#123;COLUMN=&gt;'cf:273468436_data'&#125;\"| hbase shell&gt; hbaseout1.txt 解析: get &#39;beehive:a_up_rawdata&#39;,&#39;530111199211287371&#39;,{COLUMN=&gt;&#39;cf:273468436_data&#39;}是执行的hbase的查询语句，将查询的结果存入到当前目录 hbaseout1.txt文件中 查询文件下载到本地sz hbaseout1.txt 修改文件内容可以查看hbaseout1.txt中可以看到会有表头 需要将这部分表头数据删除，组成标准的导入文件 修改文件编码 在通过 hbase shell 查看中文值时, 是 unicode 编码格式，使得直接查看中文值不太方便。如果要查看需要把 unicode 编码进行 decode 将查询结果导出来 1234567print ('需要转码内容'.decode('utf-8'))命令样例python 2.7 print ('***\\xE4\\xBD\\xA010009 '.decode('utf-8'))python 3 print '***\\xE4\\xBD\\xA010009 '.decode('utf-8') 可以有更友好的将内容设置为文件名，然后将转码后重新写入到一个文件，后续会更新 转码过后，文字显示正确 重新组合文件由于导入到hbase命令为 **格式：hbase [类][分隔符] [行键，列族][表] [导入文件] 由于我这次导入的文件里面有“,”，所有将分隔符设置为“|” 更改后的文件格式为 将文件上传到hdfs 1hadoop fs -put hadoop fs -put hbaseout1.txt /local/ 将数据导入到本地hbase1hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=\"|\" -Dimporttsv.columns=HBASE_ROW_KEY,cf:273468436_data beehive:a_up_rawdata /local/hbaseout2.txt 3、校验查看在hue上查看hbase内容，显示有数据 在hbase shell 查看","categories":[{"name":"大数据","slug":"大数据","permalink":"http://gangtieguo.cn/categories/大数据/"}],"tags":[{"name":"HBase，操作","slug":"HBase，操作","permalink":"http://gangtieguo.cn/tags/HBase，操作/"}]},{"title":"Hbase-shell操作","slug":"Hbase-shell操作","date":"2018-08-10T09:27:05.100Z","updated":"2018-08-10T18:00:25.636Z","comments":true,"path":"2018/08/10/Hbase-shell操作/","link":"","permalink":"http://gangtieguo.cn/2018/08/10/Hbase-shell操作/","excerpt":"[TOC] hbase使用命令行操作，简单直接，方便快捷，掌握一点必备的基础命令。 HBase启动命令行 1$HBASE_HOME/bin/hbase shell","text":"[TOC] hbase使用命令行操作，简单直接，方便快捷，掌握一点必备的基础命令。 HBase启动命令行 1$HBASE_HOME/bin/hbase shell 创建表1create 'testtable',&#123;NAME=&gt;'cf',VERSIONS=&gt;2&#125;,&#123;NAME=&gt;'cf2',VERSIONS=&gt;2&#125; 创建namespace1create_namespace 'beehive' 查看表结构1disable 'testtable' 删除表1drop 'testtable' 修改表1234disable 'testtable'alter 'testtable',&#123;NAME=&gt;'cf',TTL=&gt;'10000000'&#125;,&#123;NAME=&gt;'cf2',TTL=&gt;'10000000'&#125;enable 'testtable'修改表必须先 disable 表 表数据的增删查改：添加数据：1put 'testtable','rowkey1','cf:key1','val1' 查询数据:12get 'testtable','rowkey1','cf:key1'get 'testtable','rowkey1', &#123;COLUMN=&gt;'cf:key1'&#125; 扫描表:1scan 'testtable',&#123;COLUMNS=&gt;cf:col1,LIMIT=&gt;5&#125; #可以添加STARTROW、TIMERANGE和FITLER等高级功能 查询表中的数据行数:语法：count &lt;table&gt;, {INTERVAL =&gt; intervalNum, CACHE =&gt; cacheNum} 1count 'testtable',&#123;INTERVAL =&gt; 100, CACHE =&gt; 500&#125; 删除数据:12delete 'testtable','rowkey1','cf:key1'truncate 'testtable'","categories":[{"name":"大数据","slug":"大数据","permalink":"http://gangtieguo.cn/categories/大数据/"}],"tags":[{"name":"HBase","slug":"HBase","permalink":"http://gangtieguo.cn/tags/HBase/"},{"name":"Shell","slug":"Shell","permalink":"http://gangtieguo.cn/tags/Shell/"}]},{"title":"Spark本地调试远程集群程序","slug":"Spark本地调试远程集群程序","date":"2018-08-07T08:09:43.314Z","updated":"2018-08-10T18:29:43.521Z","comments":true,"path":"2018/08/07/Spark本地调试远程集群程序/","link":"","permalink":"http://gangtieguo.cn/2018/08/07/Spark本地调试远程集群程序/","excerpt":"[TOC] 由于在生产环境中进行调试spark程序需要进行打包和各种跳板机跳转，最好在本地搭一套集群来进行一些代码基础检查。","text":"[TOC] 由于在生产环境中进行调试spark程序需要进行打包和各种跳板机跳转，最好在本地搭一套集群来进行一些代码基础检查。 需要将 本地集群中hdfs-site.xml core.site.xml 拷贝到本地工程的resource文件夹下，这样会应用这些配置，注意要在提交到生产环境的时候，替换成对应环境的配置文件 12345678910111213141516171819202122val array = Array( (\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\"), (\"spark.storage.memoryFraction\", \"0.3\"), (\"spark.memory.useLegacyMode\", \"true\"), (\"spark.shuffle.memoryFraction\", \"0.6\"), (\"spark.shuffle.file.buffer\", \"128k\"), (\"spark.reducer.maxSizeInFlight\", \"96m\"), (\"spark.sql.shuffle.partitions\", \"500\"), (\"spark.default.parallelism\", \"180\"), (\"spark.dynamicAllocation.enabled\", \"false\") ) val conf = new SparkConf().setAll(array) .setJars(Array(\"your.jar\")) val sparkSession: SparkSession = SparkSession .builder .appName(applicationName) .enableHiveSupport() .master(\"spark://master:7077\") .config(conf) .getOrCreate() val sqlContext = sparkSession.sqlContext val sparkContext: SparkContext = sparkSession.sparkContext","categories":[{"name":"大数据","slug":"大数据","permalink":"http://gangtieguo.cn/categories/大数据/"}],"tags":[{"name":"Spark","slug":"Spark","permalink":"http://gangtieguo.cn/tags/Spark/"}]},{"title":"Zookeeper的配置容器的搭建","slug":"zookeeper配置","date":"2018-08-06T19:06:03.170Z","updated":"2018-08-10T17:58:15.529Z","comments":true,"path":"2018/08/07/zookeeper配置/","link":"","permalink":"http://gangtieguo.cn/2018/08/07/zookeeper配置/","excerpt":"[TOC] 在usr目录下下载zk包，并且解压到/usr/目录，改名为zk，所以$ZK_HOME为/usr/zk 创建目录123mkdir -p /usr/zk/datamkdir -p /usr/zk/logstouch /usr/zk/data/myid","text":"[TOC] 在usr目录下下载zk包，并且解压到/usr/目录，改名为zk，所以$ZK_HOME为/usr/zk 创建目录123mkdir -p /usr/zk/datamkdir -p /usr/zk/logstouch /usr/zk/data/myid 更改配置文件vim $ZK_HOME/conf/zoo.cfg 12345dataDir=/usr/zk/datadataLogDir=/usr/zk/logsserver.1=zk1:2888:3888server.2=zk2:2888:3888server.3=zk3:2888:3888 zookeeper需要全部左右节点都启动才会选举leader，follower 所有节点启动的脚本 1234567# !/bin/bashecho 1 &gt; $ZK_HOME/data/myid$ZK_HOME/bin/zkServer.sh startssh root@zk2 \"echo 2 &gt; /usr/zk/data/myid\"ssh root@zk2 \"/usr/zk/bin/zkServer.sh start\"ssh root@zk3 \"echo 3 &gt; /usr/zk/data/myid\"ssh root@zk3 \"/usr/zk/bin/zkServer.sh start\" zk问题1、由于 zk 运行一段时间后，会产生大量的日志文件，把磁盘空间占满，导致整个机器进程都不能活动了，所以需要定期清理这些日志文件，方法如下： 1）、写一个脚本文件 cleanup.sh 内容如下： 12345678java -cp zookeeper.jar:lib/slf4j-api-1.6.1.jar:lib/slf4j-log4j12-1.6.1.jar:lib/log4j-1.2.15.jar:conf org.apache.zookeeper.server.PurgeTxnLog &lt;dataDir&gt; &lt;snapDir&gt; -n &lt;count&gt;其中： dataDir：即上面配置的 dataDir 的目录 snapDir：即上面配置的 dataLogDir 的目录 count：保留前几个日志文件，默认为 3 2）、通过 crontab 写定时任务，来完成定时清理日志的需求 123crontab -e 0 0 * * /opt/zookeeper-3.4.10/bin/cleanup.shHBase Master 高可用（HA）（http://www.cnblogs.com/captainlucky/p/4710642.html）HMaster 没有单点问题，HBase 中可以启动多个 HMaster，通过 Zookeeper 的 Master Election 机制保证总有一个 Master 运行。 所以这里要配置 HBase 高可用的话，只需要启动两个 HMaster，让 Zookeeper 自己去选择一个 Master Acitve。","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://gangtieguo.cn/categories/安装部署/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"},{"name":"zk","slug":"zk","permalink":"http://gangtieguo.cn/tags/zk/"}]},{"title":"Linux安装mysql","slug":"Linux安装mysql","date":"2018-07-24T15:42:18.647Z","updated":"2018-08-10T17:52:56.914Z","comments":true,"path":"2018/07/24/Linux安装mysql/","link":"","permalink":"http://gangtieguo.cn/2018/07/24/Linux安装mysql/","excerpt":"在linux yum安装mysql","text":"在linux yum安装mysql 12345678910111213141516171819yum install -y mysql-serverchkconfig --add mysqldchkconfig mysqld onchkconfig --list mysqldservice mysqld startmysql -u root -pEnter password: //默认密码为空，输入后回车即可set password for root@localhost=password('root'); 密码设置为rootset password for root@=password('root');默认情况下Mysql只允许本地登录，所以只需配置root@localhost就好设置所有ip访问密码为rootset password for root@%=password('root'); 密码设置为root （其实这一步可以不配）设置master访问密码为rootset password for root@master=password('root'); 密码设置为root （其实这一步可以不配）查询密码select user,host,password from mysql.user; 查看密码是否设置成功设置所有ip可以通过root访问GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'root' WITH GRANT OPTION;GRANT ALL PRIVILEGES ON *.* TO 'hive'@'%' IDENTIFIED BY 'hive' WITH GRANT OPTION;","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://gangtieguo.cn/categories/安装部署/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://gangtieguo.cn/tags/Linux/"},{"name":"Mysql","slug":"Mysql","permalink":"http://gangtieguo.cn/tags/Mysql/"}]},{"title":"Docker-machine的创建，mac宿主机和docker容器网络互通Docker容器与宿主机在同一ip段下","slug":"Docker-machine的搭建(与宿主机在同一ip段下)","date":"2018-07-19T19:02:08.124Z","updated":"2018-08-10T18:48:52.042Z","comments":true,"path":"2018/07/20/Docker-machine的搭建(与宿主机在同一ip段下)/","link":"","permalink":"http://gangtieguo.cn/2018/07/20/Docker-machine的搭建(与宿主机在同一ip段下)/","excerpt":"此文纯属命令记录，后续更新原理解说 更改virtual0的ip VBoxManage hostonlyif ipconfig vboxnet0 –ip 192.168.33.253 –netmask 255.255.255.0","text":"此文纯属命令记录，后续更新原理解说 更改virtual0的ip VBoxManage hostonlyif ipconfig vboxnet0 –ip 192.168.33.253 –netmask 255.255.255.0 ifconfig 查看创建虚拟机配置文件 Vagrantfile 也可以vagrant init 会生成一个空白的Vagrantfile vi Vagrantfile1234567891011121314151617181920212223Vagrant.configure(2) do |config| config.vm.box = \"dolbager/centos-7-docker\" config.vm.hostname = \"default\" config.vm.network \"private_network\", ip: \"192.168.33.1\",netmask: \"255.255.255.0\" config.vm.provider \"virtualbox\" do |v| v.name = \"default\" v.memory = \"2048\" # Change the network adapter type and promiscuous mode v.customize ['modifyvm', :id, '--nictype1', 'Am79C973'] v.customize ['modifyvm', :id, '--nicpromisc1', 'allow-all'] v.customize ['modifyvm', :id, '--nictype2', 'Am79C973'] v.customize ['modifyvm', :id, '--nicpromisc2', 'allow-all'] end # Install bridge-utils config.vm.provision \"shell\", inline: &lt;&lt;-SHELL curl -o /etc/yum.repos.d/CentOS-Base.repohttp://mirrors.aliyun.com/repo/Centos-7.repo curl -o /etc/yum.repos.d/epel.repohttp://mirrors.aliyun.com/repo/epel-7.repo yum clean all yum makecache yum update -y yum install bridge-utils net-tools -y SHELLend vagrant upvagrant ssh vagrant ssh-config 1scp ~/.vagrant.d/boxes/dolbager-VAGRANTSLASH-centos-7-docker/0.2/virtualbox/vagrant_private_key .vagrant/machines/default/virtualbox/private_key vagrant exit 1234567docker-machine create \\ --driver \"generic\" \\ --generic-ip-address 192.168.33.1 \\ --generic-ssh-user vagrant \\ --generic-ssh-key .vagrant/machines/default/virtualbox/private_key \\ --generic-ssh-port 22 \\ default 创建网桥docker1 和 docker network br通过vagrant 从虚拟机的 eth0 登录到虚拟机 vagrant sship -4 addr 创建 docker network br 123456789sudo docker network create \\ --driver bridge \\ --subnet=192.168.33.0/24 \\ --gateway=192.168.33.1 \\ --opt \"com.docker.network.bridge.enable_icc\"=\"true\" \\ --opt \"com.docker.network.bridge.enable_ip_masquerade\"=\"true\" \\ --opt \"com.docker.network.bridge.name\"=\"docker1\" \\ --opt \"com.docker.network.driver.mtu\"=\"1500\" \\ br 创建网桥配置文件docker1 vim /etc/sysconfig/network-scripts/ifcfg-docker1 123456789DEVICE=docker1TYPE=BridgeBOOTPROTO=staticONBOOT=yesSTP=onIPADDR=NETMASK=GATEWAY=DNS1= 修改网卡配置 eth1 :sudo vi /etc/sysconfig/network-scripts/ifcfg-eth1 12345678DEVICE=eth1BOOTPROTO=staticHWADDR=ONBOOT=yesNETMASK=GATEWAY=BRIDGE=docker1TYPE=Ethernet 参考：https://github.com/SixQuant/engineering-excellence/blob/master/docker/docker-install-mac-vm-centos.md","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://gangtieguo.cn/categories/安装部署/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"},{"name":"Docker-machine","slug":"Docker-machine","permalink":"http://gangtieguo.cn/tags/Docker-machine/"}]},{"title":"HIVE搭建","slug":"hive搭建","date":"2018-07-19T18:51:21.978Z","updated":"2018-08-07T06:26:06.556Z","comments":true,"path":"2018/07/20/hive搭建/","link":"","permalink":"http://gangtieguo.cn/2018/07/20/hive搭建/","excerpt":"[TOC] 配置HOME下载hive包，并解压 1http://archive.apache.org/dist/ ln -s hive-2.1.1 /usr/hive vi ~/.bashrc 1234567export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar$HIVE_HOME/bin/hiveexport HIVE_HOME=/usr/hivePATH=$HIVE_HOME/bin:$PATH#hive依赖于hadoop(可以不运行在同一主机，但是需要hadoop的配置)$HADOOP_HOME=/usr/hadoop source ~/.bashrc","text":"[TOC] 配置HOME下载hive包，并解压 1http://archive.apache.org/dist/ ln -s hive-2.1.1 /usr/hive vi ~/.bashrc 1234567export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar$HIVE_HOME/bin/hiveexport HIVE_HOME=/usr/hivePATH=$HIVE_HOME/bin:$PATH#hive依赖于hadoop(可以不运行在同一主机，但是需要hadoop的配置)$HADOOP_HOME=/usr/hadoop source ~/.bashrc 安装mysql Hive元数据介绍Hive 将元数据存储在 RDBMS 中，一般常用 MySQL 和 Derby。默认情况下，Hive 元数据保存在内嵌的 Derby 数据库中，只能允许一个会话连接，只适合简单的测试。实际生产环境中不适用， 为了支持多用户会话，则需要一个独立的元数据库，使用 MySQL 作为元数据库，Hive 内部对 MySQL 提供了很好的支持，配置一个独立的元数据库 1234567891011121314151617181920212223242526yum install -y mysql-serverchkconfig --add mysqldchkconfig mysqld onchkconfig --list mysqldservice mysqld startmysql -u root -pEnter password: //默认密码为空，输入后回车即可set password for root@localhost=password('root'); 密码设置为rootset password for root@=password('root');默认情况下Mysql只允许本地登录，所以只需配置root@localhost就好设置所有ip访问密码为rootset password for root@%=password('root'); 密码设置为root （其实这一步可以不配）设置master访问密码为rootset password for root@master=password('root'); 密码设置为root （其实这一步可以不配）查询密码select user,host,password from mysql.user; 查看密码是否设置成功设置所有ip可以通过root访问GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'root' WITH GRANT OPTION;GRANT ALL PRIVILEGES ON *.* TO 'hive'@'%' IDENTIFIED BY 'hive' WITH GRANT OPTION;mysql -uroot -prootcreate user 'hive' identified by 'hive';create user 'hive'@'%' identified by 'hive';create database hive; 配置Hivemkdir iotmp cp hive-default.xml.template hive-site.xml vim hive-site.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;configuration&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://localhost:3306/hive?characterEncoding=UTF-8&lt;/value&gt; &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;description&gt;Username to use against metastore database&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;description&gt;password to use against metastore database&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.querylog.location&lt;/name&gt; &lt;value&gt;/usr/hive/iotmp&lt;/value&gt; &lt;description&gt;Location of Hive run time structured log file&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.exec.local.scratchdir&lt;/name&gt; &lt;value&gt;/usr/hive/iotmp&lt;/value&gt; &lt;description&gt;Local scratch space for Hive jobs&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.downloaded.resources.dir&lt;/name&gt; &lt;value&gt;/usr/hive/iotmp&lt;/value&gt; &lt;description&gt;Temporary local directory for added resources in the remote file system.&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.metastore.uris&lt;/name&gt; &lt;value&gt;thrift://master:9083&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; Hive 的元数据可以存储在本地的 MySQL 中，但是大多数情况会是一个 mysql 集群，而且不在本地。所以在 hive 中需要开启远程 metastore。由于我是本地的 mysql，我就不配置下列属性了，但是如果是远程的 metastore，配置下面的属性。123456789101112&lt;property&gt; &lt;name&gt;hive.metastore.uris&lt;/name&gt; &lt;value&gt;&lt;/value&gt; &lt;description&gt;Thrift URI for the remote metastore. Used by metastore client to connect to remote metastore.&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.server2.transport.mode&lt;/name&gt; &lt;value&gt;http&lt;/value&gt; &lt;description&gt;Server transport mode. \"binary\" or \"http\".&lt;/description&gt;&lt;/property&gt;链接：https://www.jianshu.com/p/87b76a686216 Hive命令启动hiveserver21$HIVE_HOME/bin/hive --service hiveserver2 hiveserver端口号默认是10000 hiveserver2是否启动netstat -nl|grep 10000 启动hive123$HIVE_HOME/bin/hive如果调试，可以加上参数$HIVE_HOME/bin/hivehive -hiveconf hive.root.logger=DEBUG,console beeline工具测试使用jdbc方式连接1$HIVE_HOME/bin/beeline -u jdbc:hive2://localhost:10000 使用beeline通过jdbc连接上之后就可以像client一样操作。 hiveserver2会同时启动一个webui，端口号默认为10002，可以通过http://localhost:10002/访问界面中可以看到Session/Query/Software等信息。(此网页只可查看，不可以操作hive数据仓库) 参考https://blog.csdn.net/lblblblblzdx/article/details/79760959 参考https://www.cnblogs.com/netuml/p/7841387.html 报错 报错 Hive 2.3.3 MetaException(message:Version information not found in metastore.) 1schematool -initSchema -dbType mysql 参考https://stackoverflow.com/questions/50230515/hive-2-3-3-metaexceptionmessageversion-information-not-found-in-metastore http://sishuok.com/forum/blogPost/list/6221.html https://blog.csdn.net/nokia_hp/article/details/79054079","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://gangtieguo.cn/categories/安装部署/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"},{"name":"HIVE","slug":"HIVE","permalink":"http://gangtieguo.cn/tags/HIVE/"}]},{"title":"Docker构建免密ssh镜像","slug":"Docker构建免密登录镜像","date":"2018-07-19T18:49:08.996Z","updated":"2018-08-10T18:58:45.542Z","comments":true,"path":"2018/07/20/Docker构建免密登录镜像/","link":"","permalink":"http://gangtieguo.cn/2018/07/20/Docker构建免密登录镜像/","excerpt":"免密登录参考的是http://www.shushilvshe.com/data/docker-ssh.html文中涉及命令12345sudo yum -y install openssh-server openssh-clientsssh-keygen -t rsacp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keyschmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys","text":"免密登录参考的是http://www.shushilvshe.com/data/docker-ssh.html文中涉及命令12345sudo yum -y install openssh-server openssh-clientsssh-keygen -t rsacp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keyschmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys vim /etc/ssh/sshd_config 找到以下内容，并去掉注释符”#“ 123RSAAuthentication yesPubkeyAuthentication yesAuthorizedKeysFile .ssh/authorized_keys vim /etc/ssh/ssh_config 123Host * StrictHostKeyChecking no UserKnownHostsFile=/dev/null ​ 此文也可参考 http://www.voidcn.com/article/p-gxkeusey-ma.html https://blog.csdn.net/a85820069/article/details/78745899坑使用 docker run -i -t –name c1 centos6.6:basic /bin/bash 运行容器，sshd 服务是不开启的，必须先 - d 在用 exec 切入。 https://www.cnblogs.com/aiweixiao/p/5516974.html 1.【查看是否启动】 启动 SSH 服务 “/etc/init.d/sshd start”。然后用 netstat -antulp | grep ssh 看是否能看到相关信息就可以了。 2.【设置自动启动】 如何设置把 ssh 等一些服务随系统开机自动启动？ 方法一：[root@localhost ~]# vi /etc/rc.local 加入：service sshd start 或 /etc/init.d/sshd start chmod 777 /etc/ssh/ssh_host_ecdsa_key 12345678910111213141516# 免密登录mkdir -p /root/.ssh touch /root/.ssh/config echo &quot;StrictHostKeyChecking no&quot; &gt; /root/.ssh/config sed -i &quot;a UserKnownHostsFile /dev/null&quot; /root/.ssh/config # 开机启动RUN yum install -y openssh-server sudo RUN sed -i &apos;s/UsePAM yes/UsePAM no/g&apos; /etc/ssh/sshd_config # 下面这两句比较特殊，在centos6上必须要有，否则创建出来的容器sshd不能登录RUN ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key RUN ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key ssh服务文章当中的12345678910111213curl http://mirrors.aliyun.com/repo/Centos-6.repo &gt; /etc/yum.repos.d/CentOS-Base-6-aliyun.repomv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bakyum makecacheyum install -y net-tools which openssh-clients openssh-server iproute.x86_64 wgetservice sshd startsed -i 's/UsePAM yes/UsePAM no/g' /etc/ssh/sshd_configsed -ri 's/session required pam_loginuid.so/#session required pam_loginuid.so/g' /etc/pam.d/sshdchkconfig sshd oncd ~;ssh-keygen -t rsa -P '' -f ~/.ssh/id_dsa;cd .ssh;cat id_dsa.pub &gt;&gt; authorized_keys","categories":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"}]},{"title":"CoudearManager搭建","slug":"CoudearManager搭建","date":"2018-07-10T14:10:04.881Z","updated":"2018-08-10T19:05:49.436Z","comments":true,"path":"2018/07/10/CoudearManager搭建/","link":"","permalink":"http://gangtieguo.cn/2018/07/10/CoudearManager搭建/","excerpt":"[TOC] 创建基础容器1docker run -itd --net=br --name cm --hostname cm yaosong5/centosbase:1.0 &amp;&gt; /dev/null 将下载的包进行解压然后进行拷贝12345docker cp /Users/yaosong/Yao/cloudera-manager-el6-cm5.9.0_x86_64/cloudera cm:/opt/docker cp /Users/yaosong/Yao/cloudera-manager-el6-cm5.9.0_x86_64/cm-5.9.0 cm:/opt/docker cp /Users/yaosong/Yao/mysql-connector-java-5.1.40-bin.jar cm:/opt/cm-5.9.0/share/cmf/lib/docker cp /Users/yaosong/Yao/mysql-connector-java.jar cm:/usr/share/java/docker cp /Users/yaosong/Yao/jdk1.8 cm:/usr/local/","text":"[TOC] 创建基础容器1docker run -itd --net=br --name cm --hostname cm yaosong5/centosbase:1.0 &amp;&gt; /dev/null 将下载的包进行解压然后进行拷贝12345docker cp /Users/yaosong/Yao/cloudera-manager-el6-cm5.9.0_x86_64/cloudera cm:/opt/docker cp /Users/yaosong/Yao/cloudera-manager-el6-cm5.9.0_x86_64/cm-5.9.0 cm:/opt/docker cp /Users/yaosong/Yao/mysql-connector-java-5.1.40-bin.jar cm:/opt/cm-5.9.0/share/cmf/lib/docker cp /Users/yaosong/Yao/mysql-connector-java.jar cm:/usr/share/java/docker cp /Users/yaosong/Yao/jdk1.8 cm:/usr/local/ 将 parcel 文件放至 /opt/cloudera/parcel-repo123docker cp /Users/yaosong/Yao/CDH-5.9.0-1.cdh5.9.0.p0.23-el6.parcel cm:/opt/cloudera/parcel-repodocker cp /Users/yaosong/Yao/CDH-5.9.0-1.cdh5.9.0.p0.23-el6.parcel.sha cm:/opt/cloudera/parcel-repodocker cp /Users/yaosong/Yao/manifest.json cm:/opt/cloudera/parcel-repo vim /etc/profile 123export JAVA_HOME=/usr/local/jdk1.8export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 初始化 mysql 库1/opt/cm-5.9.0/share/cmf/schema/scm_prepare_database.sh mysql cm -hlocalhost -uroot -proot --scm-host localhost scm scm scm 创建用户（所有节点执行）1useradd --system --home=/opt/cm-5.9.0/run/cloudera-scm-server/ --no-create-home --shell=/bin/false --comment &quot;Cloudera SCM User&quot; cloudera-scm Agent 配置vim /opt/cm-5.9.0/etc/cloudera-scm-agent/config.ini 将 server_host 改为主节点主机名 1server_host=cm1 安装mysqlchkconfig mysqld on 设置允许远程登录 12mysql -u root -p GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'root' WITH GRANT OPTION; 创建CM用的数据库安装集群时按需创建，详见第七章第13步 12345678910--hive数据库create database hive DEFAULT CHARSET utf8 COLLATE utf8_general_ci;--oozie数据库create database oozie DEFAULT CHARSET utf8 COLLATE utf8_general_ci;--hue数据库create database hue DEFAULT CHARSET utf8 COLLATE utf8_general_ci;create database amon DEFAULT CHARSET utf8 COLLATE utf8_general_ci;create database monitor DEFAULT CHARSET utf8 COLLATE utf8_general_ci; Cloudera推荐设置在试安装的过程，发现Cloudera给出了一些警告 身为一个有洁癖的码农，自然是连黄色的感叹号都要消灭的。因此在安装CM/CDH之前就先全部设置好。 1、设置swap空间vim /etc/sysctl.conf末尾加上vm.swappiness=10 2、关闭大页面压缩试过只设置defrag，但貌似个别节点还是会有警告，干脆全部设置 vim /etc/rc.local末尾加上(永久生效)echo never &gt; /sys/kernel/mm/transparent_hugepage/enabledecho never &gt; /sys/kernel/mm/transparent_hugepage/defrag 启动cloudera manager 服务/opt/cm-5.9.0/etc/init.d/cloudera-scm-server start /opt/cm-5.9.0/etc/init.d/cloudera-scm-agent start 端口 7180 保存为镜像docker commit -m &quot;cloudera manger image&quot; cm yaosong5/cm59:1.0 创建容器docker run -itd --net=br --name cm1 --hostname cm1 yaosong5/cm59:1.0 &amp;&gt; /dev/null docker run -itd --net=br --name cm2 --hostname cm2 yaosong5/cm59:1.0 &amp;&gt; /dev/null docker run -itd --net=br --name cm3 --hostname cm3 yaosong5/cm59:1.0 &amp;&gt; /dev/null 1234567docker stop cm1docker stop cm2docker stop cm3docker rm cm1docker rm cm2docker rm cm3 调错 .SearchRepositoryManager: No read permission to the server storage directory [/var/lib/cloudera-scm-server]2018-07-11 10:20:39,788 ERROR SearchRepositoryManager-0:com.cloudera.server.web.cmf.search.components.SearchRepositoryManager: No write permission to the server storage directory [/var/lib/cloudera-scm-server] 链接hue连接不上节点的 cm-5.x.0/log/cloudera-scm-server/cloudera-scm-server.log，一般情况下应该会说到 ImportError:libxslt.so.1:cannot open shared object file:No such file ordirectory 1yum -y install libxml2-python 提示hue测试连接连接不上，安装依赖：1yum install libxml2-python mod_ssl install krb5-devel cyrus-sasl-gssapi cyrus-sasl-deve libxml2-devel libxslt-devel mysql mysql-devel openldap-devel python-devel python-simplejson sqlite-devel -y","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://gangtieguo.cn/categories/安装部署/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"},{"name":"CDH","slug":"CDH","permalink":"http://gangtieguo.cn/tags/CDH/"}]},{"title":"Ambari镜像搭建","slug":"Ambari搭建","date":"2018-07-09T17:08:44.939Z","updated":"2018-08-10T18:48:37.181Z","comments":true,"path":"2018/07/10/Ambari搭建/","link":"","permalink":"http://gangtieguo.cn/2018/07/10/Ambari搭建/","excerpt":"[TOC] 创建基础容器1docker run -itd --net=br --name ambari-agent --hostname ambari-agent yaosong5/centosbase:1.0 &amp;&gt; /dev/null 关闭 selinux , 需要重启vim /etc/selinux/config 1SELINUX=disabled","text":"[TOC] 创建基础容器1docker run -itd --net=br --name ambari-agent --hostname ambari-agent yaosong5/centosbase:1.0 &amp;&gt; /dev/null 关闭 selinux , 需要重启vim /etc/selinux/config 1SELINUX=disabled server端更换yum源12wget http://public-repo-1.hortonworks.com/ambari/centos6/2.x/updates/2.0.1/ambari.repocp ambari.repo /etc/yum.repos.d 安装依赖及其server123yum install epel-release yum repolistyum install ambari-server 启动初始化ambari-server setup会有一连串的提示 会提示安装 jdk，网速好的可以确定，否则可以下载 jdk-6u31-linux-x64.bin，放到 /var/lib/ambari-server/resources/ 下面，可以指定已经安装的jdk接着会提示配置用的数据库，可以选择 Oracle 或 postgresql，选择 n 会按默认配置数据库类型：postgresql数据库：ambari用户名：ambari密码：bigdata如果提示 Oracle JDK license，yes等待安装完成 agent端安装 ambari-agent 12yum install -y ambari-agentchkconfig --add ambari-agent 将 ambari.server 上的 3 个. repo 文件复制到 hadoop 集群的三台服务器上；并完成 yum 源更新的命令。 安装 ambari-agent：在集群的 3 台电脑上执行添加，并添加成开机自启动服务： yum install -y ambari-agent chkconfig –add ambari-agent sudo ambari-agent start 分别启动server agent在server和agent上分别执行 12ambari-agent startambari-server start 访问http://192.168.1.133:8080 用户名密码: admin,admin 保存容器为镜像1docker commit -m \"bigdata:ambari-server\" --author=\"yaosong\" ambr yaosong5/ambari-server:1.0 根据镜像创建容器123docker run -itd --net=br --name ambari1 --hostname ambari1 yaosong5/ambari-server:1.0 &amp;&gt; /dev/nulldocker run -itd --net=br --name ambari2 --hostname ambari2 yaosong5/ambari-server:1.0 &amp;&gt; /dev/nulldocker run -itd --net=br --name ambari3 --hostname ambari3 yaosong5/ambari-server:1.0 &amp;&gt; /dev/null 停止and删除容器1234567docker stop ambari1docker stop ambari2docker stop ambari3docker rm ambari1docker rm ambari2docker rm ambari3","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://gangtieguo.cn/categories/安装部署/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"},{"name":"Ambari","slug":"Ambari","permalink":"http://gangtieguo.cn/tags/Ambari/"}]},{"title":"Hue搭建","slug":"hue搭建","date":"2018-07-09T16:37:50.903Z","updated":"2018-08-10T17:44:19.068Z","comments":true,"path":"2018/07/10/hue搭建/","link":"","permalink":"http://gangtieguo.cn/2018/07/10/hue搭建/","excerpt":"[TOC] 本次采用的ant maven来编译hue启动一个基础容器docker run -itd --net=br --name hue --hostname hue yaosong5/centosbase:1.0 &amp;&gt; /dev/null","text":"[TOC] 本次采用的ant maven来编译hue启动一个基础容器docker run -itd --net=br --name hue --hostname hue yaosong5/centosbase:1.0 &amp;&gt; /dev/null 拷贝源包将ant、hue4.0.0、ant、maven等下载到本地结业后，再拷贝到容器（这样更快速） docker cp /Users/yaosong/Yao/ant 4115ea59088e:/ docker cp /Users/yaosong/Yao/maven 4115ea59088e:/ docker cp /Users/yaosong/Yao/hue4 4115ea59088e:/usr/ 配置HOME12345678910vim ~/.bashrc加入MAVEN_HOME=/mavenexport MAVEN_HOMEexport PATH=$&#123;PATH&#125;:$&#123;MAVEN_HOME&#125;/binANT_HOME=/antPATH=$JAVA_HOME/bin:$ANT_HOME/bin:$PATHHUE_HOME=/hue4使其生效source ~/.bashrc 安装依赖，编译hue需要安装一些依赖yum install gmp-devel -y 参考 http://www.aizhuanji.com/a/0Vo0qEMW.html 若解决不了1yum install asciidoc cyrus-sasl-devel cyrus-sasl-gssapi cyrus-sasl-plain gcc gcc-c++ krb5-devel libffi-devel libtidy libxml2-devel libxslt-devel make mysql-devel openldap-devel sqlite-devel openssl-devel gmp-devel -y 参考链接：https://www.jianshu.com/p/417788238e3d \b编译安装hue首先编译 Hue，并在要安装 Hue 的节点上创建 Hue 用户和 hue 组 创建 Hue 用户1234groupadd hueuseradd hue -g huecd $HUE_HOMEchown -R hue:hue * 注：需要注意的是 hue 在编译时有两种方式:1.通过maven、ant编译 2.通过python编译（在centos6.5因为自身python为2.6.6版本和hue编译需要2.7版本会有一点小冲突，故采用1）两种方式都是在hue目录下 make apps，只是第一种方式要先配置maven、ant的环境而已 12cd $HUE_HOMEmake apps 参考 ：https://blog.csdn.net/u012802702/article/details/68071244 如果报错 1/usr/hue4/Makefile.vars:42: *** &quot;Error: must have python development packages for 2.6 or 2.7. Could not find Python.h. Please install python2.6-devel or python2.7-devel&quot;. Stop. 需执行 1234可以先查看一下含 python-devel 的包yum search python | grep python-devel64 位安装 python-devel.x86_64，32 位安装 python-devel.i686，我这里安装:sudo yum install python-devel.x86_64 -y 更改hue的配置文件vim $HUE_HOME/desktop/conf/hue.ini mysql1234567[[database]] host=master port=3306 engine=mysql user=root password=root name=hue hive123hive_server_host=masterhive_server_port=10000hive_conf_dir=$HIVE_HOME/conf hadoop-hdfs12345fs_defaultfs=hdfs://master:9000logical_name=masterwebhdfs_url=http://master:50070/webhdfs/v1hadoop_hdfs_home=$HADOOP_HOMEhadoop_conf_dir=$HADOOP_HOME/etc/hadoop hadoop-yarn在 [hadoop].[[yarn_clusters]].[[[default]]] 下 1234resourcemanager_host=masterresourcemanager_port=8032resourcemanager_api_url=http://master:8088proxy_api_url=http://master:8088 hbase在 [hbase] 节点下 123hbase_clusters=(HBASE|master:9090)hbase_conf_dir=$HBASE_HOME/confuse_doas=true 大数据各组件满足hue进行相应配置安装mysql由于需要hue需要存放一些元数据故安装mysql 12345678910111213yum install -y mysql-serverservice mysqld startmysql -u root -pEnter password: //默认密码为空，输入后回车即可set password for root@localhost=password('root'); 密码设置为root默认情况下Mysql只允许本地登录，所以只需配置root@localhost就好set password for root@%=password('root'); 密码设置为root （其实这一步可以不配）set password for root@master=password('root'); 密码设置为root （其实这一步可以不配）select user,host,password from mysql.user; 查看密码是否设置成功GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'root' WITH GRANT OPTION;create database hue; 报错DatabaseError DatabaseError:(1146,”Table ‘hue.desktop_settings’ doesn’t exist”)-初始化mysql 完成以上的这个配置，启动 Hue, 通过浏览器访问，会发生错误，原因是 mysql 数据库没有被初始化DatabaseError: (1146,”Table ‘hue.desktop_settings’ doesn’t exist”)执行以下指令对 hue 数据库进行初始化 123cd $HUE_HOME/build/env/bin/hue syncdbbin/hue migrate 此外需要注意的是如果使用的是：$HUE_HOME/build/env/bin/hue syncdb --noinput 则不会让输入初始的用户名和密码，只有在首次登录时才会让输入，作为超级管理员账户。\b hdfshdfs-site.xml增加一个值开启 hdfs 的 web 交互123456 &lt;!--HUE 增加一个值开启 hdfs 的 web 交互--&gt;&lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; &lt;!--HUE 增加一个值开启 hdfs 的 web 交互--&gt; core-site.xml12345678910&lt;!--《为了让 hue 能够访问 hdfs，需要在 hdfs-site.xml 里面配置一些内容--&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;!--《为了让 hue 能够访问 hdfs，需要在 hdfs-site.xml 里面配置一些内容--&gt; hbasehbase-site.xml 12345678910&lt;!-- hue支持 --&gt;&lt;property&gt; &lt;name&gt;hbase.thrift.support.proxyuser&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.regionserver.thrift.http&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;!-- hue支持 --&gt; hue 访问 hbase 是用的 thriftserver，并且是 thrift1，不是 thrift2，所以要在 master 上面启动 thrif1 1$HBASE_HOME/bin/hbase-daemon.sh start thrift 参考 https://blog.csdn.net/Dante_003/article/details/78889084 读取hbase问题为解决访问Failed to authenticate to HBase Thrift Server, check authentication configurations.需要在hue的配置文件中配置 1use_doas=true 参考http://gethue.com/hbase-browsing-with-doas-impersonation-and-kerberos/ 若以上配置未能解决问题，还需要将core-site.xml拷贝到hbase/conf，并添加以下内容 12345678&lt;property&gt; &lt;name&gt;hadoop.proxyuser.hbase.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.hbase.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt; [参考]https://blog.csdn.net/u012802702/article/details/68071244 hiveHue 与框架 Hive 的集成开启 Hive Remote MetaStorenohup $HIVE_HOME/bin/hive --service metastore &amp; hive 只需启动 hiveserver2，thriftserver 的 10000 端口启动即可123nohup $HIVE_HOME/bin/hiveserver2 &amp;或者nohup HIVE_HOME/bin/hive --service hiveserver2 &amp; 解决 hue ui 界面查询中文乱码问题在 [[[mysql]]]节点下 1options=&#123;\"init_command\":\"SET NAMES'utf8'\"&#125; [参考]https://blog.csdn.net/u012802702/article/details/68071244 依赖的组件启动Mysqlservice mysqld start hadoopstart-all.sh hive然后需要同时启动 hive 的 metastore 和 hiveserve2 12nohup hive --service metastore &amp;nohup hive --service hiveserver2 &amp; hbaseHue 需要读取 HBase 的数据是使用 thrift 的方式，默认 HBase 的 thrift 服务没有开启，所有需要手动额外开启 thrift 服务。 启动 thrift service$HBASE_HOME/bin/hbase-daemon.sh start thrift thrift service 默认使用的是 9090 端口，使用如下命令查看端口是否被占用 netstat -nl|grep 9090 依赖启动的脚本1234567891011#!/bin/bash#启动mysqlservice mysqld start#启动hadoopsh /hadoop-start.sh#启动hivesh /hive-start-servers2.sh#启动 thrift service$HBASE_HOME/bin/hbase-daemon.sh start thrift#启动huenohup $HUE_HOME/build/env/bin/supervisor &amp; hue启动命令1$HUE_HOME/build/env/bin/supervisor &amp; (注：想要后台执行就是 $HUE_HOME/build/env/bin/supervisor &amp; ) 或者 1$HUE_HOME/build/env/bin/hue runserver_plus 0.0.0.0:8888 【参考】https://blog.csdn.net/hexinghua0126/article/details/80338779 hue的\bweb服务端口：8888 hue停止命令pkill -U hue 报错1、如果修改配置文件后，启动后无法进人 hue 界面 12345可能是配置文件被锁住了cd $HUE_HOME/desktop/confls –arm –rf hue.ini.swp或者 hadoop、hive 等服务没有启动起来 2、在 hue\b界面异常，导致 hive 无法使用安装插件：yum install cyrus-sasl-plain cyrus-sasl-devel cyrus-sasl-gssapi 操作镜像保存为镜像docker commit -m &quot;hue&quot; hue yaosong5/hue4:1.0 创建容器docker run -itd --net=br --name gethue --hostname gethue gethue/hue:latest &amp;&gt; /dev/null\b映射宿主机的\b\bhosts文件及其hue的配置文件方式启动容器12docker run --name=hue -d --net=br -v /etc/hosts/:/etc/hosts -v $PWD/pseudo-distributed.ini:/hue/desktop/conf/pseudo-distributed.ini yaosong5/hue4:1.0 –net=br为\b了宿主机和容器之前ip自由访问所搭建的网络模式，如有需求\b请参考 其他参考 1docker run --name=hue -d --net=br -v /etc/hosts/:/etc/hosts -v $PWD/pseudo-distributed.ini:/hue/desktop/conf/pseudo-distributed.ini gethue/hue:latest 参考：https://blog.csdn.net/Dante_003/article/details/78889084","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://gangtieguo.cn/categories/安装部署/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"},{"name":"Hue","slug":"Hue","permalink":"http://gangtieguo.cn/tags/Hue/"}]},{"title":"ES测试命令","slug":"es测试命令","date":"2018-07-09T16:11:03.158Z","updated":"2018-08-10T18:02:13.602Z","comments":true,"path":"2018/07/10/es测试命令/","link":"","permalink":"http://gangtieguo.cn/2018/07/10/es测试命令/","excerpt":"[TOC] 简单命令测试和展示es的功能","text":"[TOC] 简单命令测试和展示es的功能 插入记录 1234567891011curl -H &quot;Content-Type: application/json&quot; -XPUT &apos;http://localhost:9200/store/books/1&apos; -d &apos;&#123;&quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,&quot;name&quot; : &#123; &quot;first&quot; : &quot;Zachary&quot;, &quot;last&quot; : &quot;Tong&quot;&#125;,&quot;publish_date&quot;:&quot;2015-02-06&quot;,&quot;price&quot;:&quot;49.99&quot;&#125;&apos; 在添加一个书的信息123456789curl -H &quot;Content-Type: application/json&quot; -XPUT &apos;http://elk1:9200/store/books/2&apos; -d &apos;&#123;&quot;title&quot;: &quot;Elasticsearch Blueprints&quot;,&quot;name&quot; : &#123; &quot;first&quot; : &quot;Vineeth&quot;, &quot;last&quot; : &quot;Mohan&quot;&#125;,&quot;publish_date&quot;:&quot;2015-06-06&quot;,&quot;price&quot;:&quot;35.99&quot;&#125;&apos; 通过ID获得文档信息 1curl -H &quot;Content-Type: application/json&quot; -XGET &apos;http://elk1:9200/store/books/1&apos; 12345678910111213141516curl -H &quot;Content-Type: application/json&quot; -XGET &apos;http://elk1:9200/store/books/_search&apos; -d &apos;&#123;&quot;query&quot; : &#123;&quot;filtered&quot; : &#123; &quot;query&quot; : &#123; &quot;match_all&quot; : &#123;&#125; &#125;, &quot;filter&quot; : &#123; &quot;term&quot; : &#123; &quot;price&quot; : 35.99 &#125; &#125; &#125;&#125;&#125;&apos; 在浏览 1234567891011curl -H &quot;Content-Type: application/json&quot; -XPUT &apos;http://elk1:9200/store/books/1&apos; -d &apos;&#123;&quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;,&quot;name&quot; : &#123; &quot;first&quot; : &quot;Zachary&quot;, &quot;last&quot; : &quot;Tong&quot;&#125;,&quot;publish_date&quot;:&quot;2015-02-06&quot;,&quot;price&quot;:&quot;49.99&quot;&#125;&apos; 1curl -H &quot;Content-Type: application/json&quot; -XPUT &apos;http://127.0.0.1:9200/kc22k2_test’ -d ‘ 1curl -XPUT elk1:9200/test 12345678910111213141516curl -XGET &apos;http://elk1:9200/_cluster/state?pretty&apos;&#123; &quot;error&quot; : &#123;&quot;root_cause&quot; : [ &#123; &quot;type&quot; : &quot;master_not_discovered_exception&quot;, &quot;reason&quot; : null &#125;],&quot;type&quot; : &quot;master_not_discovered_exception&quot;,&quot;reason&quot; : null &#125;, &quot;status&quot; : 503&#125;","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://gangtieguo.cn/categories/安装部署/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"},{"name":"ELK","slug":"ELK","permalink":"http://gangtieguo.cn/tags/ELK/"},{"name":"es","slug":"es","permalink":"http://gangtieguo.cn/tags/es/"}]},{"title":"Hadoop&Spark组合容器的搭建","slug":"hadoop-spark集群搭建","date":"2018-07-08T17:06:20.114Z","updated":"2018-08-10T16:07:47.069Z","comments":true,"path":"2018/07/09/hadoop-spark集群搭建/","link":"","permalink":"http://gangtieguo.cn/2018/07/09/hadoop-spark集群搭建/","excerpt":"[TOC] 配置centos集群 hadoop spark组件启动容器各组件版本对应hbase1.2 hive 版本 2.0.0 hbase1.x ZooKeeper 3.4.x is required as of HBase 1.0.0 新建容器，为减少工作量，引用的是有ssh服务的Docker镜像kinogmt/centos-ssh:6.7，生成容器os为基准。 1docker run -itd --name bigdata --hostname bigdata kinogmt/centos-ssh:6.7 &amp;&gt; /dev/null 注意必须要以-d方式启动，不然sshd服务不会启动，这算是一个小bug","text":"[TOC] 配置centos集群 hadoop spark组件启动容器各组件版本对应hbase1.2 hive 版本 2.0.0 hbase1.x ZooKeeper 3.4.x is required as of HBase 1.0.0 新建容器，为减少工作量，引用的是有ssh服务的Docker镜像kinogmt/centos-ssh:6.7，生成容器os为基准。 1docker run -itd --name bigdata --hostname bigdata kinogmt/centos-ssh:6.7 &amp;&gt; /dev/null 注意必须要以-d方式启动，不然sshd服务不会启动，这算是一个小bug 在容器中下载需要的elk的源包，做解压就不赘述，很多案例教程。 我是采用的下载到宿主机，解压后，用 “docker cp 解压包目录 os:/usr/loca/“来传到容器内，比在容器内下载速度更快 拷贝文件到容器 命令格式docker cp 本地文件路径 容器id或者容器名称: 将所有组件下载解压并拷贝到容器 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849docker cp /Users/yaosong/Downloads/hadoop-2.8.0.tar.gz bigdata:/docker cp /Users/yaosong/Downloads/spark-2.2.0-bin-without-hadoop.tgz bigdata:/docker cp /Users/yaosong/Downloads/jdk-8u144-linux-x64.rpm bigdata:/docker cp /Users/yaosong/Downloads/spark-2.1.0-bin-hadoop2.6.tgz bigdata:/docker cp /Users/yaosong/Yao/spark源包/hive bigdata:/usrdocker cp /Users/yaosong/Downloads/jdk-8u144-linux-x64.rpm bigdata:/docker cp /Users/yaosong/Downloads/hadoop-2.8.0.tar.gz bigdata:/docker cp /Users/yaosong/Downloads/spark-2.2.0-bin-without-hadoop.tgz bigdata:/docker cp /Users/yaosong/Downloads/spark-2.1.0-bin-hadoop2.6.tgz bigdata:/docker cp /Users/yaosong/Yao/spark源包/hbase bigdata:/usrdocker cp /Users/yaosong/Yao/spark源包/zk bigdata:/usrdocker cp /Users/yaosong/Yao/ant bigdata:/usrdocker cp /Users/yaosong/Yao/maven bigdata:/usrdocker cp /Users/yaosong/Yao/hue4 bigdata:/usr创建homevim /etc/profilemac: vim ~/.bashrc添加以下内容 export JAVA_HOME=/usr/java/jdk export PATH=$JAVA_HOME:$PATH export SCALA_HOME=/usr/scala-2.12.3/ export HADOOP_HOME=/usr/hadoop export HADOOP_CONFIG_HOME=$HADOOP_HOME/etc/hadoop export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop export PATH=$PATH:$HADOOP_HOME/bin export PATH=$PATH:$HADOOP_HOME/sbin export SPARK_DIST_CLASSPATH=$(hadoop classpath) SPARK_MASTER_IP=master SPARK_LOCAL_DIRS=/usr/spark SPARK_DRIVER_MEMORY=1G export SPARK_HOME=/usr/spark export PATH=$SPARK_HOME/bin:$PATH export PATH=$SPARK_HOME/sbin:$PATH MAVEN_HOME=/usr/maven export MAVEN_HOME export PATH=$&#123;PATH&#125;:$&#123;MAVEN_HOME&#125;/bin ANT_HOME=/usr/ant PATH=$JAVA_HOME/bin:$ANT_HOME/bin:$PATH export ANT_HOME PATH HUE_HOME=/usr/hue4 export ZK_HOME=/usr/zk export HBASE_HOME=/usr/hbase export PATH=$HBASE_HOME/bin:$PATH export PATH=$ZK_HOME/bin:$PATH 安装创建 hadoop 集群所需目录：在以下配置文件中会有以下目录 12345cd $HADOOP_HOME;mkdir tmpmkdir namenodemkdir datanodecd $HADOOP_CONFIG_HOME/ 更改配置文件cd $HADOOP_CONFIG_HOME/ or cd $HADOOP_HOME/etc/hadoop hdfs slaves12slave01slave02 core-site.xml：12345678910111213141516171819202122232425262728293031323334&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/hadoop/tmp&lt;/value&gt; &lt;description&gt;A base for other temporary directories.&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;final&gt;true&lt;/final&gt; &lt;description&gt;The name of the default file system. A URI whose scheme and authority determine the FileSystem implementation. &lt;/description&gt; &lt;/property&gt; &lt;!--hive的配置，参考https://blog.csdn.net/lblblblblzdx/article/details/79760959--&gt; &lt;property&gt; &lt;name&gt;hive.server2.authentication&lt;/name&gt; &lt;value&gt;NONE&lt;/value&gt; &lt;/property&gt; &lt;!--hive的配置hadoop代理用户 root用户提交的任务可以在任意机器上以任意组的所有用户的身份执行。--&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;!--HUE 增加一个值开启 hdfs 的 web 交互--&gt; &lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!--HUE 增加一个值开启 hdfs 的 web 交互--&gt; hdfs-site.xml：12345678910111213141516171819202122232425262728293031&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;final&gt;true&lt;/final&gt; &lt;description&gt;Default block replication. The actual number of replications can be specified when the file is created. The default is used if replication is not specified in create time. &lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/usr/hadoop/namenode&lt;/value&gt; &lt;final&gt;true&lt;/final&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/usr/hadoop/datanode&lt;/value&gt; &lt;final&gt;true&lt;/final&gt;&lt;/property&gt;&lt;!--《为了让 hue 能够访问 hdfs，需要在 hdfs-site.xml 里面配置一些内容--&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;!--《为了让 hue 能够访问 hdfs，需要在 hdfs-site.xml 里面配置一些内容--&gt; mapred-site.xml：12345678&lt;property&gt; &lt;name&gt;mapred.job.tracker&lt;/name&gt; &lt;value&gt;master:9001&lt;/value&gt; &lt;description&gt;The host and port that the MapReduce job tracker runs at. If \"local\", then jobs are run in-process as a single map and reduce task. &lt;/description&gt;&lt;/property&gt; yarn-site.xml：12345678910111213141516171819202122232425&lt;property&gt; &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;description&gt;Whether virtual memory limits will be enforced for containers&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt; &lt;value&gt;256&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;master:8032&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;master:8030&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;master:8031&lt;/value&gt;&lt;/property&gt; 如果是hadoop3以上版本，需要在start-dfs.sh start-yarn.sh中开头空白处分别配置一下内容 12345678910111213vim $HADOOP_HOME/sbin/start-dfs.shHDFS_DATANODE_USER=rootHADOOP_SECURE_DN_USER=hdfsHDFS_NAMENODE_USER=rootHDFS_SECONDARYNAMENODE_USER=rootvim $HADOOP_HOME/sbin/start-yarn.shYARN_RESOURCEMANAGER_USER=rootHADOOP_SECURE_DN_USER=rootYARN_NODEMANAGER_USER=yarnYARN_PROXYSERVER_USER=root 格式化namenode1$HADOOP_HOME/bin/hadoop namenode -format 启动集群$HADOOP_HOME/sbin/start-all.sh 测试 1yarn 8088端口 http://yourip:8088 1hdfs 50070端口 hdfs3.0为9870 http://yourip:50070 spark只需要在slaves中添加12slave01slave02 sparkUI端口8080 测试spark集群启动spark 1$HADOOP_HOME/bin/start-all.sh 官网命令12345678$SPARK_HOME/bin/spark-submit --class org.apache.spark.examples.SparkPi \\--master yarn \\--deploy-mode cluster \\--driver-memory 512m \\--executor-memory 512m \\--executor-cores 1 \\$SPARK_HOME/examples/jars/spark-examples*.jar \\10 执行spark on yarn命令行模式123456789spark-shell --master yarn --deploy-mode client --driver-memory 1g --executor-memory 1g --executor-cores 1spark-shell --master yarn --deploy-mode client --driver-memory 512m --executor-memory 512m --executor-cores 1spark-shell --master yarn --deploy-mode client --driver-memory 475m --executor-memory 475m --executor-cores 1spark-shell --master yarn --deploy-mode client --driver-memory 350m --executor-memory 350m --executor-cores 1spark-shell --master yarn --deploy-mode client --driver-memory 650m --executor-memory 650m --executor-cores 1 创建镜像1docker commit -m \"bigdata基础组件镜像\" bigdata yaosong5/bigdata:2.0 创建容器123docker run -itd --net=br --name master --hostname master yaosong5/bigdata:2.0 &amp;&gt; /dev/nulldocker run -itd --net=br --name slave01 --hostname slave01 yaosong5/bigdata:2.0 &amp;&gt; /dev/nulldocker run -itd --net=br --name slave02 --hostname slave02 yaosong5/bigdata:2.0 &amp;&gt; /dev/null 停止and 删除容器123456docker stop masterdocker stop slave01docker stop slave02docker rm masterdocker rm slave01docker rm slave02","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://gangtieguo.cn/categories/安装部署/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"},{"name":"Hadoop","slug":"Hadoop","permalink":"http://gangtieguo.cn/tags/Hadoop/"},{"name":"Spark","slug":"Spark","permalink":"http://gangtieguo.cn/tags/Spark/"}]},{"title":"HBase容器的搭建","slug":"hbasezk容器的搭建","date":"2018-07-08T16:01:32.819Z","updated":"2018-08-10T18:37:09.149Z","comments":true,"path":"2018/07/09/hbasezk容器的搭建/","link":"","permalink":"http://gangtieguo.cn/2018/07/09/hbasezk容器的搭建/","excerpt":"[TOC] 创建hbasezk镜像拷贝源码12345docker cp /Users/yaosong/Yao/hbase 8019587d559b:/usr/docker cp /Users/yaosong/Yao/zk 8019587d559b:/usr/docker cp /Users/yaosong/Yao/hbasezkStart.sh 8019587d559b:/usr/docker cp /Users/yaosong/Yao/hbase-start.sh 8019587d559b:/usr/docker cp /Users/yaosong/Yao/zk-start.sh 8019587d559b:/usr/ 参考https://www.cnblogs.com/netbloomy/p/6677883.html","text":"[TOC] 创建hbasezk镜像拷贝源码12345docker cp /Users/yaosong/Yao/hbase 8019587d559b:/usr/docker cp /Users/yaosong/Yao/zk 8019587d559b:/usr/docker cp /Users/yaosong/Yao/hbasezkStart.sh 8019587d559b:/usr/docker cp /Users/yaosong/Yao/hbase-start.sh 8019587d559b:/usr/docker cp /Users/yaosong/Yao/zk-start.sh 8019587d559b:/usr/ 参考https://www.cnblogs.com/netbloomy/p/6677883.html 解压tar -zxvf hbase-1.3.0-bin.tar.gz进入 hbase 的配置目录，在 hbase-env.sh 文件里面加入 java 环境变量. 即： 12vim hbase-env.shexport JAVA_HOME=JAVA_HOME=/usr/java/jdk 关闭 HBase 自带的 Zookeeper, 使用 Zookeeper 集群： 12vim hbase-env.shexport HBASE_MANAGES_ZK=false hbase-site.xml 123456789101112131415161718192021222324&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;hbasezk1,hbasezk2,hbasezk3&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/usr/hbase/tmp/zk/data&lt;/value&gt; &lt;/property&gt; &lt;!-- webui的配置 --&gt; &lt;property&gt; &lt;name&gt;hbase.master.info.port&lt;/name&gt; &lt;value&gt;60010&lt;/value&gt; &lt;/property&gt; &lt;!-- webui新增的配置 --&gt;&lt;/configuration&gt; 创建zk的datadir目录 mkdir -p /usr/hbase/tmp/zk/data 编辑配置目录下面的文件 regionservers. 命令： vim $HBASE_HOME/config/regionservers 加入如下内容： hbasezk1 hbasezk2 hbasezk3 把 Hbase 复制到其他机器scp 开启 hbase 服务。命令如下： 哪台上运行哪台就为hmaster $HBASE_HOME/bin/start-hbase.sh 在 hbasezk1,2,3 中的任意一台机器使用 $HBASE_HOME/bin/hbase shell 进入 hbase 自带的 shell 环境，然后使用命令 version 等，进行查看 hbase 信息及建立表等操作。 要配置 HBase 高可用的话，只需要启动两个 HMaster，让 Zookeeper 自己去选择一个 Master Acitve。","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://gangtieguo.cn/categories/安装部署/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"},{"name":"HBase","slug":"HBase","permalink":"http://gangtieguo.cn/tags/HBase/"}]},{"title":"FLINK容器的搭建","slug":"flink容器搭建","date":"2018-07-08T16:00:22.635Z","updated":"2018-08-07T02:52:58.322Z","comments":true,"path":"2018/07/09/flink容器搭建/","link":"","permalink":"http://gangtieguo.cn/2018/07/09/flink容器搭建/","excerpt":"[TOC] 来源容器 flk新建容器，为减少工作量，引用的是有ssh服务的Docker镜像kinogmt/centos-ssh:6.7，生成容器os为基准。 1docker run -itd --name flk --hostname flk kinogmt/centos-ssh:6.7 &amp;&gt; /dev/null 注意必须要以-d方式启动，不然sshd服务不会启动，这算是一个小bug","text":"[TOC] 来源容器 flk新建容器，为减少工作量，引用的是有ssh服务的Docker镜像kinogmt/centos-ssh:6.7，生成容器os为基准。 1docker run -itd --name flk --hostname flk kinogmt/centos-ssh:6.7 &amp;&gt; /dev/null 注意必须要以-d方式启动，不然sshd服务不会启动，这算是一个小bug 在容器中下载需要的elk的源包。做解压就不赘述，很多案例教程。 我是采用的下载到宿主机，解压后，用 “docker cp 解压包目录 os:/usr/loca/“来传到容器内，比在容器内下载速度更快 复制源包123&gt; docker cp /Users/yaosong/Yao/hadoop flk:/usr/&gt; docker cp /Users/yaosong/Yao/flink flk:/usr/&gt; 配置homeexport JAVA_HOME=/usr/java/jdk1.8.0_144/ export PATH=$JAVA_HOME/bin:$PATH export FLINK_HOME=/usr/flink export HADOOP_HOME=/usr/hadoop export HADOOP_CONFIG_HOME=$HADOOP_HOME/etc/hadoop export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop export PATH=$PATH:$HADOOP_HOME/bin export PATH=$PATH:$HADOOP_HOME/sbin export PATH=$PATH:$FLINK_HOME/bin 配置hadoop 参考： []: http://gangtieguo.cn/2018/07/20/Docker%E4%B8%ADhadoop%20spark%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/ “Docker 中 hadoop，spark 镜像搭建” flink.yml 12345678910111213141516 high-availability: zookeeper# The path where metadata for master recovery is persisted. While ZooKeeper stores# the small ground truth for checkpoint and leader election, this location stores# the larger objects, like persisted dataflow graphs.# # Must be a durable file system that is accessible from all nodes# (like HDFS, S3, Ceph, nfs, ...) # high-availability.storageDir: hdfs:///flink/ha/# The list of ZooKeeper quorum peers that coordinate the high-availability# setup. This must be a list of the form:# &quot;host1:clientPort,host2:clientPort,...&quot; (default clientPort: 2181)#high-availability.zookeeper.quorum: zk1:2181,zk2:2181,zk3:2181 Master 1master:8081 slave 12slave01slave02 zoo.cfg 123server.1=zk1:2888:3888server.2=zk2:2888:3888server.3=zk3:2888:3888 需要在yarn-site.xml中配置 12345678&lt;property&gt; &lt;name&gt;yarn.resourcemanager.am.max-attempts&lt;/name&gt; &lt;value&gt;4&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt; &lt;value&gt;8&lt;/value&gt;&lt;/property&gt; 保存镜像1docker commit -m \"bigdata:flink,hadoop\" --author=\"yaosong\" flk yao/flinkonyarn:1.0 获得flk 容器123docker run -itd --net=br --name flk1 --hostname flk1 yao/flinkonyarn:1.0 &amp;&gt; /dev/nulldocker run -itd --net=br --name flk2 --hostname flk2 yao/flinkonyarn:1.0 &amp;&gt; /dev/nulldocker run -itd --net=br --name flk3 --hostname flk3 yao/flinkonyarn:1.0 &amp;&gt; /dev/null 停止/删除flk 容器123456docker stop flk1docker stop flk2docker stop flk3docker rm flk1docker rm flk2docker rm flk3 官方：wordcountflink测试命令由于在本地搭建，机器配置有限，故设置不同参数命令来运行官方wordcount 1234567891011flink run -m yarn-cluster $FLINK_HOME/examples/batch/WordCount.jarflink run -m yarn-cluster -ynd 2 $FLINK_HOME/examples/batch/WordCount.jarflink run -m yarn-cluster -yn 4 $FLINK_HOME/examples/batch/WordCount.jarflink run -m yarn-cluster -yn 6 $FLINK_HOME/examples/batch/WordCount.jarflink run -m yarn-cluster -yn 8 $FLINK_HOME/examples/batch/WordCount.jarflink run -m yarn-cluster -yn 10 $FLINK_HOME/examples/batch/WordCount.jar","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://gangtieguo.cn/categories/安装部署/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"},{"name":"FLINK","slug":"FLINK","permalink":"http://gangtieguo.cn/tags/FLINK/"}]},{"title":"kafka的启动及命令","slug":"kafka启动脚本","date":"2018-07-08T15:58:00.558Z","updated":"2018-08-10T16:53:05.439Z","comments":true,"path":"2018/07/08/kafka启动脚本/","link":"","permalink":"http://gangtieguo.cn/2018/07/08/kafka启动脚本/","excerpt":"kafka的启动脚本kafka-startall.sh 1234567891011#!/bin/bashsed -e '1c borker.id=0' $KAFKA_HOME/config/server.properties$KAFKA_HOME/bin/kafka-server-start.sh -daemon $KAFKA_HOME/config/server.propertiesssh root@slave01 \"sed -i '1c borker.id=1 ' $KAFKA_HOME/config/server.properties\"ssh root@slave01 \"sed -i '5c host.name=slave01 ' $KAFKA_HOME/config/server.properties\"ssh root@slave01 \"sed -i '6c advertised.host.name=slave01 ' $KAFKA_HOME/config/server.properties\"ssh root@slave01 \"$KAFKA_HOME/bin/kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties\"ssh root@slave02 \"sed -i '1c borker.id=2 ' $KAFKA_HOME/config/server.properties\"ssh root@slave02 \"sed -i '5c host.name=slave02 ' $KAFKA_HOME/config/server.properties\"ssh root@slave02 \"sed -i '6c advertised.host.name=slave02 ' $KAFKA_HOME/config/server.properties\"ssh root@slave02 \"$KAFKA_HOME/bin/kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties\"","text":"kafka的启动脚本kafka-startall.sh 1234567891011#!/bin/bashsed -e '1c borker.id=0' $KAFKA_HOME/config/server.properties$KAFKA_HOME/bin/kafka-server-start.sh -daemon $KAFKA_HOME/config/server.propertiesssh root@slave01 \"sed -i '1c borker.id=1 ' $KAFKA_HOME/config/server.properties\"ssh root@slave01 \"sed -i '5c host.name=slave01 ' $KAFKA_HOME/config/server.properties\"ssh root@slave01 \"sed -i '6c advertised.host.name=slave01 ' $KAFKA_HOME/config/server.properties\"ssh root@slave01 \"$KAFKA_HOME/bin/kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties\"ssh root@slave02 \"sed -i '1c borker.id=2 ' $KAFKA_HOME/config/server.properties\"ssh root@slave02 \"sed -i '5c host.name=slave02 ' $KAFKA_HOME/config/server.properties\"ssh root@slave02 \"sed -i '6c advertised.host.name=slave02 ' $KAFKA_HOME/config/server.properties\"ssh root@slave02 \"$KAFKA_HOME/bin/kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties\" kafka的shell命令123456/usr/kafka/bin/kafka-topics.sh --create --zookeeper hbasezk1:2181 --replication-factor 2 --partitions 1 --topic shuaige/usr/kafka/bin/kafka-console-producer.sh --broker-list master:9092 --topic shuaige#在一台服务器上创建一个订阅者/usr/kafka/bin/kafka-console-consumer.sh --zookeeper hbasezk1:2181 --topic shuaige --from-beginning/kafka-topics.sh --list --zookeeper localhost:12181","categories":[{"name":"大数据","slug":"大数据","permalink":"http://gangtieguo.cn/categories/大数据/"}],"tags":[{"name":"Kakfa","slug":"Kakfa","permalink":"http://gangtieguo.cn/tags/Kakfa/"}]},{"title":"ELK容器的搭建","slug":"elk容器的搭建","date":"2018-07-08T15:43:05.950Z","updated":"2018-08-10T17:50:32.279Z","comments":true,"path":"2018/07/08/elk容器的搭建/","link":"","permalink":"http://gangtieguo.cn/2018/07/08/elk容器的搭建/","excerpt":"[TOC] 来源容器 elk新建容器，为减少工作量，引用的是有ssh服务的Docker镜像kinogmt/centos-ssh:6.7，生成容器os为基准。 1docker run -itd --name elk --hostname elk kinogmt/centos-ssh:6.7 &amp;&gt; /dev/null 注意必须要以-d方式启动，不然sshd服务不会启动，这算是一个小bug","text":"[TOC] 来源容器 elk新建容器，为减少工作量，引用的是有ssh服务的Docker镜像kinogmt/centos-ssh:6.7，生成容器os为基准。 1docker run -itd --name elk --hostname elk kinogmt/centos-ssh:6.7 &amp;&gt; /dev/null 注意必须要以-d方式启动，不然sshd服务不会启动，这算是一个小bug 在容器中下载需要的elk的源包。做解压就不赘述，很多案例教程。 我是采用的下载到宿主机，解压后，用 “docker cp 解压包目录 os:/usr/loca/“来传到容器内，比在容器内下载速度更快 设置Home vim ~/bashrc 123456789export ES_HOME=/usr/esexport PATH=$ES_HOME/bin:$PATHexport KIBANA_HOME=/usr/kibanaexport PATH=$KIBANA_HOME/bin:$PATHexport LOGSTASH_HOME=/usr/logstashexport PATH=$LOGSTASH_HOME/bin:$PATHexport NODE_HOME=/usr/nodeexport PATH=$NODE_HOME/bin:$PATHexport NODE_PATH=$NODE_HOME/lib/node_modules source ~/.bashrc 安装插件header安装nodejs一般预装的版本不对 123yum erase nodejs npm -y # 卸载旧版本的nodejsrpm -qa &apos;node|npm&apos; | grep -v nodesource # 确认nodejs是否卸载干净yum install nodejs -y # 安装npm 安装的版本会有不对 下载合适版本 1234cd /usrwget https://npm.taobao.org/mirrors/node/latest-v4.x/node-v4.4.7-llinux-x64.tar.gztar -zxvf node-v4.4.7-linux-x64.tar.gzmv node-v8.9.1-linux-x64 node 直接将node目录配置到home即可 12export NODE_HOME=/usr/nodeexport PATH=$NODE_HOME/bin:$PATH 下载 header，安装grunt（所有命令在hear的所在目录执行） wget https://github.com/mobz/elasticsearch-head/archive/master.zip unzip master.zip 看当前 head 插件目录下有无 node_modules/grunt 目录：没有：执行命令创建： 1npm install grunt --save 安装 grunt：grunt 是基于 Node.js 的项目构建工具，可以进行打包压缩、测试、执行等等的工作，head 插件就是通过 grunt 启动 1npm install -g grunt-cli 参考https://blog.csdn.net/ggwxk1990/article/details/78698648 npm install 安装所下载的header包 1npm install header启动在 elasticsearch-head-master 目录下 1grunt server 或者 npm run start els不能通过root启动，创建用户useradd elk groupadd elk usermod -a -G elk elk echo elk | passwd --stdin elk 将elk添加到sudoers echo &quot;elk ALL = (root) NOPASSWD:ALL&quot; | tee /etc/sudoers.d/elk chmod 0440 /etc/sudoers.d/elk 解决sudo: sorry, you must have a tty to run sudo问题，在/etc/sudoer注释掉 Default requiretty 一行 sudo sed -i ‘s/Defaults requiretty/Defaults:elk !requiretty/‘ /etc/sudoers 修改文件所有者chown -R elk:elk /usr/es/ 设置资源参数 1sudo vim /etc/security/limits.d/90-nproc.conf 添加 elk soft nproc 4096 12docker-machine sshsysctl -w vm.max_map_count=655360 es启动脚本单机 su elk -c &quot;$ES_HOME/bin/elasticsearch -d&quot; ssh elk@elk1 &quot; $ES_HOME/bin/elasticsearch -d&quot; ssh root@elk1 &quot; su elk -c $ES_HOME/bin/elasticsearch &quot; 集群elasticSearch脚本 vim es-start.sh 12345678#!/bin/bashsed -i '6c node.name: es1 '$ES_HOME/config/elasticsearch.ymlsu - elk -c \"$ES_HOME/bin/elasticsearch -d\"ssh root@elk2 \"sed -i '6c node.name: es2 ' $ES_HOME/config/elasticsearch.yml\"ssh root@elk2 ' su - elk -c \"$ES_HOME/bin/elasticsearch -d\" 'ssh root@elk3 \"sed -i '6c node.name: es3 ' $ES_HOME/config/elasticsearch.yml\"ssh root@elk3 ' su - elk -c \"$ES_HOME/bin/elasticsearch -d\" ' kibana启动单机（只需要启动单机） bin/kibana12345678#!/bin/bashsed -i '3c http://elk1:9200 '$KIBANA_HOME/config/kibana.ymlnohup $KIBANA_HOME/bin/kibana &amp;ssh root@elk2 \"sed -i '3c http://elk2:9200 ' $KIBANA_HOME/config/kibana.yml\"ssh root@elk2 \"nohup $KIBANA_HOME/bin/kibana &amp; \"ssh root@elk3 \"sed -i '3c http://elk3:9200 ' $KIBANA_HOME/config/kibana.yml\"ssh root@elk3 \"nohup $KIBANA_HOME/bin/kibana &amp; \" logstash单机启动 $LOGSTASH_HOME/bin/logstash -f logstash.conf $LOGSTASH_HOME/bin/logstash -f 配置文件的目录\b 集群启动脚本 logstash-start.sh1234#!/bin/bashnohup $LOGSTASH_HOME/bin/logstash -f $LOGSTASH_HOME/conf/$1 &amp;ssh root@elk2 \"nohup $LOGSTASH_HOME/bin/logstash -f $LOGSTASH_HOME/conf/$1 &amp; \"ssh root@elk3 \"nohup $LOGSTASH_HOME/bin/logstash -f $LOGSTASH_HOME/conf/$1 &amp; \" 保存容器为镜像1docker commit -m \"elk镜像\" --author=\"yaosong\" os yaosong5/elk:1.0 生成elk 容器123docker run -itd --net=br --name elk1 --hostname elk1 yaosong5/elk:1.0 &amp;&gt; /dev/nulldocker run -itd --net=br --name elk2 --hostname elk2 yaosong5/elk:1.0 &amp;&gt; /dev/nulldocker run -itd --net=br --name elk3 --hostname elk3 yaosong5/elk:1.0 &amp;&gt; /dev/null 停止/删除elk 容器1234567docker stop elk1docker stop elk2docker stop elk3docker rm elk1docker rm elk2docker rm elk3 参考elk 操作命令es操作命令http://www.yfshare.vip/2017/11/04/%E9%83%A8%E7%BD%B2FileBeat-logstash-elasticsearch%E9%9B%86%E7%BE%A4-kibana/#%E9%85%8D%E7%BD%AE-filebeart 其他yum erase nodejs npm -y # 卸载旧版本的nodejsrpm -qa ‘node|npm’ | grep -v nodesource # 确认nodejs是否卸载干净yum install nodejs -y","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://gangtieguo.cn/categories/安装部署/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"},{"name":"ELK","slug":"ELK","permalink":"http://gangtieguo.cn/tags/ELK/"}]},{"title":"Docker常用命令汇集","slug":"Docker命令汇集","date":"2018-06-26T02:33:37.714Z","updated":"2018-08-10T18:03:11.035Z","comments":true,"path":"2018/06/26/Docker命令汇集/","link":"","permalink":"http://gangtieguo.cn/2018/06/26/Docker命令汇集/","excerpt":"","text":"[TOC] Docker源配置 安装过程中需要重国外 docker 仓库下载文件，速度太慢，建议配置 docker 国内镜像仓库： vi /etc/docker/daemon.json {“registry-mirrors”:[“http://c1f0a193.m.daocloud.io&quot;] } 启动容器 docker run -itd --net=br --name slave02 --hostname slave02 centos:hadoop-spark &amp;&gt; /dev/null 如果以 /bin/bash启动的话，sshd服务不会启动(docker未知bug) 创建容器--name --hostname (同-h) --net= -d表示后台启动 此命令不会打印出容器id docker run -itd --net=br --name hm --hostname hadoop-master kiwenlau/hadoop:1.0 &amp;&gt; /dev/null （hadoop镜像） 设置静态固定ip docker run -d --net=br --name=c6 --ip=192.168.33.6 nginx 自动分配Ip docker run -d --net=br --name=c1 nginx 设置docker默认ip段命令 docker run -itd -P -p 50070:50070 -p 8088:8088 -p 8080:8080 --name master -h master --add-host slave01:172.17.0.3 --add-host slave02:172.17.0.4 centos:ssh-spark-hadoop 容器挂载目录compose文件：12volumes: - /Users/yaosong/Yao/dev/hadoop/dfs/name:/root/hadoop/dfs/name shell命令： 12-v : docker run -it -v /test:/soft centos /bin/bash “:”前目录为宿主机目录，后目录为容器目录 删除所有未用的 Data volumes1docker volume prune run 命令解释12345-d 是后台启动docker run -itd --net=br --name spark --hostname spark yaosong/spark:2.1.0 &amp;&gt; /dev/nullsudo docker exec -it spark bash（进入后台启动的容器）和下面一样（直接进入）docker run -it --net=br --name spark --hostname spark yaosong/spark:2.1.0 bash exec 进入后台容器123docker exec -it spark bashdocker exec -it 容器名 bash执行命令 docker exec -it 容器名 ip addr 可以拿到 a0 容器的 ip logs查看容器启动日志1docker logs -f -t --tail 100 kanbigdata_namenode_1 查看容器信息12docker inspect hm执行命令 docker exec -it 容器名 ip addr 可以拿到 a0 容器的 ip 启动 关闭 删除容器docker start docker stop 容器名 docker rm 容器名 cp容器宿主互拷文件12docker cp /Users/yaosong/Yao/etc.tar f7e795c0fddd:/后为容器id:/目录 删除镜像（根据镜像id删除） docker rmi 00de07ebadff 用docker images -a 查看image id， 也可docker rmi 镜像名:版本号 保存镜像123docker commit -m &quot;centos-6.9 with spark 2.2.0 and hadoop 2.8.0&quot; os centos:hadoop-sparkdocker commit -m &quot;bigdata:spark,hadoop,hive,mysql and shell foundation&quot; --author=&quot;yaosong&quot; master yao/os/bigdata:2.1 Docker用DockerFile创建镜像docker build -t hadoop:v1- &lt;Dockerfile docker build -t=&quot;hadoop:v1&quot; . （.表示是当前文件夹，也就是dockerfile所在文件夹） docker build -f Dockerfile -t hadoop:v1 . 此命令也可 一键启动docker-compose.yml编排的所有服务1docker-compose -f docker-compose.yml up d Docker改变标签docker tag IMAGEID(镜像id) REPOSITORY:TAG（仓库：标签） docker tag b7a66cb0e8ba yaosong5/bigdata:1.0 搜索docker镜像1docker search yaosong5 登录docker账户docker login 登录docker hub中注册的账户 上传仓库docker push yaosong5/elk:1.0 容器保存为镜像，加载本地镜像 引用docker save imageID &gt; filename docker load &lt;filename 如： docker save 4f9e92e56941&gt; /Users/yaosong/centosSparkHadoop.tar docker load &lt;/Users/yaosong/centosSparkHadoop.tar 通过 image 保存的镜像会保存操作历史，可以回滚到历史版本。 保存，加载容器命令：docker export containID &gt; filename docker import filename [newname] 通过容器保存的镜像不会保存操作历史，所以文件小一点。如果要运行通过容器加载的镜像， 需要在运行的时候加上相关命令。 Docker-machine命令列出docker-machine1docker-machine ls 开启虚拟机1docker-machine start default 关闭虚拟机1docker-machine stop default 重启虚拟机1docker-machine restart default 删除虚拟机1docker-machine rm default 设置环境变量docker-machine1eval $(docker-machine env default) # Setup the environment","categories":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"}]},{"title":"各种快捷键","slug":"各种快捷键","date":"2018-06-21T15:40:13.306Z","updated":"2018-08-10T18:40:41.685Z","comments":true,"path":"2018/06/21/各种快捷键/","link":"","permalink":"http://gangtieguo.cn/2018/06/21/各种快捷键/","excerpt":"一些常用快捷键让人事半功倍","text":"一些常用快捷键让人事半功倍 ​ |iterm|Command + Shift + h iterms2复制历史 分屏 command + option + 方向键 command + [ 或 command + ] 分屏切换屏幕 Control + a 到行首 Control + u 清除当前行 Control + e 到行尾 Control + p / !! 上一条命令 Control + k 从光标处删至命令行尾 (本来 Control + u 是删至命令行首，但iterm中是删掉整行) Control + w A + d 从光标处删至字首/尾 Control + k 删除到文本末尾 Control + h 删掉光标前的自负 Control + d 删掉光标后的自负 Control + r 搜索命令历史，这个较常用 |Alfred|Command + Option + C afrend剪切板历史 Command + Option + / afrend路径历史 Command + Option + \\ afrend对搜索的路径进行操作 如复制等等 ​​ ​ |sublime|Command + Shift + d 复制一行 Command + Option + f 查找并替换 CTRL + - 上个打开的文件 |idea|Command + Shift + F12 编栏全屏 其实就是 Hide All Tool Windows (隐藏所有工具窗口) 这个操作的快捷键。 Command + Option + Space 类名或接口名提示 Control + ; 是什么 代替鼠标 Command + l 跳到指定行 Command + w 关闭标签页 Option + 上 和windows的ctrl+w相同 递进选中代码块 Alt + Insert Command + N 代码自动生成，如生成对象的 set / get 方法，构造函数，toString() 等 Alt + 前方向键 Control + 前方向键 当前光标跳转到当前文件的前一个方法名位置 Ctrl + Alt + Enter Command + Option + Enter 光标所在行上空出一行，光标定位到新行 Ctrl + Alt + 左方向键 Command + Option + 左方向键 退回到上一个操作的地方 Ctrl + Alt + 右方向键 Command + Option + 右方向键 前进到上一个操作的地方 Command + Option + T 包围代码 Command + Shift +v 历史 Find usage 查看变量方法的类的直接使用情况 Shift + Enter 开始新的一行 Command + P 方法参数提示 Command + U 前往父类 Command + +/- 展开/折叠代码 Alt + 1,2,3...9 Command + 1,2,3...9 显示对应数值的选项卡，其中 1 是 Project 用得最多 Control + Option + O 优化导入的类，可以对当前文件和整个包目录使用 Ctrl + Alt + T 对选中的代码弹出环绕选项弹出层 Control + Option + H 继承关系 Control + H 接口到实现类 Control + Shift + J 智能的将代码拼接成一行 Command+Alt+V 引入变量，自动导入变量 Option + F7 查询所选对象/变量被引用 4、类、方法、文件定位 查找类 ctr + N 查找文件 Ctrl + Shift + N 符号定位 Ctrl + Alt + Shift + N 查看文件结构 ctrl + F12 最近打开的文件 ctr + E 定位下一个方法 alt + down 定位上一个方法 alt + up 查看方法参数信息 ctr + p 查看方法、类的 doc ctr + Q 行数 Command + l 5、类、方法的结构查看、定位 跳到类或方法的声明 ctr + B 定位到类的父类、接口 ctr + U 画图 ommand+Option+u 查看类的继承结构 ctr + H 查看方法的继承结构 ctr + Shift + H 查看类或方法被调用情况 ctr + alt +H 原地参看类、方法的声明 Ctrl + Shift + I ​ Control + H 显示当前类的层次结构 继承 Command + Shift + H 显示方法层次结构 Control + Option + H 显示调用层次结构 Command + L 在当前文件跳转到某一行的指定处 Command + B / Command + 鼠标点击 进入光标所在的方法/变量的接口或是定义处 Command + Option + B 跳转到实现处 Command + G 查找模式下，向下查找 Command + Shift + U 大小写切换 |Mac|​ Shift+Command+G 跳转打开文件夹 Command + Shift + . 显示隐藏文件 Command + Control + 空格 emoji表情 Shift + Option）+ K Apple logo 「 」 Command+i 简介 Shift+Control+d 搜狗表情包 Shift + Command + 空格 历史文件 Control + Command +F 全屏模式 Command + z 打开safari下最近关闭tab页面 Command + Option + Shift + Esc 强制退出活跃的 Command + Option + Esc 强制退出 Command + ` 切换同一应用的窗口 Shift + Command + d alt + cmd + space 快速打开finder cmd + Option + Shift + v 去格式粘贴（亲测大部分软件都可以） Command + Tab 切换应用的时候，可以松开Tab，然后按Q退出选中的应用。 三指点击网页链接，可以预览链接网页。 按住右上角的新建选项卡按钮能快速浏览并选择最近关闭的窗口 |finder|Command + 1，2，3 图标，列表，分栏显示文件夹 Command + Control + P 复制路径 自己配置 Command + Option + B 快捷键标记 自己配置 Command + O 打开文件夹 Command + 下 进入文件夹 Command + 上 返回文件夹 Command ＋［ 返回 Command ＋ ］ 前进 | mac命令|根据 asker 提示 作补充： command + fn + 左/右，可以调整到文件开头 / 结尾。 fn + 左/右相当于home/end在 网页和多数文档中适用。 ​ defaults write com.apple.finder QuitMenuItem -bool YES 设置finder可以关闭 open -n /Applications/WizNote.app 多次打开一个应用 mac 没有声音 sudo kill -9 `ps ax|grep &apos;coreaudio[a-z]&apos; |awk &apos;{print $1}&apos;` ​ sudo killall coreaudiod​​ 使用后的效果，可以说是非常明显了，再也不会有在「挤牙膏」的感觉。让它回到最开始的状态： defaults delete com.apple.dock; killall Dock defaults write com.apple.Dock autohide-delay -float 0 &amp;&amp; killall Dock 打开开机声音 sudo nvram -d SystemAudioVolume 双屏分任务工作！只要按住窗口左上角的绿色＋即可 去掉资源库文件夹的隐藏属性 chflags nohidden ~/Library/ 打开隐藏属性 chflags hidden ~/Library/ 调节音量的同时按住 Option + Shift键 显示“隐藏文件” Command + Shift + . defaults write com.apple.finder AppleShowAllFiles -bool true;killall Finder 隐藏 defaults write com.apple.finder AppleShowAllFiles -bool true;killall Finder 关闭开机声音 sudo nvram SystemAudioVolume=%80， 省略号 1、依次按 ⌃ ⌘ 空格 2、⇧ 数字6 Option 点击 Dock 图标，按住 Option 点击 Dock 中的图标，则会在桌面显示该应用所有窗口 Option + 左：向左移动一个单词 Option + 右：向右移动一个单词 Option + Delete：删除左边一个单词 Option + Fn + Delete：删除右边一个单词 设置 dock 显示时间命令 打开终端输入以下命令 #先修改停留时间（后面数字为停留时间）如： defaults write com.apple.dock autohide-delay -int 0 ##（时间设为最短） defaults write com.apple.dock autohide-delay -int 0.5 ##（时间设为 0.5s） defaults write com.apple.dock autohide-delay -int 10 ##（时间设为 10s） #使设置生效 killall Dock ​ |推荐|再推荐个人 池健强 《人生元编程》作者 他的博客和微信上有很多干货 ​​","categories":[{"name":"快捷键","slug":"快捷键","permalink":"http://gangtieguo.cn/categories/快捷键/"}],"tags":[{"name":"快捷键","slug":"快捷键","permalink":"http://gangtieguo.cn/tags/快捷键/"},{"name":"Mac","slug":"Mac","permalink":"http://gangtieguo.cn/tags/Mac/"},{"name":"Idea","slug":"Idea","permalink":"http://gangtieguo.cn/tags/Idea/"},{"name":"Finder","slug":"Finder","permalink":"http://gangtieguo.cn/tags/Finder/"}]},{"title":"Centos7上搭建Jenkins","slug":"Centos7上搭建Jenkins","date":"2018-06-21T14:11:28.272Z","updated":"2018-08-10T18:32:28.065Z","comments":true,"path":"2018/06/21/Centos7上搭建Jenkins/","link":"","permalink":"http://gangtieguo.cn/2018/06/21/Centos7上搭建Jenkins/","excerpt":"之前用yum模式安装，总是启动报错，解决了一番，未找到解决方案，后直接下载war包进行安装部署 默认安装了Java","text":"之前用yum模式安装，总是启动报错，解决了一番，未找到解决方案，后直接下载war包进行安装部署 默认安装了Java 1. 安装 jenkins 123456cd /optmkdir /jenkinscd jenkinsmkdir jenkins_homemkdir jenkins_nodewget http://mirrors.jenkins-ci.org/war/latest/jenkins.war 2. 编写可执行文件 vim start_jenkins.sh1234#!/bin/bashJENKINS_ROOT=/opt/jenkinsexport JENKINS_HOME=$JENKINS_ROOT/jenkins_homejava -jar $JENKINS_ROOT/jenkins.war --httpPort=8000 修改文件的权限： chmod a+x start_jenkins.sh 启动 jenkins: nohup ./start_jenkins.sh &gt; jenkins.log 2&gt;&amp; 1&amp; 3 访问 jenkins 输入 http:// 服务器地址: 8000 注意：在启动日志中会出现初始密码，这个用来首次登陆Jenkins使用 参考在 Centos7 上搭建 jenkins","categories":[{"name":"安装部署","slug":"安装部署","permalink":"http://gangtieguo.cn/categories/安装部署/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://gangtieguo.cn/tags/Jenkins/"}]},{"title":"Docker安装Hadoop集群【引用】","slug":"Docker安装Hadoop集群【引用】","date":"2018-06-03T06:36:21.404Z","updated":"2018-08-06T19:27:34.504Z","comments":true,"path":"2018/06/03/Docker安装Hadoop集群【引用】/","link":"","permalink":"http://gangtieguo.cn/2018/06/03/Docker安装Hadoop集群【引用】/","excerpt":"Docker配置Hadoop集群环境 在网上找到一个网友自制的镜像，拉取配置都是参考的，记录一下。","text":"Docker配置Hadoop集群环境 在网上找到一个网友自制的镜像，拉取配置都是参考的，记录一下。 拉取镜像 sudo docker pull kiwenlau/hadoop-master:0.1.0sudo docker pull kiwenlau/hadoop-slave:0.1.0sudo docker pull kiwenlau/hadoop-base:0.1.0sudo docker pull kiwenlau/serf-dnsmasq:0.1.0 查看下载的镜像 sudo docker images 在github中拉取源代码(或者在oschina中拉取)git clone https://github.com/kiwenlau/hadoop-cluster-docker开源中国git clone http://git.oschina.net/kiwenlau/hadoop-cluster-docker 运行容器拉取镜像后，打开源代码文件夹，并且运行脚本 cd hadoop-cluster-docker 注意：运行脚本时,需要先启动docker服务 ./start-container.sh 一共开启了 3 个容器，1 个 master, 2 个 slave。开启容器后就进入了 master 容器 root 用户的根目录（/root） 查看root目录下文件 测试容器是否正常运行serf members 参考：基于 Docker 快速搭建多节点 Hadoop 集群","categories":[{"name":"环境配置","slug":"环境配置","permalink":"http://gangtieguo.cn/categories/环境配置/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://gangtieguo.cn/tags/Docker/"},{"name":"Hadoop","slug":"Hadoop","permalink":"http://gangtieguo.cn/tags/Hadoop/"}]},{"title":"命令积累","slug":"大数据命令积累","date":"2018-05-31T06:10:40.710Z","updated":"2018-08-06T18:20:09.751Z","comments":true,"path":"2018/05/31/大数据命令积累/","link":"","permalink":"http://gangtieguo.cn/2018/05/31/大数据命令积累/","excerpt":"bin /h dfs oev -i edits -o edits.xml 查看元数据","text":"bin /h dfs oev -i edits -o edits.xml 查看元数据","categories":[{"name":"碎片知识","slug":"碎片知识","permalink":"http://gangtieguo.cn/categories/碎片知识/"}],"tags":[{"name":"命令","slug":"命令","permalink":"http://gangtieguo.cn/tags/命令/"},{"name":"大数据","slug":"大数据","permalink":"http://gangtieguo.cn/tags/大数据/"}]},{"title":"jsontool使用","slug":"json-tool使用","date":"2018-05-30T01:36:02.864Z","updated":"2018-08-10T17:46:56.174Z","comments":true,"path":"2018/05/30/json-tool使用/","link":"","permalink":"http://gangtieguo.cn/2018/05/30/json-tool使用/","excerpt":"","text":"json-tool使用：java -jar json-tool.jar &quot;json文件目录&quot; &quot;jsonPath路径&quot;示例： 1java -jar /Users/yaosong/Documents/json-tool.jar &quot;/Users/yaosong/tmp/access_report_data_by_token.json&quot; &quot;$.report_data.behavior_check[?(@.check_point_cn == &apos;朋友圈在哪里&apos;)].evidence&quot;","categories":[{"name":"tool","slug":"tool","permalink":"http://gangtieguo.cn/categories/tool/"}],"tags":[{"name":"命令","slug":"命令","permalink":"http://gangtieguo.cn/tags/命令/"}]},{"title":"git命令总结","slug":"git命令总结","date":"2018-05-21T17:43:07.025Z","updated":"2018-08-10T18:01:16.275Z","comments":true,"path":"2018/05/22/git命令总结/","link":"","permalink":"http://gangtieguo.cn/2018/05/22/git命令总结/","excerpt":"提交 git add .git commit -m “ “git push origin mastergit push origin master -f 拉取git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;如拉取远程的 master 分支到本地 wy 分支：git pull origin master:wy 分支切换","text":"提交 git add .git commit -m “ “git push origin mastergit push origin master -f 拉取git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;如拉取远程的 master 分支到本地 wy 分支：git pull origin master:wy 分支切换 查看分支：git branch创建分支：git branch 切换分支：git checkout 创建 + 切换分支：git checkout -b 合并某分支到当前分支：git merge 删除分支：git branch -d","categories":[{"name":"工程框架","slug":"工程框架","permalink":"http://gangtieguo.cn/categories/工程框架/"}],"tags":[{"name":"git","slug":"git","permalink":"http://gangtieguo.cn/tags/git/"}]},{"title":"源文件提交到仓库","slug":"博客源文件提交到仓库","date":"2018-05-21T17:43:07.025Z","updated":"2018-05-21T17:44:03.947Z","comments":true,"path":"2018/05/22/博客源文件提交到仓库/","link":"","permalink":"http://gangtieguo.cn/2018/05/22/博客源文件提交到仓库/","excerpt":"将博客源文件加入到仓库 git add .git commit -m “ “git push origin mastergit push origin master -f","text":"将博客源文件加入到仓库 git add .git commit -m “ “git push origin mastergit push origin master -f","categories":[{"name":"博客","slug":"博客","permalink":"http://gangtieguo.cn/categories/博客/"}],"tags":[{"name":"git","slug":"git","permalink":"http://gangtieguo.cn/tags/git/"},{"name":"Hexo","slug":"Hexo","permalink":"http://gangtieguo.cn/tags/Hexo/"}]},{"title":"部署博客到云服务器","slug":"转移Github博客到云服务器","date":"2018-05-20T16:56:17.069Z","updated":"2018-08-10T18:32:14.487Z","comments":true,"path":"2018/05/21/转移Github博客到云服务器/","link":"","permalink":"http://gangtieguo.cn/2018/05/21/转移Github博客到云服务器/","excerpt":"简单记录转移到博客到云服务器","text":"简单记录转移到博客到云服务器 原理及准备 我们在自己的电脑上写好博客, 使用 git 发布到代码仓库进行备份, git 仓库接收到 push 请求后, 使用 webhook 配合 nodejs 自动进行服务器端页面的更新. 准备安装Git和NodeJS (CentOS 环境) 1yum install git 安装NodeJS 1curl --silent --location https://rpm.nodesource.com/setup_5.x | bash - 服务器构建webhook方式服务器端的” 钩子”我们借助一个 node 插件 github-webhook-handler 来快速完成配合 github webhook 的操作, 其他 git 平台也有相应的插件, 如配合 coding 的 coding-webhook-handler. 监听脚本 我们借助一个 node 插件 github webhook-handler来快速完成配合 github webhook 的操作, 其他 git 平台也有相应的插件, 如配合 coding 的 coding-webhook-handler. 使用 npm install -g github-webhook-handler 命令来安装到服务器端.conding则为npm install -g coding-webhook-handler 切换到服务器站点目录，如我的是 /root/blog,新建一个public目录，将你的github仓库中的master分支pull到该目录中，这个目录作为这个博客的根目录了 123456cd /root/blogmkdir public cd public git initgit remote add origin https://github.com/yaosong5/yaosong5.github.iogit pull origin master 然后我们创建一个webhooks.js文件，将以下的内容粘贴，这相当于Node.js 服务器的代码构建 123456789101112131415161718192021222324252627282930var http = require('http')var createHandler = require('github-webhook-handler')var handler = createHandler(&#123; path: '/', secret: 'yao' &#125;)function run_cmd(cmd, args, callback) &#123; var spawn = require('child_process').spawn; var child = spawn(cmd, args); var resp = \"\"; child.stdout.on('data', function(buffer) &#123; resp += buffer.toString(); &#125;); child.stdout.on('end', function() &#123; callback (resp) &#125;);&#125;http.createServer(function (req, res) &#123; handler(req, res, function (err) &#123; res.statusCode = 404 res.end('no such location') &#125;)&#125;).listen(7777)handler.on('error', function (err) &#123; console.error('Error:', err.message)&#125;)handler.on('push', function (event) &#123; console.log('Received a push event for %s to %s', event.payload.repository.name, event.payload.ref); run_cmd('sh', ['./deploy.sh',event.payload.repository.name], function(text)&#123; console.log(text) &#125;);&#125;) 注意上段代码中第 3 行 { path: ‘/‘, secret: ‘改为你的secret’ } 中 secret 可以改为你喜欢的口令, 这口令将在下面的步骤中起到作用 ,配置github webhooks的时候填入的口令, 请留意. 第 19 行 listen(7777) 中 7777 为监听程序需要使用的端口. 执行脚本上面的 javascript 代码是用来捕捉 github 发来的信号并发起一个执行 ./deploy.sh 的脚本, 接下来我们还需要写 deploy.sh 的内容. 123456789101112#!/bin/bashWEB_PATH='/root/blog/public'echo \"Start deployment\"cd $WEB_PATHecho \"pulling source code...\"git reset --hard origin/mastergit clean -fgit pullgit checkout masterecho \"Finished.\" 将以上代码的第 3 行改为你服务器中的实际目录. 接下来只需要开启监听就可以了. tips: 在此之前你可以使用 node webhook.js 来测试一下监听程序是否能够正常运行.我在这里碰到了一个 node 环境变量的问题, 读取不到 github-webhook-handler 这个模块, 找了很多办法也没有解决, 后来我直接在项目根目录的上级目录安装了这个模块, 问题就解决了. cd /root/blognpm install github-webhook-handlernpm 会从当前目录依次向上寻找含有 node_modules 目录并访问该模块. 普通方式运行 webhook.js利用 Linux 提供的 nohup 命令，让 webhooks.js 运行在后台 1nohup node webhook.js &gt; deploy.log &amp; Forever方式运行webhook.js 我在实际使用的时候发现，我的 Node 服务器时不时会自动停掉，具体原因我暂时还没有弄清楚。不过似乎很多人都遇到了这样的困扰，要解决这个问题，forever 是个不错的选择。借助 forever 这个库，它可以保证 Node 持续运行下去，一旦服务器挂了，它都会重启服务器。 安装 forever：npm install -g forever运行：12cd &#123; 部署服务器的根目录 &#125; nohup forever start webhook.js &gt; deploy.log &amp; Ubuntu 中原本就有一个叫 node 的包。为了避免冲突，在 Ubuntu 上安装或使用 Node 得用 nodejs 这个名字。而 forever 默认是使用 node 作为执行脚本的程序名。所以为了处理 Ubuntu 存在的这种特殊情况，在启动 forever 时得另外添加一个参数：(其它则忽略) forever start webhook.js -c nodejs Github配置webhooks配置好 Webhook 后，Github 会发送一个 ping 来测试这个地址。如果成功了，那么这个 Webhook 前就会加上一个绿色的勾；如果你得到的是一个红色的叉，那就好好检查一下哪儿出问题了吧！ git-hook方式可采用一种更为简单的部署方式 这种方式和webhook可二选一 服务器上建立git裸库创建一个裸仓库，裸仓库就是只保存git信息的Repository, 首先切换到git用户确保git用户拥有仓库所有权一定要加 –bare，这样才是一个裸库。 12cd git init --bare blog.git 使用 git-hooks 同步网站根目录在这里我们使用的是 post-receive这个钩子，当git有收发的时候就会调用这个钩子。 在 ~/blog.git 裸库的 hooks文件夹中，新建post-receive文件。 vim ~/blog.git/hooks/post-receive 填入以下内容 12#!/bin/shgit --work-tree=/root/blog/public --git-dir=/root/blog.git checkout -f work-tree=/root/blog/public这个目录是网站的网页文件目录，–git-dir=/root/blog.git目录为裸库地址，裸库监听git提交会将文件提交到网页目录保存后，要赋予这个文件可执行权限chmod +x post-receive 配置博客根目录_config.yml完成自动化部署打开 _config.yml, 找到 deploy12345deploy: type: git repo: 用户名@SERVER名:/home/git/blog.git（裸库地址） //&lt;repository url&gt; branch: master //这里填写分支 [branch] message: 提交的信息 //自定义提交信息 (默认为 Site updated: &#123;&#123; now(&apos;YYYY-MM-DD HH:mm:ss&apos;) &#125;&#125;) Nginx服务npm 安装nginx启动nginx 1service nginx start nginx -t 查看nginx配置文件若nginx服务启动，访问报403错误 则将首行 user nginx 改为user root 123456789vim /etc/nginx/nginx.confserver &#123; listen 80; # 监听端口 server_name 47.98.141.252:80 gangtieguo.cn wwww.gangtieguo.cn; # 你的域名 location / &#123; root /root/blog/public; index index.html; &#125;&#125; 重载 nginx，使配置生效 nginx -s reload 参考Hexo 静态博客搭建并实现自动部署到远程 vps将 Hexo 博客发布到自己的服务器上利用 Github 的 Webhook 功能和 Node.js 完成项目的自动部署Webhook 实践 —— 自动部署Hexo 快速搭建静态博客并实现远程 VPS 自动部署阿里云 VPS 搭建自己的的 Hexo 博客","categories":[{"name":"博客","slug":"博客","permalink":"http://gangtieguo.cn/categories/博客/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://gangtieguo.cn/tags/Hexo/"}]},{"title":"MyBatis相关注解","slug":"MyBatis注解","date":"2018-05-17T12:09:55.000Z","updated":"2018-08-10T17:52:53.516Z","comments":true,"path":"2018/05/17/MyBatis注解/","link":"","permalink":"http://gangtieguo.cn/2018/05/17/MyBatis注解/","excerpt":"现接触MyBatic记录一些注解","text":"现接触MyBatic记录一些注解自动生成主键 可以使用 @Options 注解的 userGeneratedKeys 和 keyProperty 属性让数据库产生 auto_increment（自增长）列的值，然后将生成的值设置到输入参数对象的属性中。 123@Insert(\"insert into students(name,sex,age) values(#&#123;name&#125;,#&#123;sex&#125;,#&#123;age&#125;\") @Options(useGeneratedKeys = true, keyProperty =\"userId\") int insertUser(User user); 将自增的Id存入到userId属性中","categories":[{"name":"框架","slug":"框架","permalink":"http://gangtieguo.cn/categories/框架/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://gangtieguo.cn/tags/Java/"},{"name":"SSH","slug":"SSH","permalink":"http://gangtieguo.cn/tags/SSH/"}]},{"title":"linux命令积累","slug":"Linux命令","date":"2018-05-10T07:37:28.983Z","updated":"2018-08-10T19:05:59.249Z","comments":true,"path":"2018/05/10/Linux命令/","link":"","permalink":"http://gangtieguo.cn/2018/05/10/Linux命令/","excerpt":"简单linux命令 nohup &amp;后台运行","text":"简单linux命令 nohup &amp;后台运行 文件查找find / -type f -size +10G在Linux下如何让文件让按大小单位为M,G等易读格式，S size大小排序。 ls -lhSdu -h * | sort -n当然您也可以结合管道文件夹内最大的几个文件 du -h * | sort -n|head动态显示机器各端口的链接情况while :; do netstat -apn | grep &quot;:80&quot; | wc -l; sleep 1; done sed更改第一行 sed -i &#39;1s/.*//&#39; sed -i ‘1s/.*/想更改的内容/‘ 12ssh root@slave01 \"sed -i '6c advertised.host.name=slave01 ' $KAFKA_HOME/config/server.properties\"s 删除第一行sed -i &#39;1d&#39; sed -i ‘1d’ 文件名插入第一行 sed -i &#39;1i\\&#39; sed -i ‘1i\\内容‘ 文件名 cpucat /proc/cpuinfo | grep processor | wc -llscpu sz rz与服务器交互上传下载文件sudo yum install lrzsz -y 挂载 sshfs root@192.168.73.12:/home/ /csdn/win10/ 即：sshfs 用户名@远程主机IP:远程主机路径 本地挂载点sshfs root@master:/usr/hadoop /usr/hive/hadoop 查看端口是否被监听也可验证对应端口程序是否启动netstat -nl|grep 10000","categories":[{"name":"Linux","slug":"Linux","permalink":"http://gangtieguo.cn/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://gangtieguo.cn/tags/linux/"},{"name":"开发","slug":"开发","permalink":"http://gangtieguo.cn/tags/开发/"}]},{"title":"spring集成权限校验","slug":"spring集成权限校验","date":"2018-05-08T10:34:55.000Z","updated":"2018-05-17T12:21:22.941Z","comments":true,"path":"2018/05/08/spring集成权限校验/","link":"","permalink":"http://gangtieguo.cn/2018/05/08/spring集成权限校验/","excerpt":"shiro简介shiro是权限控制的一个框架是一个强大易用的Java安全框架，提供了认证、授权、加密和会话管理功能，可为任何应用提供安全保障 - 从命令行应用、移动应用到大型网络及企业应用。","text":"shiro简介shiro是权限控制的一个框架是一个强大易用的Java安全框架，提供了认证、授权、加密和会话管理功能，可为任何应用提供安全保障 - 从命令行应用、移动应用到大型网络及企业应用。 权限控制的方式权限有四种实现方式注解(基于代理),url拦截(基于过滤器),shiro标签库(基于标签),编写代码(及其不推荐)不论哪种方式:都需要引入spring用于整合shiro的过滤器 web.xml中:DelegatingFilterProxy=&gt;spring整合shiro配置spring提供的用于整合shiro框架的过滤器123456789101112131415 &lt;filter&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy &lt;/fileter&gt;``` filet-name需要和**spring配置文件**中的一个BEAN对象的id保持一致**非常重要** ### 配置 I. 注解方式,注解是利用生成的代理对象来完成权限校验: spring框架会为当前action对象(加注解的action)创建一个代理对象,如果有权限,就执行这个方法,不然就会报**异常**(将spring,Strust配置文件丰富:添加权限的注解,struts添加捕获异常,跳转页面) 1. 需要在spring配置文件中进行配置开启注解**DefaultAdvisorAutoProxyCreator**, 并配置成cjlib方式的注解 ```xml&lt;property name=\"proxyTargetClass\" value=\"true\"&gt;\\&lt;/property&gt; 注解实现权限当为jdk模式的时候方法注解实现权限过滤抛异常的原因:因为如果是jdk方式的话,实现的接口modelDriven只有一个getModel方法所以不能进行对除该方法外其他方法进行注解 定义切面类AuthorizationAttributeSourceAdvisor 1&lt;bean id=\"authorizationAttributeSourceAdvisor\" class=\"org.apache.shiro.spring.security.interceptor.AuthorizationAttributeSourceAdvisor\"&gt;&lt;/bean&gt; 在需要权限才能访问的方法上添加注解 1234567891011121314151617181920212223242526272829 @RequiresPermissions(\"relo_delete这是权限名称\") ``` II. url拦截(springxml) 基于过滤器或者拦截器实现 ```xml&lt;bean id=\"shiroFilter\" class=\"org.apache.shiro.spring.web.ShiroFilterFactoryBean\"&gt; &lt;property name=\"securityManager\" ref=\"securityManager\"/&gt; &lt;property name=\"loginUrl\" value=\"/login.jsp\"/&gt; &lt;property name=\"unauthorizedUrl\" value=\"/unauthorized.jsp\"/&gt; &lt;property name=\"filterChainDefinitions\"&gt; &lt;value&gt; /css/** = anon /js/** = anon /images/** = anon /validatecode.jsp* = anon /login.jsp* = anon /userAction_login.action = anon /page_base_staff.action = perms[\"staff\"] /** = authc &lt;!--/** = authc--&gt; &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!--开启自动代理,并且将代理代理模式设置为cjlib--&gt; &lt;bean id=\"defaultAdvisorAutoProxyCreator\" class=\"org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator\"&gt; &lt;!--设置成cglib方式--&gt; &lt;property name=\"proxyTargetClass\" value=\"true\"&gt;&lt;/property&gt; &lt;/bean&gt; shiro的使用 在web.xml中引入用于创建shiro框架的过滤器web.xml中:DelegatingFilterProxy=&gt;spring整合shiro注意引入的位置:要在struts核心过滤器的前面,StrutsPrepareAndExcutFilter,不然,所有请求会通过struts过滤器获直接访问得到,shiro的过滤器将不会起到作用 在Spring中整合shiro2.1). shiro框架过滤器:ShiroFilterFactoryBean 需要声明那些过滤器,那些资源需要匹配那些过滤器,采用url拦截方式进行的路径对应的拦截器2.2). 配置安全管理器:DefaultWebSecurityManager 需要注入 自定义的Realm bean对象 1234567891011121314151617181920212223242526272829303132333435363738 &lt;!--配置一个shiro框架的过滤器工厂bean,用于创建shiro框架的过滤器--&gt; &lt;bean id=\"shiroFilter\" class=\"org.apache.shiro.spring.web.ShiroFilterFactoryBean\"&gt; &lt;property name=\"securityManager\" ref=\"securityManager\"/&gt; &lt;property name=\"loginUrl\" value=\"/login.jsp\"/&gt; &lt;property name=\"unauthorizedUrl\" value=\"/unauthorized.jsp\"/&gt; &lt;property name=\"filterChainDefinitions\"&gt; &lt;value&gt; /css/** = anon /js/** = anon /images/** = anon /validatecode.jsp* = anon /login.jsp* = anon /userAction_login.action = anon /page_base_staff.action = perms[\"staff\"] /** = authc &lt;!--/** 表示所有/下所有路径,包括下面的所有路径--&gt; &lt;!--/validatecode.jsp* 表示所有除了validatecode.jsp,还包括jsp后追加其他内容的.如validatecode.jsp?'+Math.random();防止验证码读取缓存 &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!--开启自动代理,并且将代理代理模式设置为cjlib 动态代理分为两类 基于jdk 创建的类必须要实现一个接口,这是面向接口的动态代理 基于cjlib 创建的类不能用final修饰--&gt; &lt;bean id=\"defaultAdvisorAutoProxyCreator\" class=\"org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator\"&gt; &lt;!--设置成cglib方式--&gt; &lt;property name=\"proxyTargetClass\" value=\"true\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--定义aop通知+切入点--&gt; &lt;bean id=\"authorizationAttributeSourceAdvisor\" class=\"org.apache.shiro.spring.security.interceptor.AuthorizationAttributeSourceAdvisor\"&gt;&lt;/bean&gt; &lt;!--注入安全管理器--&gt; &lt;bean id=\"securityManager\" class=\"org.apache.shiro.web.mgt.DefaultWebSecurityManager\"&gt; &lt;property name=\"realm\" ref=\"bosRealm\"&gt;&lt;/property&gt; &lt;property name=\"cacheManager\" ref=\"ehCacheManager\"&gt;&lt;/property&gt; &lt;/bean&gt; 在登陆认证的方法中加入subject controller中的login方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344public String login()&#123;Subject subject = SecurityUtils.getSubject(); //创建一个用户名密码令牌 AuthenticationToken token = new UsernamePasswordToken(getModel().getUsername(), MD5Utils.md5( getModel().getPassword())); try &#123; //认证 subject.login(token); &#125; catch (Exception e) &#123; this.addActionError(\"用户名或者密码错误\"); return LOGIN; &#125; /*当通过认证,跳入主页*/ User user = (User) subject.getPrincipal(); /*将用户信息存入session*/ ServletActionContext.getRequest().getSession().setAttribute(\"currentUser\", user); /*返回主页*/ return \"\";&#125;``` 4. 自定义Realm(用于权限的具体实施,即认证和授权)一般实现Realm接口的 **AuthorizingRealm** 实例 4.1实现认证 重写doGetAuthenticationInfo方法必须继承*AuthorizingRealm* 在需要交付给spring生成,并需要在安全注册管理器中注入属性Realm```javaprotected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123;UsernamePasswordToken mytoken = (UsernamePasswordToken) token; String username = mytoken.getUsername(); DetachedCriteria dc = DetachedCriteria.forClass(User.class); dc.add(Restrictions.eq(\"username\",username)); List&lt;User&gt; list = userDao.findByCriteria(dc); if(list != null &amp;&amp; list.size() &gt;0)&#123; User user = list.get(0); String dbPassword = user.getPassword(); AuthenticationInfo info = new SimpleAuthenticationInfo(user,dbPassword,this.getName()); return info; &#125;else&#123; return null; &#125; &#125; 4.2实现授权 重写doGetAuthorizationInfo方法 12345678910111213141516171819202122232425262728293031323334353637383940protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123;/*获的简单授权对象,用于授权的*/ SimpleAuthorizationInfo info = new SimpleAuthorizationInfo(); /*授权staff权限*/ //info.addStringPermission(\"staff\"); //步骤获得授权对象,获得当前用户,获得当前用户的权限(若为admin即授予所有权限),当前用户授权 //获得对象 User user = (User)principals.getPrimaryPrincipal(); List&lt;Function&gt; fList = null; //获得权限 if(user.getUsername().equals(\"admin\"))&#123; fList = functionDao.findAll(); &#125;else&#123; fList = functionDao.findFunctionByUserId(user.getId()); &#125; //授予权限 for(Function f : fList)&#123; info.addStringPermission(f.getCode());&#125;``` ## 关于Shiro中使用 **encache** 1.引入包 `在spring配置文件中配置以下` 2.配置文件ehcache.xml ```xml&lt;ehcache xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:noNamespaceSchemaLocation=\"../config/ehcache.xsd\"&gt; &lt;defaultCache maxElementsInMemory=\"10000\" eternal=\"false\" timeToIdleSeconds=\"120\" timeToLiveSeconds=\"120\" overflowToDisk=\"true\" maxElementsOnDisk=\"10000000\" diskPersistent=\"false\" diskExpiryThreadIntervalSeconds=\"120\" memoryStoreEvictionPolicy=\"LRU\" /&gt;&lt;/ehcache&gt; &lt;!--eternal是否永久有效--&gt; 3.引入缓存管理器EhCacheManager(shiro包中的),并设置配置文件;4.将缓存管理器注入安全管理器DefaultWebSecurityManager12345678910&lt;!--注册安全管理器--&gt;&lt;bean id=\"securityManager\" class=\"org.apache.shiro.web.mgt.DefaultWebSecurityManager\"&gt; &lt;property name=\"realm\" ref=\"bosRealm\"&gt;&lt;/property&gt; &lt;property name=\"cacheManager\" ref=\"ehCacheManager\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"bosRealm\" class=\"org.yao.bos.web.action.realm.BOSRealm\"&gt;&lt;/bean&gt; &lt;!--注入缓存管理器--&gt; &lt;bean id=\"ehCacheManager\" class=\"org.apache.shiro.cache.ehcache.EhCacheManager\"&gt; &lt;property name=\"cacheManagerConfigFile\" value=\"classpath:ehcache.xml\"&gt;&lt;/property&gt; &lt;/bean&gt;","categories":[{"name":"Spring","slug":"Spring","permalink":"http://gangtieguo.cn/categories/Spring/"}],"tags":[{"name":"开发","slug":"开发","permalink":"http://gangtieguo.cn/tags/开发/"},{"name":"Java","slug":"Java","permalink":"http://gangtieguo.cn/tags/Java/"},{"name":"技术","slug":"技术","permalink":"http://gangtieguo.cn/tags/技术/"}]},{"title":"博客备份.md","slug":"博客修改备份","date":"2018-05-08T10:34:55.000Z","updated":"2018-05-17T16:18:46.428Z","comments":true,"path":"2018/05/08/博客修改备份/","link":"","permalink":"http://gangtieguo.cn/2018/05/08/博客修改备份/","excerpt":"","text":"1234567891011121314151617&lt;% if (!is_post()) &#123; %&gt; &lt;% if (site.tags.length)&#123; %&gt; &lt;div class=&quot;widget tag&quot;&gt; &lt;h3 class=&quot;title&quot;&gt;&lt;%= __(&apos;标签 :&apos;) %&gt;&lt;/h3&gt; &lt;%- list_categories(site.tags) %&gt; &lt;/div&gt; &lt;% &#125; %&gt; &lt;% &#125; %&gt; &lt;% if (!is_post()) &#123; %&gt; &lt;% if (site.categories.length)&#123; %&gt; &lt;div class=&quot;widget tag&quot;&gt; &lt;h2 class=&quot;title&quot;&gt;&lt;%= __(&apos;分类 :&apos;) %&gt;&lt;/h2&gt; &lt;h4&gt; &lt;%- list_categories(site.categories) %&gt;&lt;/h4&gt; &lt;/div&gt; &lt;% &#125; %&gt; &lt;% &#125; %&gt; 123456&lt;% if (!index &amp;&amp; post.toc) &#123; %&gt; &lt;div id=&quot;toc&quot; class=&quot;toc-article&quot;&gt; &lt;strong class=&quot;toc-title&quot;&gt;&lt;%= __(&apos;&apos;) %&gt;&lt;/strong&gt; &lt;%- toc(post.content) %&gt; &lt;/div&gt; &lt;% &#125; %&gt;","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://gangtieguo.cn/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://gangtieguo.cn/tags/Hexo/"},{"name":"Other","slug":"Other","permalink":"http://gangtieguo.cn/tags/Other/"}]}]}